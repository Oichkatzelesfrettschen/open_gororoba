#!/usr/bin/env python3
"""
Build a TOML scope registry for pending CSV->TOML migration waves.

Input:
- registry/csv_inventory.toml

Output:
- registry/csv_migration_scope.toml
"""

from __future__ import annotations

import argparse
import json
import tomllib
from collections import Counter
from pathlib import Path


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        sample = "".join(bad[:20])
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {sample!r}")


def _esc(value: str) -> str:
    return json.dumps(value, ensure_ascii=True)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--inventory",
        default="registry/csv_inventory.toml",
        help="Input CSV inventory TOML path.",
    )
    parser.add_argument(
        "--out",
        default="registry/csv_migration_scope.toml",
        help="Output TOML path.",
    )
    args = parser.parse_args()

    root = Path(args.repo_root).resolve()
    inv_path = root / args.inventory
    out_path = root / args.out

    inv = tomllib.loads(inv_path.read_text(encoding="utf-8"))
    docs = inv.get("document", [])

    zone_counter: Counter[str] = Counter()
    action_counter: Counter[str] = Counter()
    priority_counter: Counter[str] = Counter()

    high_priority_paths: list[str] = []
    medium_priority_paths: list[str] = []

    for row in docs:
        zone = str(row.get("zone", "unknown"))
        action = str(row.get("migration_action", "manual_triage"))
        priority = str(row.get("migration_priority", "medium"))
        path = str(row.get("path", ""))

        zone_counter[zone] += 1
        action_counter[action] += 1
        priority_counter[priority] += 1

        if priority in {"critical", "high"}:
            high_priority_paths.append(path)
        elif priority == "medium":
            medium_priority_paths.append(path)

    lines: list[str] = []
    lines.append("# CSV migration scope registry (TOML-first).")
    lines.append("# Generated by src/scripts/analysis/build_csv_migration_scope_registry.py")
    lines.append("")
    lines.append("[csv_migration_scope]")
    lines.append('updated = "2026-02-09"')
    lines.append("authoritative = true")
    lines.append(f"inventory_path = {_esc(args.inventory)}")
    lines.append(f"document_count = {len(docs)}")
    lines.append("")

    lines.append("[zone_counts]")
    for key in sorted(zone_counter):
        lines.append(f"{key} = {zone_counter[key]}")
    lines.append("")

    lines.append("[action_counts]")
    for key in sorted(action_counter):
        lines.append(f"{key} = {action_counter[key]}")
    lines.append("")

    lines.append("[priority_counts]")
    for key in sorted(priority_counter):
        lines.append(f"{key} = {priority_counter[key]}")
    lines.append("")

    lines.append("[next_waves]")
    lines.append('wave_1 = "complete: legacy_csv -> registry/data/legacy_csv"')
    lines.append('wave_2 = "pending: curated_csv canonicalization strategy and conversion"')
    lines.append('wave_3 = "pending: project_csv split (generated artifact vs canonical dataset)"')
    lines.append('wave_4 = "pending: archive_csv retention policy and optional canonical lift"')
    lines.append("")

    lines.append("high_priority_path_sample = [")
    for path in sorted(high_priority_paths)[:200]:
        lines.append(f"  {_esc(path)},")
    lines.append("]")
    lines.append("")

    lines.append("medium_priority_path_sample = [")
    for path in sorted(medium_priority_paths)[:200]:
        lines.append(f"  {_esc(path)},")
    lines.append("]")

    rendered = "\n".join(lines)
    _assert_ascii(rendered, str(out_path))
    out_path.write_text(rendered, encoding="utf-8")

    print(f"Wrote {out_path} with scope summary from {len(docs)} CSV records.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
