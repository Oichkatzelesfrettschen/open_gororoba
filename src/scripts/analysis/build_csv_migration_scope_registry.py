#!/usr/bin/env python3
"""
Build a TOML scope registry for pending CSV->TOML migration waves.

Input:
- registry/csv_inventory.toml

Output:
- registry/csv_migration_scope.toml
"""

from __future__ import annotations

import argparse
import json
import tomllib
from collections import Counter
from pathlib import Path


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        sample = "".join(bad[:20])
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {sample!r}")


def _esc(value: str) -> str:
    return json.dumps(value, ensure_ascii=True)


def _wave_state(total: int, done: int, pending_label: str, done_label: str) -> str:
    if total <= 0:
        return "n/a: no records"
    if done >= total:
        return f"complete: {done}/{total} {done_label}"
    remaining = total - done
    return f"in_progress: {done}/{total} done, {remaining} pending ({pending_label})"


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--inventory",
        default="registry/csv_inventory.toml",
        help="Input CSV inventory TOML path.",
    )
    parser.add_argument(
        "--out",
        default="registry/csv_migration_scope.toml",
        help="Output TOML path.",
    )
    args = parser.parse_args()

    root = Path(args.repo_root).resolve()
    inv_path = root / args.inventory
    out_path = root / args.out

    inv = tomllib.loads(inv_path.read_text(encoding="utf-8"))
    docs = inv.get("document", [])

    zone_counter: Counter[str] = Counter()
    action_counter: Counter[str] = Counter()
    priority_counter: Counter[str] = Counter()

    high_priority_paths: list[str] = []
    medium_priority_paths: list[str] = []

    for row in docs:
        zone = str(row.get("zone", "unknown"))
        action = str(row.get("migration_action", "manual_triage"))
        priority = str(row.get("migration_priority", "medium"))
        path = str(row.get("path", ""))

        zone_counter[zone] += 1
        action_counter[action] += 1
        priority_counter[priority] += 1

        if priority in {"critical", "high"}:
            high_priority_paths.append(path)
        elif priority == "medium":
            medium_priority_paths.append(path)

    lines: list[str] = []
    lines.append("# CSV migration scope registry (TOML-first).")
    lines.append("# Generated by src/scripts/analysis/build_csv_migration_scope_registry.py")
    lines.append("")
    lines.append("[csv_migration_scope]")
    lines.append('updated = "2026-02-09"')
    lines.append("authoritative = true")
    lines.append(f"inventory_path = {_esc(args.inventory)}")
    lines.append(f"document_count = {len(docs)}")
    lines.append("")

    lines.append("[zone_counts]")
    for key in sorted(zone_counter):
        lines.append(f"{key} = {zone_counter[key]}")
    lines.append("")

    lines.append("[action_counts]")
    for key in sorted(action_counter):
        lines.append(f"{key} = {action_counter[key]}")
    lines.append("")

    lines.append("[priority_counts]")
    for key in sorted(priority_counter):
        lines.append(f"{key} = {priority_counter[key]}")
    lines.append("")

    legacy_total = zone_counter.get("legacy_csv", 0)
    legacy_done = sum(
        1
        for row in docs
        if str(row.get("zone", "")) == "legacy_csv"
        and str(row.get("migration_action", "")) == "canonicalized_to_toml"
    )
    curated_total = zone_counter.get("curated_csv", 0)
    curated_done = sum(
        1
        for row in docs
        if str(row.get("zone", "")) == "curated_csv"
        and str(row.get("migration_action", "")) == "canonicalized_to_toml"
    )
    project_total = zone_counter.get("project_csv", 0)
    project_done = sum(
        1
        for row in docs
        if str(row.get("zone", "")) == "project_csv"
        and str(row.get("migration_action", ""))
        in {"canonicalized_to_toml", "canonicalized_to_toml_generated_artifact"}
    )
    external_total = zone_counter.get("external_csv", 0)
    archive_total = zone_counter.get("archive_csv", 0)
    holding_total = external_total + archive_total
    holding_done = sum(
        1
        for row in docs
        if str(row.get("zone", "")) in {"external_csv", "archive_csv"}
        and str(row.get("migration_action", "")) == "queued_for_scroll_holding"
    )

    lines.append("[next_waves]")
    lines.append(
        f"wave_1 = {_esc(_wave_state(legacy_total, legacy_done, 'migrate_to_toml_canonical', 'legacy_csv canonicalized'))}"
    )
    lines.append(
        f"wave_2 = {_esc(_wave_state(curated_total, curated_done, 'plan_curated_ingest', 'curated_csv canonicalized'))}"
    )
    lines.append(
        f"wave_3 = {_esc(_wave_state(project_total, project_done, 'project_csv split/migration', 'project_csv split-and-scroll complete'))}"
    )
    lines.append(
        f"wave_4 = {_esc(_wave_state(holding_total, holding_done, 'external/archive holding queue', 'external+archive holding queued'))}"
    )
    lines.append("")

    lines.append("high_priority_path_sample = [")
    for path in sorted(high_priority_paths)[:200]:
        lines.append(f"  {_esc(path)},")
    lines.append("]")
    lines.append("")

    lines.append("medium_priority_path_sample = [")
    for path in sorted(medium_priority_paths)[:200]:
        lines.append(f"  {_esc(path)},")
    lines.append("]")

    rendered = "\n".join(lines)
    _assert_ascii(rendered, str(out_path))
    out_path.write_text(rendered, encoding="utf-8")

    print(f"Wrote {out_path} with scope summary from {len(docs)} CSV records.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
