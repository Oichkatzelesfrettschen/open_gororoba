#!/usr/bin/env python3
"""
Migrate tracked markdown corpus into central TOML document database.

Policy:
- Ingest all non-generated markdown docs into registry/knowledge/docs/*.toml.
- Keep generated markdown as artifacts (indexed but not ingested).
- Emit a master manifest: registry/knowledge/documents.toml.
"""

from __future__ import annotations

import argparse
import hashlib
import tomllib
from dataclasses import dataclass
from pathlib import Path

DETERMINISTIC_STAMP = "deterministic"


@dataclass(frozen=True)
class SourceDoc:
    doc_id: str
    path: str
    title: str
    kind: str
    generated: bool
    status: str
    migration_priority: str
    sha256: str
    line_count: int
    size_bytes: int


def _escape_toml(text: str) -> str:
    escaped = (
        text.replace("\\", "\\\\")
        .replace('"', '\\"')
        .replace("\n", "\\n")
        .replace("\r", "\\r")
        .replace("\t", "\\t")
    )
    return f'"{escaped}"'


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        sample = "".join(bad[:20])
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {sample!r}")


def _read_index(path: Path) -> list[SourceDoc]:
    data = tomllib.loads(path.read_text(encoding="utf-8"))
    out: list[SourceDoc] = []
    for row in data.get("document", []):
        out.append(
            SourceDoc(
                doc_id=row["id"],
                path=row["path"],
                title=row["title"],
                kind=row["kind"],
                generated=bool(row["generated"]),
                status=row["status"],
                migration_priority=row["migration_priority"],
                sha256=row["sha256"],
                line_count=int(row["line_count"]),
                size_bytes=int(row["size_bytes"]),
            )
        )
    return out


def _hash(text: str) -> str:
    return hashlib.sha256(text.encode("utf-8")).hexdigest()


def _to_toml_multiline(content: str) -> str:
    out: list[str] = []
    for ch in content:
        code = ord(ch)
        if ch == "\\":
            out.append("\\\\")
        elif ch == '"':
            out.append('\\"')
        elif ch == "\t":
            out.append("\\t")
        elif ch == "\r":
            out.append("\\r")
        elif ch == "\n":
            out.append("\n")
        elif code < 32:
            out.append(f"\\u{code:04X}")
        elif code > 127 and code <= 0xFFFF:
            out.append(f"\\u{code:04X}")
        elif code > 0xFFFF:
            out.append(f"\\U{code:08X}")
        else:
            out.append(ch)
    return '"""\n' + "".join(out) + '\n"""'


def _render_doc_toml(source: SourceDoc, content: str) -> str:
    content_hash = _hash(content)
    lines: list[str] = []
    lines.append("# Markdown source migrated to TOML document store.")
    lines.append("# This file is generated by migrate_markdown_corpus_to_toml.py.")
    lines.append("")
    lines.append("[document]")
    lines.append(f"id = {_escape_toml(source.doc_id)}")
    lines.append(f"source_path = {_escape_toml(source.path)}")
    lines.append(f"title = {_escape_toml(source.title)}")
    lines.append(f"kind = {_escape_toml(source.kind)}")
    lines.append(f"status = {_escape_toml(source.status)}")
    lines.append(f"migration_priority = {_escape_toml(source.migration_priority)}")
    lines.append(f"generated = {'true' if source.generated else 'false'}")
    lines.append(f"source_sha256 = {_escape_toml(source.sha256)}")
    lines.append(f"source_line_count = {source.line_count}")
    lines.append(f"source_size_bytes = {source.size_bytes}")
    lines.append(f"content_sha256 = {_escape_toml(content_hash)}")
    lines.append(f"migrated_at = {_escape_toml(DETERMINISTIC_STAMP)}")
    lines.append("capture_mode = \"raw_markdown_capture\"")
    lines.append("authoritative = false")
    lines.append("content_format = \"markdown\"")
    lines.append(f"content_markdown = {_to_toml_multiline(content)}")
    lines.append("")
    return "\n".join(lines)


def _render_manifest(
    ingested: list[tuple[SourceDoc, str]],
    skipped: list[SourceDoc],
) -> str:
    lines: list[str] = []
    lines.append("# Central document manifest for TOML-backed markdown knowledge corpus.")
    lines.append("# Generated by migrate_markdown_corpus_to_toml.py.")
    lines.append("# This is a raw capture layer, not a normalized authoritative schema.")
    lines.append("")
    lines.append("[knowledge_documents]")
    lines.append(f"generated_at = {_escape_toml(DETERMINISTIC_STAMP)}")
    lines.append(f"raw_capture_count = {len(ingested)}")
    lines.append(f"skipped_generated_count = {len(skipped)}")
    lines.append("authoritative = false")
    lines.append("normalization_required = true")
    lines.append("")
    for source, out_rel in ingested:
        lines.append("[[document]]")
        lines.append(f"id = {_escape_toml(source.doc_id)}")
        lines.append(f"source_path = {_escape_toml(source.path)}")
        lines.append(f"title = {_escape_toml(source.title)}")
        lines.append(f"kind = {_escape_toml(source.kind)}")
        lines.append(f"migration_priority = {_escape_toml(source.migration_priority)}")
        lines.append("raw_captured = true")
        lines.append("authoritative = false")
        lines.append("normalization_status = \"pending\"")
        lines.append(f"document_toml = {_escape_toml(out_rel)}")
        lines.append("")
    for source in skipped:
        lines.append("[[document]]")
        lines.append(f"id = {_escape_toml(source.doc_id)}")
        lines.append(f"source_path = {_escape_toml(source.path)}")
        lines.append(f"title = {_escape_toml(source.title)}")
        lines.append(f"kind = {_escape_toml(source.kind)}")
        lines.append("raw_captured = false")
        lines.append("authoritative = false")
        lines.append("skip_reason = \"generated_markdown_or_artifact\"")
        lines.append("")
    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--index",
        default="registry/knowledge_sources.toml",
        help="Input knowledge-source index TOML.",
    )
    parser.add_argument(
        "--out-dir",
        default="registry/knowledge/docs",
        help="Output directory for per-document TOML files.",
    )
    parser.add_argument(
        "--manifest",
        default="registry/knowledge/documents.toml",
        help="Output manifest path.",
    )
    parser.add_argument(
        "--prune-stale",
        action="store_true",
        help=(
            "Delete stale registry/knowledge/docs/DOC-*.toml files. "
            "Default keeps historical raw captures for non-reproducible context preservation."
        ),
    )
    args = parser.parse_args()

    repo_root = Path(args.repo_root).resolve()
    index_path = repo_root / args.index
    out_dir = repo_root / args.out_dir
    manifest_path = repo_root / args.manifest

    docs = _read_index(index_path)
    out_dir.mkdir(parents=True, exist_ok=True)
    manifest_path.parent.mkdir(parents=True, exist_ok=True)

    ingested: list[tuple[SourceDoc, str]] = []
    skipped: list[SourceDoc] = []

    expected_outputs: set[Path] = set()

    for doc in docs:
        if doc.generated:
            skipped.append(doc)
            continue
        source_path = repo_root / doc.path
        if not source_path.exists():
            continue
        content = source_path.read_text(encoding="utf-8", errors="ignore")
        rendered = _render_doc_toml(doc, content)
        rel_out = f"registry/knowledge/docs/{doc.doc_id}.toml"
        out_path = repo_root / rel_out
        expected_outputs.add(out_path.resolve())
        _assert_ascii(rendered, str(out_path))
        out_path.write_text(rendered, encoding="utf-8")
        ingested.append((doc, rel_out))

    stale_count = 0
    for existing in out_dir.glob("DOC-*.toml"):
        if existing.resolve() in expected_outputs:
            continue
        stale_count += 1
        if args.prune_stale:
            existing.unlink()

    manifest = _render_manifest(ingested, skipped)
    _assert_ascii(manifest, str(manifest_path))
    manifest_path.write_text(manifest, encoding="utf-8")

    print(
        f"Raw-captured {len(ingested)} markdown docs into TOML; "
        f"skipped {len(skipped)} generated docs; "
        f"stale captures {'pruned' if args.prune_stale else 'retained'}={stale_count}."
    )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
