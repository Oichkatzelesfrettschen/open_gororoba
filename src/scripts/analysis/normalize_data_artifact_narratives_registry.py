#!/usr/bin/env python3
"""
Bootstrap selected data/artifacts markdown narratives into a TOML-first registry.

Inputs:
- data/artifacts/ALGEBRAIC_FOUNDATIONS.md
- data/artifacts/BIBLIOGRAPHY.md
- data/artifacts/FINAL_REPORT.md
- data/artifacts/QUANTUM_REPORT.md
- data/artifacts/SIMULATION_REPORT.md
- data/artifacts/extracted_equations.md
- data/artifacts/reality_check_and_synthesis.md

Output:
- registry/data_artifact_narratives.toml
"""

from __future__ import annotations

import argparse
import re
from dataclasses import dataclass
from pathlib import Path

CLAIM_RE = re.compile(r"\bC-\d{3}\b")
BACKTICK_RE = re.compile(r"`([^`\n]+)`")
HEADING_RE = re.compile(r"^#\s+(.+?)\s*$", flags=re.M)

TARGET_FILES = (
    "data/artifacts/ALGEBRAIC_FOUNDATIONS.md",
    "data/artifacts/BIBLIOGRAPHY.md",
    "data/artifacts/FINAL_REPORT.md",
    "data/artifacts/QUANTUM_REPORT.md",
    "data/artifacts/SIMULATION_REPORT.md",
    "data/artifacts/extracted_equations.md",
    "data/artifacts/reality_check_and_synthesis.md",
)


@dataclass(frozen=True)
class ArtifactDoc:
    doc_id: str
    source_markdown: str
    slug: str
    title: str
    content_kind: str
    claim_refs: list[str]
    path_refs: list[str]
    line_count: int
    body_markdown: str


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        sample = "".join(bad[:20])
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {sample!r}")


def _ascii_sanitize(text: str) -> str:
    replacements = {
        "\u2018": "'",
        "\u2019": "'",
        "\u201c": '"',
        "\u201d": '"',
        "\u2013": "-",
        "\u2014": "-",
        "\u2026": "...",
        "\u00a0": " ",
    }
    out: list[str] = []
    for ch in text:
        mapped = replacements.get(ch, ch)
        for item in mapped:
            code = ord(item)
            if item in {"\n", "\r", "\t"}:
                out.append(item)
            elif code < 32:
                out.append(" ")
            elif code <= 127:
                out.append(item)
            else:
                out.append(f"<U+{code:04X}>")
    return "".join(out)


def _escape(text: str) -> str:
    escaped = (
        text.replace("\\", "\\\\")
        .replace('"', '\\"')
        .replace("\n", "\\n")
        .replace("\r", "\\r")
        .replace("\t", "\\t")
    )
    return f'"{escaped}"'


def _render_list(values: list[str]) -> str:
    if not values:
        return "[]"
    return "[" + ", ".join(_escape(v) for v in values) + "]"


def _render_multiline(text: str) -> str:
    if "'''" not in text:
        return "'''\n" + text + "\n'''"
    escaped = (
        text.replace("\\", "\\\\")
        .replace('"', '\\"')
        .replace("\n", "\\n")
        .replace("\r", "\\r")
        .replace("\t", "\\t")
    )
    return f'"{escaped}"'


def _title(text: str, fallback: str) -> str:
    match = HEADING_RE.search(text)
    return match.group(1).strip() if match else fallback


def _paths(text: str) -> list[str]:
    out: list[str] = []
    seen: set[str] = set()
    for raw in BACKTICK_RE.findall(text):
        token = raw.strip()
        if not token:
            continue
        if token.startswith("http://") or token.startswith("https://"):
            continue
        if "/" not in token and "." not in token:
            continue
        if token in seen:
            continue
        seen.add(token)
        out.append(token)
    return out


def _kind(filename: str) -> str:
    mapping = {
        "ALGEBRAIC_FOUNDATIONS.md": "algebraic_foundations",
        "BIBLIOGRAPHY.md": "artifact_bibliography",
        "FINAL_REPORT.md": "final_report",
        "QUANTUM_REPORT.md": "quantum_report",
        "SIMULATION_REPORT.md": "simulation_report",
        "extracted_equations.md": "equation_extract",
        "reality_check_and_synthesis.md": "reality_check_and_synthesis",
    }
    return mapping.get(filename, "artifact_narrative")


def _parse_doc(index: int, rel: Path, text: str) -> ArtifactDoc:
    sanitized = _ascii_sanitize(text)
    return ArtifactDoc(
        doc_id=f"ART-{index:03d}",
        source_markdown=rel.as_posix(),
        slug=rel.stem,
        title=_title(sanitized, rel.stem),
        content_kind=_kind(rel.name),
        claim_refs=sorted(set(CLAIM_RE.findall(sanitized))),
        path_refs=_paths(sanitized),
        line_count=len(sanitized.splitlines()),
        body_markdown=sanitized.rstrip("\n"),
    )


def _render_toml(records: list[ArtifactDoc]) -> str:
    lines: list[str] = []
    lines.append("# Data artifact narratives registry (TOML-first).")
    lines.append("# Generated by src/scripts/analysis/normalize_data_artifact_narratives_registry.py")
    lines.append("")
    lines.append("[data_artifact_narratives]")
    lines.append('updated = "2026-02-09"')
    lines.append("authoritative = true")
    lines.append(f"source_markdown_count = {len(TARGET_FILES)}")
    lines.append(f"document_count = {len(records)}")
    lines.append("")
    lines.append("source_markdown = [")
    for rel in TARGET_FILES:
        lines.append(f"  {_escape(rel)},")
    lines.append("]")
    lines.append("")
    for rec in records:
        lines.append("[[document]]")
        lines.append(f"id = {_escape(rec.doc_id)}")
        lines.append(f"source_markdown = {_escape(rec.source_markdown)}")
        lines.append(f"slug = {_escape(rec.slug)}")
        lines.append(f"title = {_escape(rec.title)}")
        lines.append(f"content_kind = {_escape(rec.content_kind)}")
        lines.append(f"claim_refs = {_render_list(rec.claim_refs)}")
        lines.append(f"path_refs = {_render_list(rec.path_refs)}")
        lines.append(f"line_count = {rec.line_count}")
        lines.append(f"body_markdown = {_render_multiline(rec.body_markdown)}")
        lines.append("")
    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--bootstrap-from-markdown",
        action="store_true",
        help="Required flag to ingest markdown into TOML registry.",
    )
    parser.add_argument(
        "--out",
        default="registry/data_artifact_narratives.toml",
        help="Output TOML registry path.",
    )
    args = parser.parse_args()

    if not args.bootstrap_from_markdown:
        raise SystemExit("ERROR: pass --bootstrap-from-markdown to ingest markdown sources")

    root = Path(args.repo_root).resolve()
    records: list[ArtifactDoc] = []

    for idx, rel in enumerate(TARGET_FILES, start=1):
        path = root / rel
        if not path.exists():
            raise SystemExit(f"ERROR: missing expected markdown source: {rel}")
        text = path.read_text(encoding="utf-8", errors="ignore")
        records.append(_parse_doc(idx, Path(rel), text))

    out_text = _render_toml(records)
    out_path = root / args.out
    _assert_ascii(out_text, str(out_path))
    out_path.write_text(out_text, encoding="utf-8")
    print(f"Wrote {out_path} with {len(records)} documents.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
