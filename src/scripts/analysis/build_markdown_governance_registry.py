#!/usr/bin/env python3
"""
Build markdown lifecycle governance registry.

The registry classifies each tracked markdown file into one of:
- toml_generated_mirror
- toml_manual_source
- generated_artifact
- manual_narrative
- immutable_transcript

This allows enforceable TOML-first policy and explicit exceptions.
"""

from __future__ import annotations

import argparse
import fnmatch
import tomllib
from pathlib import Path


def _escape(text: str) -> str:
    esc = (
        text.replace("\\", "\\\\")
        .replace('"', '\\"')
        .replace("\n", "\\n")
        .replace("\r", "\\r")
        .replace("\t", "\\t")
    )
    return f'"{esc}"'


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {''.join(bad[:20])!r}")


def _iter_registry_refs(root: Path) -> dict[str, set[str]]:
    refs: dict[str, set[str]] = {}
    reg_files = sorted((root / "registry").glob("*.toml"))

    def add(path: str, src: str) -> None:
        path = path.strip()
        if not path.endswith(".md"):
            return
        refs.setdefault(path, set()).add(src)

    def walk(obj: object, src: str) -> None:
        if isinstance(obj, dict):
            for key, value in obj.items():
                lk = key.lower()
                if lk in {"source_markdown", "markdown"}:
                    if isinstance(value, str):
                        add(value, src)
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, str):
                                add(item, src)
                elif lk in {"source_markdown_glob", "source_markdown_globs"}:
                    if isinstance(value, str):
                        for p in root.glob(value):
                            if p.is_file():
                                add(p.relative_to(root).as_posix(), src)
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, str):
                                for p in root.glob(item):
                                    if p.is_file():
                                        add(p.relative_to(root).as_posix(), src)
                else:
                    walk(value, src)
        elif isinstance(obj, list):
            for item in obj:
                walk(item, src)

    for reg in reg_files:
        data = tomllib.loads(reg.read_text(encoding="utf-8"))
        walk(data, reg.relative_to(root).as_posix())

    return refs


def _generated_mirror_patterns() -> list[str]:
    return [
        "docs/generated/*.md",
        "docs/INSIGHTS.md",
        "docs/EXPERIMENTS_PORTFOLIO_SHORTLIST.md",
        "docs/ROADMAP.md",
        "docs/TODO.md",
        "docs/NEXT_ACTIONS.md",
        "docs/CLAIMS_TASKS.md",
        "docs/claims/INDEX.md",
        "docs/claims/by_domain/*.md",
        "docs/tickets/*.md",
        "docs/tickets/INDEX.md",
        "REQUIREMENTS.md",
        "docs/REQUIREMENTS.md",
        "docs/requirements/*.md",
    ]


def _is_generated_mirror(path: str) -> bool:
    for pattern in _generated_mirror_patterns():
        if fnmatch.fnmatch(path, pattern):
            return True
    return False


def _render(records: list[dict]) -> str:
    by_mode: dict[str, int] = {}
    for rec in records:
        mode = rec["mode"]
        by_mode[mode] = by_mode.get(mode, 0) + 1

    lines: list[str] = []
    lines.append("# Markdown lifecycle governance registry (TOML-first).")
    lines.append("# Generated by src/scripts/analysis/build_markdown_governance_registry.py")
    lines.append("")
    lines.append("[markdown_governance]")
    lines.append('generated_at = "deterministic"')
    lines.append("authoritative = true")
    lines.append(f"document_count = {len(records)}")
    for key in sorted(by_mode):
        lines.append(f"{key}_count = {by_mode[key]}")
    lines.append("")

    for rec in records:
        lines.append("[[document]]")
        lines.append(f"path = {_escape(rec['path'])}")
        lines.append(f"id = {_escape(rec['id'])}")
        lines.append(f"kind = {_escape(rec['kind'])}")
        lines.append(f"mode = {_escape(rec['mode'])}")
        lines.append(f"header_required = {'true' if rec['header_required'] else 'false'}")
        if rec["source_toml_refs"]:
            refs = ", ".join(_escape(x) for x in rec["source_toml_refs"])
            lines.append(f"source_toml_refs = [{refs}]")
        if rec["notes"]:
            lines.append(f"notes = {_escape(rec['notes'])}")
        lines.append("")

    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--knowledge-index",
        default="registry/knowledge_sources.toml",
        help="Knowledge source index path.",
    )
    parser.add_argument(
        "--out",
        default="registry/markdown_governance.toml",
        help="Output governance registry path.",
    )
    args = parser.parse_args()

    root = Path(args.repo_root).resolve()
    knowledge = tomllib.loads((root / args.knowledge_index).read_text(encoding="utf-8"))
    refs = _iter_registry_refs(root)

    records: list[dict] = []
    for i, row in enumerate(knowledge.get("document", []), start=1):
        path = str(row.get("path", "")).strip()
        if not path.endswith(".md"):
            continue
        kind = str(row.get("kind", ""))
        source_refs = sorted(refs.get(path, set()))

        if _is_generated_mirror(path):
            mode = "toml_generated_mirror"
            header_required = True
            notes = "Generated from TOML registries and overlays."
        elif kind == "transcript_input":
            mode = "immutable_transcript"
            header_required = False
            notes = "Immutable transcript input; not authoritative for claims."
        elif source_refs:
            mode = "toml_manual_source"
            header_required = False
            notes = "Manual source consumed by TOML normalizers."
        elif kind in {"generated_markdown", "artifact_report"}:
            mode = "generated_artifact"
            header_required = False
            notes = "Generated artifact/report; preserve reproducibility."
        else:
            mode = "manual_narrative"
            header_required = False
            notes = "Manual narrative source; raw-captured in registry/knowledge/docs."

        records.append(
            {
                "id": f"MDG-{i:04d}",
                "path": path,
                "kind": kind,
                "mode": mode,
                "header_required": header_required,
                "source_toml_refs": source_refs,
                "notes": notes,
            }
        )

    out_text = _render(records)
    out_path = root / args.out
    _assert_ascii(out_text, str(out_path))
    out_path.write_text(out_text, encoding="utf-8")
    print(f"Wrote {out_path} with {len(records)} entries.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
