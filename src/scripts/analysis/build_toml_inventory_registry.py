#!/usr/bin/env python3
"""
Build a full TOML inventory registry for Wave 4 control-plane hardening.

This registry inventories tracked/untracked/ignored TOML files and classifies
their role in the repository architecture.
"""

from __future__ import annotations

import argparse
import hashlib
import json
import subprocess
import tomllib
from collections import Counter
from pathlib import Path


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {''.join(bad[:20])!r}")


def _esc(value: str) -> str:
    return json.dumps(value, ensure_ascii=True)


def _git_paths(root: Path, args: list[str]) -> set[str]:
    out = subprocess.check_output(["git", *args], cwd=root, text=True)
    return {line.strip() for line in out.splitlines() if line.strip()}


def _classify(path: str) -> tuple[str, str]:
    if path.startswith("registry/data/"):
        return ("dataset_scroll", "registry_dataset")
    if path.startswith("registry/"):
        return ("registry_control_plane", "registry_control")
    if path == "Cargo.toml":
        return ("cargo_workspace_manifest", "workspace_manifest")
    if path.endswith("/Cargo.toml"):
        return ("cargo_crate_manifest", "crate_manifest")
    if path == ".cargo/config.toml":
        return ("cargo_toolchain_config", "toolchain_config")
    if path == "pyproject.toml":
        return ("python_project_config", "python_config")
    if path.startswith("papers/"):
        return ("papers_registry", "papers")
    return ("toml_other", "other")


def _count_markdown_refs(obj: object) -> int:
    count = 0
    if isinstance(obj, dict):
        for key, value in obj.items():
            lk = key.lower()
            if lk in {
                "source_markdown",
                "source_markdown_glob",
                "source_markdown_globs",
                "generated_mirror",
                "output_markdown",
                "markdown",
                "primary_markdown",
            }:
                if isinstance(value, str):
                    count += 1 if ".md" in value else 0
                elif isinstance(value, list):
                    count += sum(
                        1
                        for item in value
                        if isinstance(item, str) and ".md" in item
                    )
            count += _count_markdown_refs(value)
    elif isinstance(obj, list):
        for item in obj:
            count += _count_markdown_refs(item)
    return count


def _has_authoritative(obj: object) -> bool:
    if isinstance(obj, dict):
        for key, value in obj.items():
            if key == "authoritative" and value is True:
                return True
            if _has_authoritative(value):
                return True
    elif isinstance(obj, list):
        for item in obj:
            if _has_authoritative(item):
                return True
    return False


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--out",
        default="registry/toml_inventory.toml",
        help="Output TOML inventory path.",
    )
    args = parser.parse_args()

    root = Path(args.repo_root).resolve()
    out_path = root / args.out

    tracked = _git_paths(root, ["ls-files", "*.toml"])
    untracked = _git_paths(root, ["ls-files", "--others", "--exclude-standard", "*.toml"])
    ignored = _git_paths(root, ["ls-files", "--others", "--ignored", "--exclude-standard", "*.toml"])

    all_paths = sorted(tracked | untracked | ignored)

    status_counts: Counter[str] = Counter()
    role_counts: Counter[str] = Counter()
    zone_counts: Counter[str] = Counter()

    parse_error_paths: list[str] = []

    lines: list[str] = []
    lines.append("# TOML inventory registry (Wave 4 control plane).")
    lines.append("# Generated by src/scripts/analysis/build_toml_inventory_registry.py")
    lines.append("")

    doc_rows: list[dict[str, object]] = []
    for path in all_paths:
        if path in tracked:
            git_status = "tracked"
        elif path in untracked:
            git_status = "untracked"
        else:
            git_status = "ignored"

        full = root / path
        text = full.read_text(encoding="utf-8", errors="ignore")
        sha = hashlib.sha256(text.encode("utf-8")).hexdigest()
        line_count = text.count("\n") + (1 if text else 0)
        size_bytes = full.stat().st_size
        role, zone = _classify(path)

        parse_ok = True
        parse_error = ""
        table_count = 0
        markdown_ref_count = 0
        has_authoritative = False
        try:
            data = tomllib.loads(text)
            if isinstance(data, dict):
                table_count = len(data.keys())
            markdown_ref_count = _count_markdown_refs(data)
            has_authoritative = _has_authoritative(data)
        except tomllib.TOMLDecodeError as exc:
            parse_ok = False
            parse_error = str(exc)
            parse_error_paths.append(path)

        status_counts[git_status] += 1
        role_counts[role] += 1
        zone_counts[zone] += 1

        doc_rows.append(
            {
                "path": path,
                "git_status": git_status,
                "role": role,
                "zone": zone,
                "parse_ok": parse_ok,
                "parse_error": parse_error,
                "line_count": line_count,
                "size_bytes": size_bytes,
                "sha256": sha,
                "table_count": table_count,
                "markdown_ref_count": markdown_ref_count,
                "has_authoritative": has_authoritative,
            }
        )

    lines.append("[toml_inventory]")
    lines.append('updated = "deterministic"')
    lines.append("authoritative = true")
    lines.append(f"document_count = {len(doc_rows)}")
    lines.append(f"tracked_count = {status_counts.get('tracked', 0)}")
    lines.append(f"untracked_count = {status_counts.get('untracked', 0)}")
    lines.append(f"ignored_count = {status_counts.get('ignored', 0)}")
    lines.append(f"parse_error_count = {len(parse_error_paths)}")
    lines.append("")

    lines.append("[git_status_counts]")
    for key in sorted(status_counts):
        lines.append(f"{key} = {status_counts[key]}")
    lines.append("")

    lines.append("[role_counts]")
    for key in sorted(role_counts):
        lines.append(f"{key} = {role_counts[key]}")
    lines.append("")

    lines.append("[zone_counts]")
    for key in sorted(zone_counts):
        lines.append(f"{key} = {zone_counts[key]}")
    lines.append("")

    if parse_error_paths:
        lines.append("parse_error_paths = [")
        for path in sorted(parse_error_paths):
            lines.append(f"  {_esc(path)},")
        lines.append("]")
        lines.append("")

    for i, row in enumerate(sorted(doc_rows, key=lambda item: str(item["path"])), start=1):
        lines.append("[[document]]")
        lines.append(f"id = {_esc(f'TOML-{i:04d}')}")
        lines.append(f"path = {_esc(str(row['path']))}")
        lines.append(f"git_status = {_esc(str(row['git_status']))}")
        lines.append(f"role = {_esc(str(row['role']))}")
        lines.append(f"zone = {_esc(str(row['zone']))}")
        lines.append(f"parse_ok = {'true' if bool(row['parse_ok']) else 'false'}")
        if row["parse_error"]:
            lines.append(f"parse_error = {_esc(str(row['parse_error']))}")
        lines.append(f"has_authoritative = {'true' if bool(row['has_authoritative']) else 'false'}")
        lines.append(f"table_count = {int(row['table_count'])}")
        lines.append(f"markdown_ref_count = {int(row['markdown_ref_count'])}")
        lines.append(f"size_bytes = {int(row['size_bytes'])}")
        lines.append(f"line_count = {int(row['line_count'])}")
        lines.append(f"sha256 = {_esc(str(row['sha256']))}")
        lines.append("")

    rendered = "\n".join(lines)
    _assert_ascii(rendered, str(out_path))
    out_path.write_text(rendered, encoding="utf-8")
    print(f"Wrote {out_path} with {len(doc_rows)} TOML records.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
