#!/usr/bin/env python3
"""
Build a full CSV inventory registry (tracked, untracked, ignored, archived).

This complements markdown inventory work by establishing CSV corpus visibility,
including gitignored and archived files.
"""

from __future__ import annotations

import argparse
import hashlib
import json
import subprocess
from dataclasses import dataclass
from pathlib import Path


@dataclass(frozen=True)
class CsvDoc:
    path: str
    git_status: str
    zone: str
    archived: bool
    generated: bool
    size_bytes: int
    line_count: int
    sha256: str
    migration_action: str
    migration_priority: str
    rationale: str


def _assert_ascii(text: str, context: str) -> None:
    bad = sorted({ch for ch in text if ord(ch) > 127})
    if bad:
        sample = "".join(bad[:20])
        raise SystemExit(f"ERROR: Non-ASCII output in {context}: {sample!r}")


def _esc(value: str) -> str:
    return json.dumps(value, ensure_ascii=True)


def _git_paths(root: Path, args: list[str]) -> set[str]:
    out = subprocess.check_output(["git", *args], cwd=root, text=True)
    return {line.strip() for line in out.splitlines() if line.strip()}


def _all_filesystem_csv(root: Path) -> set[str]:
    out: set[str] = set()
    for path in root.rglob("*.csv"):
        rel = path.relative_to(root).as_posix()
        if rel.startswith(".git/"):
            continue
        out.add(rel)
    return out


def _status(path: str, tracked: set[str], untracked: set[str], ignored: set[str]) -> str:
    if path in tracked:
        return "tracked"
    if path in untracked:
        return "untracked"
    if path in ignored:
        return "ignored"
    return "unknown"


def _zone(path: str) -> str:
    if path.startswith("data/csv/legacy/"):
        return "legacy_csv"
    if path.startswith("data/csv/"):
        return "project_csv"
    if path.startswith("data/external/"):
        return "external_csv"
    if path.startswith("curated/"):
        return "curated_csv"
    if path.startswith("archive/") or path.startswith("docs/archive/"):
        return "archive_csv"
    return "other_csv"


def _policy(path: str, zone: str) -> tuple[str, str, str]:
    if zone == "legacy_csv":
        return (
            "migrate_to_toml_canonical",
            "critical",
            "Legacy CSV should become TOML-native canonical data.",
        )
    if zone == "project_csv":
        return (
            "evaluate_for_toml_canonical",
            "high",
            "Project CSV may be generated artifacts or transition candidates.",
        )
    if zone == "curated_csv":
        return (
            "plan_curated_ingest",
            "high",
            "Curated observational CSV should move under central TOML data policy.",
        )
    if zone == "external_csv":
        return (
            "track_provenance_only",
            "medium",
            "External CSV remains provenance-managed input unless explicitly curated.",
        )
    if zone == "archive_csv":
        return (
            "review_archive_policy",
            "low",
            "Archived CSV may be retained as historical snapshots.",
        )
    return (
        "manual_triage",
        "medium",
        "CSV outside expected zones; requires classification.",
    )


def _render(docs: list[CsvDoc]) -> str:
    tracked_count = sum(1 for d in docs if d.git_status == "tracked")
    untracked_count = sum(1 for d in docs if d.git_status == "untracked")
    ignored_count = sum(1 for d in docs if d.git_status == "ignored")
    archived_count = sum(1 for d in docs if d.archived)
    legacy_count = sum(1 for d in docs if d.zone == "legacy_csv")

    lines: list[str] = []
    lines.append("# Full CSV inventory registry (tracked/untracked/ignored/archived).")
    lines.append("# Generated by src/scripts/analysis/build_csv_inventory_registry.py")
    lines.append("")
    lines.append("[csv_inventory]")
    lines.append('updated = "2026-02-09"')
    lines.append("authoritative = true")
    lines.append(f"document_count = {len(docs)}")
    lines.append(f"tracked_count = {tracked_count}")
    lines.append(f"untracked_count = {untracked_count}")
    lines.append(f"ignored_count = {ignored_count}")
    lines.append(f"archived_count = {archived_count}")
    lines.append(f"legacy_count = {legacy_count}")
    lines.append("")

    for doc in docs:
        lines.append("[[document]]")
        lines.append(f"path = {_esc(doc.path)}")
        lines.append(f"git_status = {_esc(doc.git_status)}")
        lines.append(f"zone = {_esc(doc.zone)}")
        lines.append(f"archived = {str(doc.archived).lower()}")
        lines.append(f"generated = {str(doc.generated).lower()}")
        lines.append(f"size_bytes = {doc.size_bytes}")
        lines.append(f"line_count = {doc.line_count}")
        lines.append(f"sha256 = {_esc(doc.sha256)}")
        lines.append(f"migration_action = {_esc(doc.migration_action)}")
        lines.append(f"migration_priority = {_esc(doc.migration_priority)}")
        lines.append(f"rationale = {_esc(doc.rationale)}")
        lines.append("")

    return "\n".join(lines)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--repo-root",
        default=str(Path(__file__).resolve().parents[3]),
        help="Repository root.",
    )
    parser.add_argument(
        "--out",
        default="registry/csv_inventory.toml",
        help="Output TOML path relative to repo root.",
    )
    args = parser.parse_args()

    root = Path(args.repo_root).resolve()

    tracked = _git_paths(root, ["ls-files", "*.csv"])
    untracked = _git_paths(root, ["ls-files", "--others", "--exclude-standard", "*.csv"])
    ignored = _git_paths(
        root,
        ["ls-files", "--others", "--ignored", "--exclude-standard", "*.csv"],
    )

    files = sorted(_all_filesystem_csv(root))

    docs: list[CsvDoc] = []
    for rel in files:
        path = root / rel
        raw = path.read_bytes()
        text = raw.decode("utf-8", errors="ignore")
        zone = _zone(rel)
        action, priority, rationale = _policy(rel, zone)
        docs.append(
            CsvDoc(
                path=rel,
                git_status=_status(rel, tracked, untracked, ignored),
                zone=zone,
                archived=rel.startswith("archive/") or rel.startswith("docs/archive/"),
                generated=rel.startswith("data/csv/") and not rel.startswith("data/csv/legacy/"),
                size_bytes=len(raw),
                line_count=text.count("\n") + (1 if text else 0),
                sha256=hashlib.sha256(raw).hexdigest(),
                migration_action=action,
                migration_priority=priority,
                rationale=rationale,
            )
        )

    out_path = root / args.out
    rendered = _render(docs)
    _assert_ascii(rendered, str(out_path))
    out_path.write_text(rendered, encoding="utf-8")

    print(f"Wrote {out_path} with {len(docs)} CSV entries.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
