LLVM IR Output
"{(Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True)): '; ModuleID = \'numba_vectorized\'\nsource_filename = ""<string>""\ntarget datalayout = ""e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128""\ntarget triple = ""x86_64-unknown-linux-gnu""\n\n@.const.pickledata.139580233997072 = internal constant [181 x i8] c""\\80\\04\\95\\AA\\00\\00\\00\\00\\00\\00\\00\\8C\\08builtins\\94\\8C\\0AValueError\\94\\93\\94\\8C\\87unable to broadcast argument 1 to output array\\0AFile \\22/home/sandbox/.local/lib/python3.11/site-packages/numba/np/npyimpl.py\\22, line 370, \\94\\85\\94N\\87\\94.""\n@.const.pickledata.139580233997072.sha1 = internal constant [20 x i8] c""(\\A4\\88\'\\83\\ACT[\\F5K\\F2\\89\\1E\\9D\\88o\\9C\\BE\\84!""\n@.const.picklebuf.139580233997072 = internal constant { i8*, i32, i8*, i8*, i32 } { i8* getelementptr inbounds ([181 x i8], [181 x i8]* @.const.pickledata.139580233997072, i32 0, i32 0), i32 181, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.139580233997072.sha1, i32 0, i32 0), i8* null, i32 0 }\n@.const.pickledata.139580234506448 = internal constant [137 x i8] c""\\80\\04\\95~\\00\\00\\00\\00\\00\\00\\00\\8C\\08builtins\\94\\8C\\0AValueError\\94\\93\\94\\8C[array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.\\94\\85\\94N\\87\\94.""\n@.const.pickledata.139580234506448.sha1 = internal constant [20 x i8] c""X\\E1N\\CC\\B5\\07\\B1\\E0 i\\81t\\02#\\E6\\85\\CB\\8C<W""\n@.const.picklebuf.139580234506448 = internal constant { i8*, i32, i8*, i8*, i32 } { i8* getelementptr inbounds ([137 x i8], [137 x i8]* @.const.pickledata.139580234506448, i32 0, i32 0), i32 137, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.139580234506448.sha1, i32 0, i32 0), i8* null, i32 0 }\n@.const.numba_vectorized = internal constant [17 x i8] c""numba_vectorized\\00""\n@_ZN08NumbaEnv8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE = common local_unnamed_addr global i8* null\n@"".const.missing Environment: _ZN08NumbaEnv8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE"" = internal constant [171 x i8] c""missing Environment: _ZN08NumbaEnv8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE\\00""\n@PyExc_TypeError = external global i8\n@"".const.can\'t unbox array from PyObject into native value.  The object maybe of a different type"" = internal constant [89 x i8] c""can\'t unbox array from PyObject into native value.  The object maybe of a different type\\00""\n@"".const.`env.consts` is NULL in `read_const`"" = internal constant [37 x i8] c""`env.consts` is NULL in `read_const`\\00""\n@.const.pickledata.139583502599616 = internal constant [32 x i8] c""\\80\\04\\95\\15\\00\\00\\00\\00\\00\\00\\00\\8C\\05numpy\\94\\8C\\07ndarray\\94\\93\\94.""\n@.const.pickledata.139583502599616.sha1 = internal constant [20 x i8] c""\\DF\\BC\\FD\\D3\\9F\\CB&\\F4\\D0\\C6\\80\\95D\\87\\B8\\C0\\B5;\\B8\\A3""\n@"".const.Error creating Python tuple from runtime exception arguments"" = internal constant [61 x i8] c""Error creating Python tuple from runtime exception arguments\\00""\n@"".const.unknown error when calling native function"" = internal constant [43 x i8] c""unknown error when calling native function\\00""\n@PyExc_RuntimeError = external global i8\n@"".const.Error creating Python tuple from runtime exception arguments.1"" = internal constant [61 x i8] c""Error creating Python tuple from runtime exception arguments\\00""\n@PyExc_StopIteration = external global i8\n@PyExc_SystemError = external global i8\n@"".const.unknown error when calling native function.2"" = internal constant [43 x i8] c""unknown error when calling native function\\00""\n@"".const.<numba.core.cpu.CPUContext object at 0x7ef28e11a5e0>"" = internal constant [53 x i8] c""<numba.core.cpu.CPUContext object at 0x7ef28e11a5e0>\\00""\n@_ZN08NumbaEnv13_3cdynamic_3e33__numba_array_expr_0x7ef28d879160B3v12B72c8tJTIeFIjxB2IKSgI4CrvQCk0Z4yRYcWsBAQ4s_2fqEpEUkESQI1_2bmEQRxHRNAA_3d_3dEdd = common local_unnamed_addr global i8* null\n@_ZN08NumbaEnv5numba2np7npyimpl15_broadcast_ontoB3v13B42c8tJTC_2fWQA93W1AaAIYBPIqRBFCjDSZRVAJmaQIAEx8int64_2ax8int64_2a = common local_unnamed_addr global i8* null\n@_ZN08NumbaEnv5numba2np8arrayobj15_call_allocatorB2v3B42c8tJTC_2fWQA93W1AaAIYBPIqRBFCjDSZRVAJmaQIAEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj = common local_unnamed_addr global i8* null\n@_ZN08NumbaEnv5numba2np8arrayobj18_ol_array_allocate12_3clocals_3e4implB2v4B42c8tJTIeFIjxB2IKSgI4CrvQClcaMQ5hEEUSJJgA_3dEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj = common local_unnamed_addr global i8* null\n@.const.pickledata.139580232182160 = internal constant [86 x i8] c""\\80\\04\\95K\\00\\00\\00\\00\\00\\00\\00\\8C\\08builtins\\94\\8C\\0BMemoryError\\94\\93\\94\\8C\'Allocation failed (probably too large).\\94\\85\\94N\\87\\94.""\n@.const.pickledata.139580232182160.sha1 = internal constant [20 x i8] c""\\BA(\\9D\\81\\F0\\\\p \\F3G|\\15sH\\04\\DFe\\AB\\E2\\09""\n@.const.picklebuf.139580232182160 = internal constant { i8*, i32, i8*, i8*, i32 } { i8* getelementptr inbounds ([86 x i8], [86 x i8]* @.const.pickledata.139580232182160, i32 0, i32 0), i32 86, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.139580232182160.sha1, i32 0, i32 0), i8* null, i32 0 }\n\ndefine i32 @_ZN8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE({ i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* noalias nocapture writeonly %retptr, { i8*, i32, i8*, i8*, i32 }** noalias nocapture writeonly %excinfo, i8* %arg.a.0, i8* nocapture readnone %arg.a.1, i64 %arg.a.2, i64 %arg.a.3, double* %arg.a.4, i64 %arg.a.5.0, i64 %arg.a.6.0, i8* %arg.b.0, i8* nocapture readnone %arg.b.1, i64 %arg.b.2, i64 %arg.b.3, double* %arg.b.4, i64 %arg.b.5.0, i64 %arg.b.6.0) local_unnamed_addr {\nentry:\n  tail call void @NRT_incref(i8* %arg.a.0)\n  tail call void @NRT_incref(i8* %arg.b.0)\n  %.101.not.i = icmp eq i64 %arg.a.5.0, 1\n  br i1 %.101.not.i, label %B0.endif.endif.endif.endif, label %B90.i12\n\ncommon.ret:                                       ; preds = %B0.endif.endif.endif.endif.endif.if, %for.end, %B0.endif.endif.endif.endif.if, %B0.endif.endif.endif.if\n  %common.ret.op = phi i32 [ 1, %B0.endif.endif.endif.if ], [ 1, %B0.endif.endif.endif.endif.if ], [ 0, %for.end ], [ 1, %B0.endif.endif.endif.endif.endif.if ]\n  ret i32 %common.ret.op\n\nB90.i12:                                          ; preds = %entry\n  %.71.not.i9 = icmp eq i64 %arg.a.5.0, %arg.b.5.0\n  %.76.not.i10 = icmp eq i64 %arg.b.5.0, 1\n  %or.cond.i11 = or i1 %.76.not.i10, %.71.not.i9\n  br i1 %or.cond.i11, label %B0.endif.endif.endif.endif, label %B0.endif.endif.endif.if\n\nB0.endif.endif.endif.if:                          ; preds = %B90.i12\n  store { i8*, i32, i8*, i8*, i32 }* @.const.picklebuf.139580233997072, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8, !numba_exception_output !0\n  br label %common.ret\n\nB0.endif.endif.endif.endif:                       ; preds = %entry, %B90.i12\n  %dest_shape.1 = phi i64 [ %arg.a.5.0, %B90.i12 ], [ %arg.b.5.0, %entry ]\n  %.136 = tail call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %dest_shape.1, i64 8)\n  %.138 = extractvalue { i64, i1 } %.136, 1\n  br i1 %.138, label %B0.endif.endif.endif.endif.if, label %B0.endif.endif.endif.endif.endif, !prof !1\n\nB0.endif.endif.endif.endif.if:                    ; preds = %B0.endif.endif.endif.endif\n  store { i8*, i32, i8*, i8*, i32 }* @.const.picklebuf.139580234506448, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8, !numba_exception_output !0\n  br label %common.ret\n\nB0.endif.endif.endif.endif.endif:                 ; preds = %B0.endif.endif.endif.endif\n  %.137 = extractvalue { i64, i1 } %.136, 0\n  %.7.i.i = tail call i8* @NRT_MemInfo_alloc_aligned(i64 %.137, i32 32), !noalias !2\n  %.8.i.i = icmp eq i8* %.7.i.i, null\n  br i1 %.8.i.i, label %B0.endif.endif.endif.endif.endif.if, label %B0.endif.endif.endif.endif.endif.endif, !prof !1\n\nB0.endif.endif.endif.endif.endif.if:              ; preds = %B0.endif.endif.endif.endif.endif\n  store { i8*, i32, i8*, i8*, i32 }* @.const.picklebuf.139580232182160, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8\n  br label %common.ret\n\nB0.endif.endif.endif.endif.endif.endif:           ; preds = %B0.endif.endif.endif.endif.endif\n  %.5.i = getelementptr i8, i8* %.7.i.i, i64 24\n  %0 = bitcast i8* %.5.i to double**\n  %.6.i2229 = load double*, double** %0, align 8\n  %.20825 = icmp sgt i64 %dest_shape.1, 0\n  br i1 %.20825, label %for.body.preheader, label %for.end\n\nfor.body.preheader:                               ; preds = %B0.endif.endif.endif.endif.endif.endif\n  %.210 = icmp ugt i64 %arg.a.5.0, 1\n  br i1 %.210, label %for.body.preheader.split.us, label %for.body.preheader.split\n\nfor.body.preheader.split.us:                      ; preds = %for.body.preheader\n  %1 = icmp ugt i64 %arg.b.5.0, 1\n  br i1 %1, label %for.body.us.us.preheader, label %for.body.us.preheader\n\nfor.body.us.preheader:                            ; preds = %for.body.preheader.split.us\n  %2 = add i64 %dest_shape.1, -1\n  %xtraiter111 = and i64 %dest_shape.1, 3\n  %3 = icmp ult i64 %2, 3\n  br i1 %3, label %for.end.loopexit107.unr-lcssa, label %for.body.us.preheader.new\n\nfor.body.us.preheader.new:                        ; preds = %for.body.us.preheader\n  %4 = ptrtoint double* %arg.a.4 to i64\n  %unroll_iter114 = and i64 %dest_shape.1, -4\n  %5 = shl i64 %arg.a.6.0, 2\n  %6 = mul i64 %arg.a.6.0, 3\n  br label %for.body.us\n\nfor.body.us.us.preheader:                         ; preds = %for.body.preheader.split.us\n  %7 = add i64 %dest_shape.1, -1\n  %xtraiter = and i64 %dest_shape.1, 3\n  %8 = icmp ult i64 %7, 3\n  br i1 %8, label %for.end.loopexit.unr-lcssa, label %for.body.us.us.preheader.new\n\nfor.body.us.us.preheader.new:                     ; preds = %for.body.us.us.preheader\n  %9 = ptrtoint double* %arg.b.4 to i64\n  %10 = ptrtoint double* %arg.a.4 to i64\n  %unroll_iter = and i64 %dest_shape.1, -4\n  %11 = shl i64 %arg.a.6.0, 2\n  %12 = shl i64 %arg.b.6.0, 2\n  %13 = mul i64 %arg.a.6.0, 3\n  %14 = mul i64 %arg.b.6.0, 3\n  br label %for.body.us.us\n\nfor.body.us.us:                                   ; preds = %for.body.us.us, %for.body.us.us.preheader.new\n  %lsr.iv138 = phi i64 [ %lsr.iv.next139, %for.body.us.us ], [ %9, %for.body.us.us.preheader.new ]\n  %lsr.iv136 = phi i64 [ %lsr.iv.next137, %for.body.us.us ], [ %10, %for.body.us.us.preheader.new ]\n  %loop.index28.us.us = phi i64 [ 0, %for.body.us.us.preheader.new ], [ %.258.us.us.3, %for.body.us.us ]\n  %.218.us.us = inttoptr i64 %lsr.iv136 to double*\n  %.219.us.us = load double, double* %.218.us.us, align 8\n  %.228.us.us = inttoptr i64 %lsr.iv138 to double*\n  %.229.us.us = load double, double* %.228.us.us, align 8\n  %.6.i.us.us = fadd double %.219.us.us, %.229.us.us\n  %sunkaddr = mul i64 %loop.index28.us.us, 8\n  %15 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr221 = getelementptr i8, i8* %15, i64 %sunkaddr\n  %16 = bitcast i8* %sunkaddr221 to double*\n  store double %.6.i.us.us, double* %16, align 8\n  %17 = add i64 %arg.a.6.0, %lsr.iv136\n  %.218.us.us.1 = inttoptr i64 %17 to double*\n  %.219.us.us.1 = load double, double* %.218.us.us.1, align 8\n  %18 = add i64 %arg.b.6.0, %lsr.iv138\n  %.228.us.us.1 = inttoptr i64 %18 to double*\n  %.229.us.us.1 = load double, double* %.228.us.us.1, align 8\n  %.6.i.us.us.1 = fadd double %.219.us.us.1, %.229.us.us.1\n  %sunkaddr222 = mul i64 %loop.index28.us.us, 8\n  %19 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr223 = getelementptr i8, i8* %19, i64 %sunkaddr222\n  %sunkaddr224 = getelementptr i8, i8* %sunkaddr223, i64 8\n  %20 = bitcast i8* %sunkaddr224 to double*\n  store double %.6.i.us.us.1, double* %20, align 8\n  %sunkaddr225 = inttoptr i64 %lsr.iv136 to double*\n  %sunkaddr226 = mul i64 %arg.a.6.0, 2\n  %21 = bitcast double* %sunkaddr225 to i8*\n  %sunkaddr227 = getelementptr i8, i8* %21, i64 %sunkaddr226\n  %22 = bitcast i8* %sunkaddr227 to double*\n  %.219.us.us.2 = load double, double* %22, align 8\n  %sunkaddr228 = inttoptr i64 %lsr.iv138 to double*\n  %sunkaddr229 = mul i64 %arg.b.6.0, 2\n  %23 = bitcast double* %sunkaddr228 to i8*\n  %sunkaddr230 = getelementptr i8, i8* %23, i64 %sunkaddr229\n  %24 = bitcast i8* %sunkaddr230 to double*\n  %.229.us.us.2 = load double, double* %24, align 8\n  %.6.i.us.us.2 = fadd double %.219.us.us.2, %.229.us.us.2\n  %sunkaddr231 = mul i64 %loop.index28.us.us, 8\n  %25 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr232 = getelementptr i8, i8* %25, i64 %sunkaddr231\n  %sunkaddr233 = getelementptr i8, i8* %sunkaddr232, i64 16\n  %26 = bitcast i8* %sunkaddr233 to double*\n  store double %.6.i.us.us.2, double* %26, align 8\n  %27 = add i64 %13, %lsr.iv136\n  %.218.us.us.3 = inttoptr i64 %27 to double*\n  %.219.us.us.3 = load double, double* %.218.us.us.3, align 8\n  %28 = add i64 %14, %lsr.iv138\n  %.228.us.us.3 = inttoptr i64 %28 to double*\n  %.229.us.us.3 = load double, double* %.228.us.us.3, align 8\n  %.6.i.us.us.3 = fadd double %.219.us.us.3, %.229.us.us.3\n  %sunkaddr234 = mul i64 %loop.index28.us.us, 8\n  %29 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr235 = getelementptr i8, i8* %29, i64 %sunkaddr234\n  %sunkaddr236 = getelementptr i8, i8* %sunkaddr235, i64 24\n  %30 = bitcast i8* %sunkaddr236 to double*\n  store double %.6.i.us.us.3, double* %30, align 8\n  %.258.us.us.3 = add nuw i64 %loop.index28.us.us, 4\n  %lsr.iv.next137 = add i64 %lsr.iv136, %11\n  %lsr.iv.next139 = add i64 %lsr.iv138, %12\n  %niter.ncmp.3 = icmp eq i64 %unroll_iter, %.258.us.us.3\n  br i1 %niter.ncmp.3, label %for.end.loopexit.unr-lcssa, label %for.body.us.us\n\nfor.body.us:                                      ; preds = %for.body.us, %for.body.us.preheader.new\n  %lsr.iv152 = phi i64 [ %lsr.iv.next153, %for.body.us ], [ %4, %for.body.us.preheader.new ]\n  %loop.index28.us = phi i64 [ 0, %for.body.us.preheader.new ], [ %.258.us.3, %for.body.us ]\n  %.218.us = inttoptr i64 %lsr.iv152 to double*\n  %.219.us = load double, double* %.218.us, align 8\n  %.229.us = load double, double* %arg.b.4, align 8\n  %.6.i.us = fadd double %.219.us, %.229.us\n  %sunkaddr237 = mul i64 %loop.index28.us, 8\n  %31 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr238 = getelementptr i8, i8* %31, i64 %sunkaddr237\n  %32 = bitcast i8* %sunkaddr238 to double*\n  store double %.6.i.us, double* %32, align 8\n  %33 = add i64 %arg.a.6.0, %lsr.iv152\n  %.218.us.1 = inttoptr i64 %33 to double*\n  %.219.us.1 = load double, double* %.218.us.1, align 8\n  %.229.us.1 = load double, double* %arg.b.4, align 8\n  %.6.i.us.1 = fadd double %.219.us.1, %.229.us.1\n  %sunkaddr239 = mul i64 %loop.index28.us, 8\n  %34 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr240 = getelementptr i8, i8* %34, i64 %sunkaddr239\n  %sunkaddr241 = getelementptr i8, i8* %sunkaddr240, i64 8\n  %35 = bitcast i8* %sunkaddr241 to double*\n  store double %.6.i.us.1, double* %35, align 8\n  %sunkaddr242 = inttoptr i64 %lsr.iv152 to double*\n  %sunkaddr243 = mul i64 %arg.a.6.0, 2\n  %36 = bitcast double* %sunkaddr242 to i8*\n  %sunkaddr244 = getelementptr i8, i8* %36, i64 %sunkaddr243\n  %37 = bitcast i8* %sunkaddr244 to double*\n  %.219.us.2 = load double, double* %37, align 8\n  %.229.us.2 = load double, double* %arg.b.4, align 8\n  %.6.i.us.2 = fadd double %.219.us.2, %.229.us.2\n  %sunkaddr245 = mul i64 %loop.index28.us, 8\n  %38 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr246 = getelementptr i8, i8* %38, i64 %sunkaddr245\n  %sunkaddr247 = getelementptr i8, i8* %sunkaddr246, i64 16\n  %39 = bitcast i8* %sunkaddr247 to double*\n  store double %.6.i.us.2, double* %39, align 8\n  %40 = add i64 %6, %lsr.iv152\n  %.218.us.3 = inttoptr i64 %40 to double*\n  %.219.us.3 = load double, double* %.218.us.3, align 8\n  %.229.us.3 = load double, double* %arg.b.4, align 8\n  %.6.i.us.3 = fadd double %.219.us.3, %.229.us.3\n  %sunkaddr248 = mul i64 %loop.index28.us, 8\n  %41 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr249 = getelementptr i8, i8* %41, i64 %sunkaddr248\n  %sunkaddr250 = getelementptr i8, i8* %sunkaddr249, i64 24\n  %42 = bitcast i8* %sunkaddr250 to double*\n  store double %.6.i.us.3, double* %42, align 8\n  %.258.us.3 = add nuw i64 %loop.index28.us, 4\n  %lsr.iv.next153 = add i64 %lsr.iv152, %5\n  %niter115.ncmp.3 = icmp eq i64 %unroll_iter114, %.258.us.3\n  br i1 %niter115.ncmp.3, label %for.end.loopexit107.unr-lcssa, label %for.body.us\n\nfor.body.preheader.split:                         ; preds = %for.body.preheader\n  %43 = icmp ugt i64 %arg.b.5.0, 1\n  br i1 %43, label %for.body.us52.preheader, label %for.body.preheader77\n\nfor.body.us52.preheader:                          ; preds = %for.body.preheader.split\n  %44 = add i64 %dest_shape.1, -1\n  %xtraiter116 = and i64 %dest_shape.1, 3\n  %45 = icmp ult i64 %44, 3\n  br i1 %45, label %for.end.loopexit108.unr-lcssa, label %for.body.us52.preheader.new\n\nfor.body.us52.preheader.new:                      ; preds = %for.body.us52.preheader\n  %46 = ptrtoint double* %arg.b.4 to i64\n  %unroll_iter119 = and i64 %dest_shape.1, -4\n  %47 = shl i64 %arg.b.6.0, 2\n  %48 = mul i64 %arg.b.6.0, 3\n  br label %for.body.us52\n\nfor.body.preheader77:                             ; preds = %for.body.preheader.split\n  %min.iters.check = icmp ult i64 %dest_shape.1, 16\n  br i1 %min.iters.check, label %for.body.preheader109, label %vector.memcheck\n\nvector.memcheck:                                  ; preds = %for.body.preheader77\n  %scevgep = getelementptr double, double* %.6.i2229, i64 %dest_shape.1\n  %scevgep82 = getelementptr double, double* %arg.a.4, i64 1\n  %scevgep85 = getelementptr double, double* %arg.b.4, i64 1\n  %bound0 = icmp ult double* %.6.i2229, %scevgep82\n  %bound1 = icmp ugt double* %scevgep, %arg.a.4\n  %found.conflict = and i1 %bound0, %bound1\n  %bound087 = icmp ult double* %.6.i2229, %scevgep85\n  %bound188 = icmp ugt double* %scevgep, %arg.b.4\n  %found.conflict89 = and i1 %bound087, %bound188\n  %conflict.rdx = or i1 %found.conflict, %found.conflict89\n  br i1 %conflict.rdx, label %for.body.preheader109, label %vector.ph\n\nvector.ph:                                        ; preds = %vector.memcheck\n  %n.vec = and i64 %dest_shape.1, -16\n  %49 = add i64 %n.vec, -16\n  %50 = lshr exact i64 %49, 4\n  %51 = add nuw nsw i64 %50, 1\n  %52 = icmp eq i64 %49, 0\n  br i1 %52, label %middle.block.unr-lcssa, label %vector.ph.new\n\nvector.ph.new:                                    ; preds = %vector.ph\n  %unroll_iter126 = and i64 %51, 2305843009213693950\n  %53 = load double, double* %arg.a.4, align 8, !alias.scope !9\n  %54 = load double, double* %arg.b.4, align 8, !alias.scope !12\n  %.scalar = fadd double %53, %54\n  %55 = insertelement <4 x double> poison, double %.scalar, i64 0\n  %56 = shufflevector <4 x double> %55, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar104 = fadd double %53, %54\n  %57 = insertelement <4 x double> poison, double %.scalar104, i64 0\n  %58 = shufflevector <4 x double> %57, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar105 = fadd double %53, %54\n  %59 = insertelement <4 x double> poison, double %.scalar105, i64 0\n  %60 = shufflevector <4 x double> %59, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar106 = fadd double %53, %54\n  %61 = insertelement <4 x double> poison, double %.scalar106, i64 0\n  %62 = shufflevector <4 x double> %61, <4 x double> poison, <4 x i32> zeroinitializer\n  %63 = load double, double* %arg.a.4, align 8, !alias.scope !9\n  %64 = load double, double* %arg.b.4, align 8, !alias.scope !12\n  %.scalar.1 = fadd double %63, %64\n  %65 = insertelement <4 x double> poison, double %.scalar.1, i64 0\n  %66 = shufflevector <4 x double> %65, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar104.1 = fadd double %63, %64\n  %67 = insertelement <4 x double> poison, double %.scalar104.1, i64 0\n  %68 = shufflevector <4 x double> %67, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar105.1 = fadd double %63, %64\n  %69 = insertelement <4 x double> poison, double %.scalar105.1, i64 0\n  %70 = shufflevector <4 x double> %69, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar106.1 = fadd double %63, %64\n  %71 = insertelement <4 x double> poison, double %.scalar106.1, i64 0\n  %72 = shufflevector <4 x double> %71, <4 x double> poison, <4 x i32> zeroinitializer\n  br label %vector.body\n\nvector.body:                                      ; preds = %vector.body, %vector.ph.new\n  %lsr.iv219 = phi i64 [ %lsr.iv.next220, %vector.body ], [ %unroll_iter126, %vector.ph.new ]\n  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]\n  %sunkaddr251 = mul i64 %index, 8\n  %73 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr252 = getelementptr i8, i8* %73, i64 %sunkaddr251\n  %74 = bitcast i8* %sunkaddr252 to <4 x double>*\n  store <4 x double> %56, <4 x double>* %74, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr253 = mul i64 %index, 8\n  %75 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr254 = getelementptr i8, i8* %75, i64 %sunkaddr253\n  %sunkaddr255 = getelementptr i8, i8* %sunkaddr254, i64 32\n  %76 = bitcast i8* %sunkaddr255 to <4 x double>*\n  store <4 x double> %58, <4 x double>* %76, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr256 = mul i64 %index, 8\n  %77 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr257 = getelementptr i8, i8* %77, i64 %sunkaddr256\n  %sunkaddr258 = getelementptr i8, i8* %sunkaddr257, i64 64\n  %78 = bitcast i8* %sunkaddr258 to <4 x double>*\n  store <4 x double> %60, <4 x double>* %78, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr259 = mul i64 %index, 8\n  %79 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr260 = getelementptr i8, i8* %79, i64 %sunkaddr259\n  %sunkaddr261 = getelementptr i8, i8* %sunkaddr260, i64 96\n  %80 = bitcast i8* %sunkaddr261 to <4 x double>*\n  store <4 x double> %62, <4 x double>* %80, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr262 = mul i64 %index, 8\n  %81 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr263 = getelementptr i8, i8* %81, i64 %sunkaddr262\n  %sunkaddr264 = getelementptr i8, i8* %sunkaddr263, i64 128\n  %82 = bitcast i8* %sunkaddr264 to <4 x double>*\n  store <4 x double> %66, <4 x double>* %82, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr265 = mul i64 %index, 8\n  %83 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr266 = getelementptr i8, i8* %83, i64 %sunkaddr265\n  %sunkaddr267 = getelementptr i8, i8* %sunkaddr266, i64 160\n  %84 = bitcast i8* %sunkaddr267 to <4 x double>*\n  store <4 x double> %68, <4 x double>* %84, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr268 = mul i64 %index, 8\n  %85 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr269 = getelementptr i8, i8* %85, i64 %sunkaddr268\n  %sunkaddr270 = getelementptr i8, i8* %sunkaddr269, i64 192\n  %86 = bitcast i8* %sunkaddr270 to <4 x double>*\n  store <4 x double> %70, <4 x double>* %86, align 8, !alias.scope !14, !noalias !16\n  %sunkaddr271 = mul i64 %index, 8\n  %87 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr272 = getelementptr i8, i8* %87, i64 %sunkaddr271\n  %sunkaddr273 = getelementptr i8, i8* %sunkaddr272, i64 224\n  %88 = bitcast i8* %sunkaddr273 to <4 x double>*\n  store <4 x double> %72, <4 x double>* %88, align 8, !alias.scope !14, !noalias !16\n  %index.next.1 = add i64 %index, 32\n  %lsr.iv.next220 = add i64 %lsr.iv219, -2\n  %niter127.ncmp.1 = icmp eq i64 %lsr.iv.next220, 0\n  br i1 %niter127.ncmp.1, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !17\n\nmiddle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph\n  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %vector.body ]\n  %89 = and i64 %51, 1\n  %lcmp.mod125.not = icmp eq i64 %89, 0\n  br i1 %lcmp.mod125.not, label %middle.block, label %vector.body.epil\n\nvector.body.epil:                                 ; preds = %middle.block.unr-lcssa\n  %90 = load double, double* %arg.a.4, align 8, !alias.scope !9\n  %91 = load double, double* %arg.b.4, align 8, !alias.scope !12\n  %.scalar.epil = fadd double %90, %91\n  %92 = insertelement <4 x double> poison, double %.scalar.epil, i64 0\n  %93 = shufflevector <4 x double> %92, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar104.epil = fadd double %90, %91\n  %94 = insertelement <4 x double> poison, double %.scalar104.epil, i64 0\n  %95 = shufflevector <4 x double> %94, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar105.epil = fadd double %90, %91\n  %96 = insertelement <4 x double> poison, double %.scalar105.epil, i64 0\n  %97 = shufflevector <4 x double> %96, <4 x double> poison, <4 x i32> zeroinitializer\n  %.scalar106.epil = fadd double %90, %91\n  %98 = insertelement <4 x double> poison, double %.scalar106.epil, i64 0\n  %99 = shufflevector <4 x double> %98, <4 x double> poison, <4 x i32> zeroinitializer\n  %100 = getelementptr double, double* %.6.i2229, i64 %index.unr\n  %101 = bitcast double* %100 to <4 x double>*\n  store <4 x double> %93, <4 x double>* %101, align 8, !alias.scope !14, !noalias !16\n  %102 = getelementptr double, double* %100, i64 4\n  %103 = bitcast double* %102 to <4 x double>*\n  store <4 x double> %95, <4 x double>* %103, align 8, !alias.scope !14, !noalias !16\n  %104 = getelementptr double, double* %100, i64 8\n  %105 = bitcast double* %104 to <4 x double>*\n  store <4 x double> %97, <4 x double>* %105, align 8, !alias.scope !14, !noalias !16\n  %106 = getelementptr double, double* %100, i64 12\n  %107 = bitcast double* %106 to <4 x double>*\n  store <4 x double> %99, <4 x double>* %107, align 8, !alias.scope !14, !noalias !16\n  br label %middle.block\n\nmiddle.block:                                     ; preds = %middle.block.unr-lcssa, %vector.body.epil\n  %cmp.n = icmp eq i64 %dest_shape.1, %n.vec\n  br i1 %cmp.n, label %for.end, label %for.body.preheader109\n\nfor.body.preheader109:                            ; preds = %vector.memcheck, %for.body.preheader77, %middle.block\n  %loop.index28.ph = phi i64 [ 0, %vector.memcheck ], [ 0, %for.body.preheader77 ], [ %n.vec, %middle.block ]\n  %108 = xor i64 %loop.index28.ph, -1\n  %109 = add i64 %dest_shape.1, %108\n  %xtraiter121 = and i64 %dest_shape.1, 7\n  %lcmp.mod122.not = icmp eq i64 %xtraiter121, 0\n  br i1 %lcmp.mod122.not, label %for.body.prol.loopexit, label %for.body.prol.preheader\n\nfor.body.prol.preheader:                          ; preds = %for.body.preheader109\n  br label %for.body.prol\n\nfor.body.prol:                                    ; preds = %for.body.prol.preheader, %for.body.prol\n  %lsr.iv193 = phi i64 [ %xtraiter121, %for.body.prol.preheader ], [ %lsr.iv.next194, %for.body.prol ]\n  %loop.index28.prol = phi i64 [ %.258.prol, %for.body.prol ], [ %loop.index28.ph, %for.body.prol.preheader ]\n  %.219.prol = load double, double* %arg.a.4, align 8\n  %.229.prol = load double, double* %arg.b.4, align 8\n  %.6.i.prol = fadd double %.219.prol, %.229.prol\n  %scevgep192 = getelementptr double, double* %.6.i2229, i64 %loop.index28.prol\n  store double %.6.i.prol, double* %scevgep192, align 8\n  %.258.prol = add nuw i64 %loop.index28.prol, 1\n  %lsr.iv.next194 = add nsw i64 %lsr.iv193, -1\n  %prol.iter.cmp.not = icmp eq i64 %lsr.iv.next194, 0\n  br i1 %prol.iter.cmp.not, label %for.body.prol.loopexit, label %for.body.prol, !llvm.loop !19\n\nfor.body.prol.loopexit:                           ; preds = %for.body.prol, %for.body.preheader109\n  %loop.index28.unr = phi i64 [ %loop.index28.ph, %for.body.preheader109 ], [ %.258.prol, %for.body.prol ]\n  %110 = icmp ult i64 %109, 7\n  br i1 %110, label %for.end, label %for.body.preheader130\n\nfor.body.preheader130:                            ; preds = %for.body.prol.loopexit\n  br label %for.body\n\nfor.body.us52:                                    ; preds = %for.body.us52, %for.body.us52.preheader.new\n  %lsr.iv166 = phi i64 [ %lsr.iv.next167, %for.body.us52 ], [ %46, %for.body.us52.preheader.new ]\n  %loop.index28.us53 = phi i64 [ 0, %for.body.us52.preheader.new ], [ %.258.us63.3, %for.body.us52 ]\n  %.219.us55 = load double, double* %arg.a.4, align 8\n  %.228.us59 = inttoptr i64 %lsr.iv166 to double*\n  %.229.us60 = load double, double* %.228.us59, align 8\n  %.6.i.us61 = fadd double %.219.us55, %.229.us60\n  %sunkaddr274 = mul i64 %loop.index28.us53, 8\n  %111 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr275 = getelementptr i8, i8* %111, i64 %sunkaddr274\n  %112 = bitcast i8* %sunkaddr275 to double*\n  store double %.6.i.us61, double* %112, align 8\n  %.219.us55.1 = load double, double* %arg.a.4, align 8\n  %113 = add i64 %arg.b.6.0, %lsr.iv166\n  %.228.us59.1 = inttoptr i64 %113 to double*\n  %.229.us60.1 = load double, double* %.228.us59.1, align 8\n  %.6.i.us61.1 = fadd double %.219.us55.1, %.229.us60.1\n  %sunkaddr276 = mul i64 %loop.index28.us53, 8\n  %114 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr277 = getelementptr i8, i8* %114, i64 %sunkaddr276\n  %sunkaddr278 = getelementptr i8, i8* %sunkaddr277, i64 8\n  %115 = bitcast i8* %sunkaddr278 to double*\n  store double %.6.i.us61.1, double* %115, align 8\n  %.219.us55.2 = load double, double* %arg.a.4, align 8\n  %sunkaddr279 = inttoptr i64 %lsr.iv166 to double*\n  %sunkaddr280 = mul i64 %arg.b.6.0, 2\n  %116 = bitcast double* %sunkaddr279 to i8*\n  %sunkaddr281 = getelementptr i8, i8* %116, i64 %sunkaddr280\n  %117 = bitcast i8* %sunkaddr281 to double*\n  %.229.us60.2 = load double, double* %117, align 8\n  %.6.i.us61.2 = fadd double %.219.us55.2, %.229.us60.2\n  %sunkaddr282 = mul i64 %loop.index28.us53, 8\n  %118 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr283 = getelementptr i8, i8* %118, i64 %sunkaddr282\n  %sunkaddr284 = getelementptr i8, i8* %sunkaddr283, i64 16\n  %119 = bitcast i8* %sunkaddr284 to double*\n  store double %.6.i.us61.2, double* %119, align 8\n  %.219.us55.3 = load double, double* %arg.a.4, align 8\n  %120 = add i64 %48, %lsr.iv166\n  %.228.us59.3 = inttoptr i64 %120 to double*\n  %.229.us60.3 = load double, double* %.228.us59.3, align 8\n  %.6.i.us61.3 = fadd double %.219.us55.3, %.229.us60.3\n  %sunkaddr285 = mul i64 %loop.index28.us53, 8\n  %121 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr286 = getelementptr i8, i8* %121, i64 %sunkaddr285\n  %sunkaddr287 = getelementptr i8, i8* %sunkaddr286, i64 24\n  %122 = bitcast i8* %sunkaddr287 to double*\n  store double %.6.i.us61.3, double* %122, align 8\n  %.258.us63.3 = add nuw i64 %loop.index28.us53, 4\n  %lsr.iv.next167 = add i64 %lsr.iv166, %47\n  %niter120.ncmp.3 = icmp eq i64 %unroll_iter119, %.258.us63.3\n  br i1 %niter120.ncmp.3, label %for.end.loopexit108.unr-lcssa, label %for.body.us52\n\nfor.body:                                         ; preds = %for.body.preheader130, %for.body\n  %loop.index28 = phi i64 [ %.258.7, %for.body ], [ %loop.index28.unr, %for.body.preheader130 ]\n  %.219 = load double, double* %arg.a.4, align 8\n  %.229 = load double, double* %arg.b.4, align 8\n  %.6.i = fadd double %.219, %.229\n  %sunkaddr288 = mul i64 %loop.index28, 8\n  %123 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr289 = getelementptr i8, i8* %123, i64 %sunkaddr288\n  %124 = bitcast i8* %sunkaddr289 to double*\n  store double %.6.i, double* %124, align 8\n  %.219.1 = load double, double* %arg.a.4, align 8\n  %.229.1 = load double, double* %arg.b.4, align 8\n  %.6.i.1 = fadd double %.219.1, %.229.1\n  %sunkaddr290 = mul i64 %loop.index28, 8\n  %125 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr291 = getelementptr i8, i8* %125, i64 %sunkaddr290\n  %sunkaddr292 = getelementptr i8, i8* %sunkaddr291, i64 8\n  %126 = bitcast i8* %sunkaddr292 to double*\n  store double %.6.i.1, double* %126, align 8\n  %.219.2 = load double, double* %arg.a.4, align 8\n  %.229.2 = load double, double* %arg.b.4, align 8\n  %.6.i.2 = fadd double %.219.2, %.229.2\n  %sunkaddr293 = mul i64 %loop.index28, 8\n  %127 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr294 = getelementptr i8, i8* %127, i64 %sunkaddr293\n  %sunkaddr295 = getelementptr i8, i8* %sunkaddr294, i64 16\n  %128 = bitcast i8* %sunkaddr295 to double*\n  store double %.6.i.2, double* %128, align 8\n  %.219.3 = load double, double* %arg.a.4, align 8\n  %.229.3 = load double, double* %arg.b.4, align 8\n  %.6.i.3 = fadd double %.219.3, %.229.3\n  %sunkaddr296 = mul i64 %loop.index28, 8\n  %129 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr297 = getelementptr i8, i8* %129, i64 %sunkaddr296\n  %sunkaddr298 = getelementptr i8, i8* %sunkaddr297, i64 24\n  %130 = bitcast i8* %sunkaddr298 to double*\n  store double %.6.i.3, double* %130, align 8\n  %.219.4 = load double, double* %arg.a.4, align 8\n  %.229.4 = load double, double* %arg.b.4, align 8\n  %.6.i.4 = fadd double %.219.4, %.229.4\n  %sunkaddr299 = mul i64 %loop.index28, 8\n  %131 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr300 = getelementptr i8, i8* %131, i64 %sunkaddr299\n  %sunkaddr301 = getelementptr i8, i8* %sunkaddr300, i64 32\n  %132 = bitcast i8* %sunkaddr301 to double*\n  store double %.6.i.4, double* %132, align 8\n  %.219.5 = load double, double* %arg.a.4, align 8\n  %.229.5 = load double, double* %arg.b.4, align 8\n  %.6.i.5 = fadd double %.219.5, %.229.5\n  %sunkaddr302 = mul i64 %loop.index28, 8\n  %133 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr303 = getelementptr i8, i8* %133, i64 %sunkaddr302\n  %sunkaddr304 = getelementptr i8, i8* %sunkaddr303, i64 40\n  %134 = bitcast i8* %sunkaddr304 to double*\n  store double %.6.i.5, double* %134, align 8\n  %.219.6 = load double, double* %arg.a.4, align 8\n  %.229.6 = load double, double* %arg.b.4, align 8\n  %.6.i.6 = fadd double %.219.6, %.229.6\n  %sunkaddr305 = mul i64 %loop.index28, 8\n  %135 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr306 = getelementptr i8, i8* %135, i64 %sunkaddr305\n  %sunkaddr307 = getelementptr i8, i8* %sunkaddr306, i64 48\n  %136 = bitcast i8* %sunkaddr307 to double*\n  store double %.6.i.6, double* %136, align 8\n  %.219.7 = load double, double* %arg.a.4, align 8\n  %.229.7 = load double, double* %arg.b.4, align 8\n  %.6.i.7 = fadd double %.219.7, %.229.7\n  %sunkaddr308 = mul i64 %loop.index28, 8\n  %137 = bitcast double* %.6.i2229 to i8*\n  %sunkaddr309 = getelementptr i8, i8* %137, i64 %sunkaddr308\n  %sunkaddr310 = getelementptr i8, i8* %sunkaddr309, i64 56\n  %138 = bitcast i8* %sunkaddr310 to double*\n  store double %.6.i.7, double* %138, align 8\n  %.258.7 = add nuw nsw i64 %loop.index28, 8\n  %exitcond71.not.7 = icmp eq i64 %dest_shape.1, %.258.7\n  br i1 %exitcond71.not.7, label %for.end, label %for.body, !llvm.loop !21\n\nfor.end.loopexit.unr-lcssa:                       ; preds = %for.body.us.us, %for.body.us.us.preheader\n  %loop.index28.us.us.unr = phi i64 [ 0, %for.body.us.us.preheader ], [ %.258.us.us.3, %for.body.us.us ]\n  %lcmp.mod.not = icmp eq i64 %xtraiter, 0\n  br i1 %lcmp.mod.not, label %for.end, label %for.body.us.us.epil.preheader\n\nfor.body.us.us.epil.preheader:                    ; preds = %for.end.loopexit.unr-lcssa\n  %139 = ptrtoint double* %arg.b.4 to i64\n  %140 = ptrtoint double* %arg.a.4 to i64\n  %scevgep132 = getelementptr double, double* %.6.i2229, i64 %loop.index28.us.us.unr\n  %141 = mul i64 %loop.index28.us.us.unr, %arg.b.6.0\n  %142 = add i64 %139, %141\n  %143 = mul i64 %loop.index28.us.us.unr, %arg.a.6.0\n  %144 = add i64 %140, %143\n  br label %for.body.us.us.epil\n\nfor.body.us.us.epil:                              ; preds = %for.body.us.us.epil.preheader, %for.body.us.us.epil\n  %lsr.iv134 = phi i64 [ %144, %for.body.us.us.epil.preheader ], [ %lsr.iv.next135, %for.body.us.us.epil ]\n  %lsr.iv = phi i64 [ %142, %for.body.us.us.epil.preheader ], [ %lsr.iv.next, %for.body.us.us.epil ]\n  %epil.iter = phi i64 [ %epil.iter.next, %for.body.us.us.epil ], [ 0, %for.body.us.us.epil.preheader ]\n  %.218.us.us.epil = inttoptr i64 %lsr.iv134 to double*\n  %.219.us.us.epil = load double, double* %.218.us.us.epil, align 8\n  %.228.us.us.epil = inttoptr i64 %lsr.iv to double*\n  %.229.us.us.epil = load double, double* %.228.us.us.epil, align 8\n  %.6.i.us.us.epil = fadd double %.219.us.us.epil, %.229.us.us.epil\n  %scevgep133 = getelementptr double, double* %scevgep132, i64 %epil.iter\n  store double %.6.i.us.us.epil, double* %scevgep133, align 8\n  %epil.iter.next = add i64 %epil.iter, 1\n  %lsr.iv.next = add i64 %lsr.iv, %arg.b.6.0\n  %lsr.iv.next135 = add i64 %lsr.iv134, %arg.a.6.0\n  %epil.iter.cmp.not = icmp eq i64 %xtraiter, %epil.iter.next\n  br i1 %epil.iter.cmp.not, label %for.end, label %for.body.us.us.epil, !llvm.loop !22\n\nfor.end.loopexit107.unr-lcssa:                    ; preds = %for.body.us, %for.body.us.preheader\n  %loop.index28.us.unr = phi i64 [ 0, %for.body.us.preheader ], [ %.258.us.3, %for.body.us ]\n  %lcmp.mod113.not = icmp eq i64 %xtraiter111, 0\n  br i1 %lcmp.mod113.not, label %for.end, label %for.body.us.epil.preheader\n\nfor.body.us.epil.preheader:                       ; preds = %for.end.loopexit107.unr-lcssa\n  %145 = ptrtoint double* %arg.a.4 to i64\n  %scevgep148 = getelementptr double, double* %.6.i2229, i64 %loop.index28.us.unr\n  %146 = mul i64 %loop.index28.us.unr, %arg.a.6.0\n  %147 = add i64 %145, %146\n  br label %for.body.us.epil\n\nfor.body.us.epil:                                 ; preds = %for.body.us.epil.preheader, %for.body.us.epil\n  %lsr.iv150 = phi i64 [ %147, %for.body.us.epil.preheader ], [ %lsr.iv.next151, %for.body.us.epil ]\n  %epil.iter112 = phi i64 [ %epil.iter112.next, %for.body.us.epil ], [ 0, %for.body.us.epil.preheader ]\n  %.218.us.epil = inttoptr i64 %lsr.iv150 to double*\n  %.219.us.epil = load double, double* %.218.us.epil, align 8\n  %.229.us.epil = load double, double* %arg.b.4, align 8\n  %.6.i.us.epil = fadd double %.219.us.epil, %.229.us.epil\n  %scevgep149 = getelementptr double, double* %scevgep148, i64 %epil.iter112\n  store double %.6.i.us.epil, double* %scevgep149, align 8\n  %epil.iter112.next = add i64 %epil.iter112, 1\n  %lsr.iv.next151 = add i64 %lsr.iv150, %arg.a.6.0\n  %epil.iter112.cmp.not = icmp eq i64 %xtraiter111, %epil.iter112.next\n  br i1 %epil.iter112.cmp.not, label %for.end, label %for.body.us.epil, !llvm.loop !23\n\nfor.end.loopexit108.unr-lcssa:                    ; preds = %for.body.us52, %for.body.us52.preheader\n  %loop.index28.us53.unr = phi i64 [ 0, %for.body.us52.preheader ], [ %.258.us63.3, %for.body.us52 ]\n  %lcmp.mod118.not = icmp eq i64 %xtraiter116, 0\n  br i1 %lcmp.mod118.not, label %for.end, label %for.body.us52.epil.preheader\n\nfor.body.us52.epil.preheader:                     ; preds = %for.end.loopexit108.unr-lcssa\n  %148 = ptrtoint double* %arg.b.4 to i64\n  %scevgep162 = getelementptr double, double* %.6.i2229, i64 %loop.index28.us53.unr\n  %149 = mul i64 %loop.index28.us53.unr, %arg.b.6.0\n  %150 = add i64 %148, %149\n  br label %for.body.us52.epil\n\nfor.body.us52.epil:                               ; preds = %for.body.us52.epil.preheader, %for.body.us52.epil\n  %lsr.iv164 = phi i64 [ %150, %for.body.us52.epil.preheader ], [ %lsr.iv.next165, %for.body.us52.epil ]\n  %epil.iter117 = phi i64 [ %epil.iter117.next, %for.body.us52.epil ], [ 0, %for.body.us52.epil.preheader ]\n  %.219.us55.epil = load double, double* %arg.a.4, align 8\n  %.228.us59.epil = inttoptr i64 %lsr.iv164 to double*\n  %.229.us60.epil = load double, double* %.228.us59.epil, align 8\n  %.6.i.us61.epil = fadd double %.219.us55.epil, %.229.us60.epil\n  %scevgep163 = getelementptr double, double* %scevgep162, i64 %epil.iter117\n  store double %.6.i.us61.epil, double* %scevgep163, align 8\n  %epil.iter117.next = add i64 %epil.iter117, 1\n  %lsr.iv.next165 = add i64 %lsr.iv164, %arg.b.6.0\n  %epil.iter117.cmp.not = icmp eq i64 %xtraiter116, %epil.iter117.next\n  br i1 %epil.iter117.cmp.not, label %for.end, label %for.body.us52.epil, !llvm.loop !24\n\nfor.end:                                          ; preds = %for.body, %for.body.us52.epil, %for.body.us.epil, %for.body.us.us.epil, %for.body.prol.loopexit, %for.end.loopexit108.unr-lcssa, %for.end.loopexit107.unr-lcssa, %for.end.loopexit.unr-lcssa, %middle.block, %B0.endif.endif.endif.endif.endif.endif\n  %retptr.repack311 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr to i8**\n  store i8* %.7.i.i, i8** %retptr.repack311, align 8\n  %retptr.repack30 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 1\n  store i8* null, i8** %retptr.repack30, align 8\n  %retptr.repack32 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 2\n  store i64 %dest_shape.1, i64* %retptr.repack32, align 8\n  %retptr.repack34 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 3\n  store i64 8, i64* %retptr.repack34, align 8\n  %retptr.repack36 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 4\n  store double* %.6.i2229, double** %retptr.repack36, align 8\n  %151 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 5, i64 0\n  store i64 %dest_shape.1, i64* %151, align 8\n  %152 = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %retptr, i64 0, i32 6, i64 0\n  store i64 8, i64* %152, align 8\n  tail call void @NRT_decref(i8* %arg.b.0)\n  tail call void @NRT_decref(i8* %arg.a.0)\n  br label %common.ret\n}\n\n; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn\ndeclare { i64, i1 } @llvm.smul.with.overflow.i64(i64, i64) #0\n\ndefine i8* @_ZN7cpython8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE(i8* nocapture readnone %py_closure, i8* %py_args, i8* nocapture readnone %py_kws) local_unnamed_addr {\nentry:\n  %.5 = alloca i8*, align 8\n  %.6 = alloca i8*, align 8\n  %.7 = call i32 (i8*, i8*, i64, i64, ...) @PyArg_UnpackTuple(i8* %py_args, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.const.numba_vectorized, i64 0, i64 0), i64 2, i64 2, i8** nonnull %.5, i8** nonnull %.6)\n  %.8 = icmp eq i32 %.7, 0\n  %.22 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  %.45 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  %.67 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  %excinfo = alloca { i8*, i32, i8*, i8*, i32 }*, align 8\n  store { i8*, i32, i8*, i8*, i32 }* null, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8\n  %.131 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  br i1 %.8, label %common.ret, label %entry.endif, !prof !1\n\ncommon.ret:                                       ; preds = %entry.endif.endif.endif.thread, %entry.endif.endif.endif.endif.endif.endif.endif.if.endif, %entry.endif.endif.endif.e...if.1, %entry.endif.endif.endif.e...endif.2.endif, %entry.endif.endif.endif.endif.endif.if, %entry, %entry.endif.endif.endif.e...if, %entry.endif.endif.endif.endif.endif.endif.if.endif.endif, %entry.endif.if\n  %common.ret.op = phi i8* [ null, %entry.endif.if ], [ %.135, %entry.endif.endif.endif.endif.endif.endif.if.endif.endif ], [ null, %entry.endif.endif.endif.e...if ], [ null, %entry ], [ null, %entry.endif.endif.endif.endif.endif.if ], [ null, %entry.endif.endif.endif.e...endif.2.endif ], [ null, %entry.endif.endif.endif.e...if.1 ], [ null, %entry.endif.endif.endif.endif.endif.endif.endif.if.endif ], [ null, %entry.endif.endif.endif.thread ]\n  ret i8* %common.ret.op\n\nentry.endif:                                      ; preds = %entry\n  %.12 = load i8*, i8** @_ZN08NumbaEnv8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE, align 8\n  %.17 = icmp eq i8* %.12, null\n  br i1 %.17, label %entry.endif.if, label %entry.endif.endif, !prof !1\n\nentry.endif.if:                                   ; preds = %entry.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([171 x i8], [171 x i8]* @"".const.missing Environment: _ZN08NumbaEnv8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE"", i64 0, i64 0))\n  br label %common.ret\n\nentry.endif.endif:                                ; preds = %entry.endif\n  %.21 = load i8*, i8** %.5, align 8\n  %.25 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  %0 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 8 dereferenceable(56) %0, i8 0, i64 56, i1 false)\n  %.26 = call i32 @NRT_adapt_ndarray_from_python(i8* %.21, i8* nonnull %.25)\n  %1 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  %sunkaddr = getelementptr inbounds i8, i8* %1, i64 24\n  %2 = bitcast i8* %sunkaddr to i64*\n  %.30 = load i64, i64* %2, align 8\n  %.31 = icmp ne i64 %.30, 8\n  %.32 = icmp ne i32 %.26, 0\n  %.33 = or i1 %.32, %.31\n  br i1 %.33, label %entry.endif.endif.endif.thread, label %entry.endif.endif.endif.endif, !prof !1\n\nentry.endif.endif.endif.thread:                   ; preds = %entry.endif.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_TypeError, i8* getelementptr inbounds ([89 x i8], [89 x i8]* @"".const.can\'t unbox array from PyObject into native value.  The object maybe of a different type"", i64 0, i64 0))\n  br label %common.ret\n\nentry.endif.endif.endif.endif:                    ; preds = %entry.endif.endif\n  %3 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8**\n  %.37.fca.0.load = load i8*, i8** %3, align 8\n  %4 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  %sunkaddr10 = getelementptr inbounds i8, i8* %4, i64 32\n  %5 = bitcast i8* %sunkaddr10 to double**\n  %.37.fca.4.load = load double*, double** %5, align 8\n  %6 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  %sunkaddr11 = getelementptr inbounds i8, i8* %6, i64 40\n  %7 = bitcast i8* %sunkaddr11 to i64*\n  %.37.fca.5.0.load = load i64, i64* %7, align 8\n  %8 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.22 to i8*\n  %sunkaddr12 = getelementptr inbounds i8, i8* %8, i64 48\n  %9 = bitcast i8* %sunkaddr12 to i64*\n  %.37.fca.6.0.load = load i64, i64* %9, align 8\n  %.44 = load i8*, i8** %.6, align 8\n  %.48 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  %10 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 8 dereferenceable(56) %10, i8 0, i64 56, i1 false)\n  %.49 = call i32 @NRT_adapt_ndarray_from_python(i8* %.44, i8* nonnull %.48)\n  %11 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  %sunkaddr13 = getelementptr inbounds i8, i8* %11, i64 24\n  %12 = bitcast i8* %sunkaddr13 to i64*\n  %.53 = load i64, i64* %12, align 8\n  %.54 = icmp ne i64 %.53, 8\n  %.55 = icmp ne i32 %.49, 0\n  %.56 = or i1 %.55, %.54\n  br i1 %.56, label %entry.endif.endif.endif.endif.endif.if, label %entry.endif.endif.endif.endif.endif.endif, !prof !1\n\nentry.endif.endif.endif.endif.endif.if:           ; preds = %entry.endif.endif.endif.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_TypeError, i8* getelementptr inbounds ([89 x i8], [89 x i8]* @"".const.can\'t unbox array from PyObject into native value.  The object maybe of a different type"", i64 0, i64 0))\n  call void @NRT_decref(i8* %.37.fca.0.load)\n  br label %common.ret\n\nentry.endif.endif.endif.endif.endif.endif:        ; preds = %entry.endif.endif.endif.endif\n  %13 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8**\n  %14 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8**\n  %.60.fca.0.load = load i8*, i8** %14, align 8\n  %15 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  %sunkaddr14 = getelementptr inbounds i8, i8* %15, i64 32\n  %16 = bitcast i8* %sunkaddr14 to double**\n  %.60.fca.4.load = load double*, double** %16, align 8\n  %17 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  %sunkaddr15 = getelementptr inbounds i8, i8* %17, i64 40\n  %18 = bitcast i8* %sunkaddr15 to i64*\n  %.60.fca.5.0.load = load i64, i64* %18, align 8\n  %19 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.45 to i8*\n  %sunkaddr16 = getelementptr inbounds i8, i8* %19, i64 48\n  %20 = bitcast i8* %sunkaddr16 to i64*\n  %.60.fca.6.0.load = load i64, i64* %20, align 8\n  %21 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 8 dereferenceable(56) %21, i8 0, i64 56, i1 false)\n  %.75 = call i32 @_ZN8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE({ i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* nonnull %.67, { i8*, i32, i8*, i8*, i32 }** nonnull %excinfo, i8* %.37.fca.0.load, i8* undef, i64 undef, i64 undef, double* %.37.fca.4.load, i64 %.37.fca.5.0.load, i64 %.37.fca.6.0.load, i8* %.60.fca.0.load, i8* undef, i64 undef, i64 undef, double* %.60.fca.4.load, i64 %.60.fca.5.0.load, i64 %.60.fca.6.0.load) #2\n  %.76 = load { i8*, i32, i8*, i8*, i32 }*, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8\n  %.83 = icmp sgt i32 %.75, 0\n  %.84 = select i1 %.83, { i8*, i32, i8*, i8*, i32 }* %.76, { i8*, i32, i8*, i8*, i32 }* undef\n  %.85.fca.0.load = load i8*, i8** %13, align 8\n  %22 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr17 = getelementptr inbounds i8, i8* %22, i64 8\n  %23 = bitcast i8* %sunkaddr17 to i8**\n  %.85.fca.1.load = load i8*, i8** %23, align 8\n  %24 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr18 = getelementptr inbounds i8, i8* %24, i64 16\n  %25 = bitcast i8* %sunkaddr18 to i64*\n  %.85.fca.2.load = load i64, i64* %25, align 8\n  %26 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr19 = getelementptr inbounds i8, i8* %26, i64 24\n  %27 = bitcast i8* %sunkaddr19 to i64*\n  %.85.fca.3.load = load i64, i64* %27, align 8\n  %28 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr20 = getelementptr inbounds i8, i8* %28, i64 32\n  %29 = bitcast i8* %sunkaddr20 to double**\n  %.85.fca.4.load = load double*, double** %29, align 8\n  %30 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr21 = getelementptr inbounds i8, i8* %30, i64 40\n  %31 = bitcast i8* %sunkaddr21 to i64*\n  %.85.fca.5.0.load = load i64, i64* %31, align 8\n  %32 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.67 to i8*\n  %sunkaddr22 = getelementptr inbounds i8, i8* %32, i64 48\n  %33 = bitcast i8* %sunkaddr22 to i64*\n  %.85.fca.6.0.load = load i64, i64* %33, align 8\n  call void @NRT_decref(i8* %.37.fca.0.load)\n  call void @NRT_decref(i8* %.60.fca.0.load)\n  switch i32 %.75, label %entry.endif.endif.endif.endif.endif.endif.endif [\n    i32 -2, label %entry.endif.endif.endif.endif.endif.endif.if.endif\n    i32 0, label %entry.endif.endif.endif.endif.endif.endif.if.endif\n  ]\n\nentry.endif.endif.endif.endif.endif.endif.endif:  ; preds = %entry.endif.endif.endif.endif.endif.endif\n  %34 = icmp sgt i32 %.75, 0\n  br i1 %34, label %entry.endif.endif.endif.endif.endif.endif.endif.if, label %entry.endif.endif.endif.e...endif.2.endif\n\nentry.endif.endif.endif.endif.endif.endif.if.endif: ; preds = %entry.endif.endif.endif.endif.endif.endif, %entry.endif.endif.endif.endif.endif.endif\n  %sunkaddr23 = getelementptr i8, i8* %.12, i64 24\n  %35 = bitcast i8* %sunkaddr23 to i8**\n  %.112 = load i8*, i8** %35, align 8\n  %.116.not = icmp eq i8* %.112, null\n  br i1 %.116.not, label %entry.endif.endif.endif.endif.endif.endif.if.endif.else, label %entry.endif.endif.endif.endif.endif.endif.if.endif.if\n\nentry.endif.endif.endif.endif.endif.endif.if.endif.if: ; preds = %entry.endif.endif.endif.endif.endif.endif.if.endif\n  %.118 = call i8* @PyList_GetItem(i8* nonnull %.112, i64 0)\n  br label %entry.endif.endif.endif.endif.endif.endif.if.endif.endif\n\nentry.endif.endif.endif.endif.endif.endif.if.endif.else: ; preds = %entry.endif.endif.endif.endif.endif.endif.if.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @"".const.`env.consts` is NULL in `read_const`"", i64 0, i64 0))\n  br label %entry.endif.endif.endif.endif.endif.endif.if.endif.endif\n\nentry.endif.endif.endif.endif.endif.endif.if.endif.endif: ; preds = %entry.endif.endif.endif.endif.endif.endif.if.endif.else, %entry.endif.endif.endif.endif.endif.endif.if.endif.if\n  %.113.0 = phi i8* [ %.118, %entry.endif.endif.endif.endif.endif.endif.if.endif.if ], [ null, %entry.endif.endif.endif.endif.endif.endif.if.endif.else ]\n  %36 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8**\n  %.130 = call i8* @numba_unpickle(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.const.pickledata.139583502599616, i64 0, i64 0), i32 32, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.const.pickledata.139583502599616.sha1, i64 0, i64 0))\n  store i8* %.85.fca.0.load, i8** %36, align 8\n  %37 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr24 = getelementptr inbounds i8, i8* %37, i64 8\n  %38 = bitcast i8* %sunkaddr24 to i8**\n  store i8* %.85.fca.1.load, i8** %38, align 8\n  %39 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr25 = getelementptr inbounds i8, i8* %39, i64 16\n  %40 = bitcast i8* %sunkaddr25 to i64*\n  store i64 %.85.fca.2.load, i64* %40, align 8\n  %41 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr26 = getelementptr inbounds i8, i8* %41, i64 24\n  %42 = bitcast i8* %sunkaddr26 to i64*\n  store i64 %.85.fca.3.load, i64* %42, align 8\n  %43 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr27 = getelementptr inbounds i8, i8* %43, i64 32\n  %44 = bitcast i8* %sunkaddr27 to double**\n  store double* %.85.fca.4.load, double** %44, align 8\n  %45 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr28 = getelementptr inbounds i8, i8* %45, i64 40\n  %46 = bitcast i8* %sunkaddr28 to i64*\n  store i64 %.85.fca.5.0.load, i64* %46, align 8\n  %47 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %sunkaddr29 = getelementptr inbounds i8, i8* %47, i64 48\n  %48 = bitcast i8* %sunkaddr29 to i64*\n  store i64 %.85.fca.6.0.load, i64* %48, align 8\n  %.134 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.131 to i8*\n  %.135 = call i8* @NRT_adapt_ndarray_to_python_acqref(i8* nonnull %.134, i8* %.130, i32 1, i32 1, i8* %.113.0)\n  call void @NRT_decref(i8* %.85.fca.0.load)\n  br label %common.ret\n\nentry.endif.endif.endif.endif.endif.endif.endif.if: ; preds = %entry.endif.endif.endif.endif.endif.endif.endif\n  call void @PyErr_Clear()\n  %.143 = load { i8*, i32, i8*, i8*, i32 }, { i8*, i32, i8*, i8*, i32 }* %.84, align 8\n  %.144 = extractvalue { i8*, i32, i8*, i8*, i32 } %.143, 4\n  %.145 = icmp sgt i32 %.144, 0\n  %.148 = extractvalue { i8*, i32, i8*, i8*, i32 } %.143, 0\n  %.150 = extractvalue { i8*, i32, i8*, i8*, i32 } %.143, 1\n  br i1 %.145, label %entry.endif.endif.endif.endif.endif.endif.endif.if.if, label %entry.endif.endif.endif.endif.endif.endif.endif.if.else\n\nentry.endif.endif.endif.endif.endif.endif.endif.if.if: ; preds = %entry.endif.endif.endif.endif.endif.endif.endif.if\n  %.151 = sext i32 %.150 to i64\n  %.152 = call i8* @PyBytes_FromStringAndSize(i8* %.148, i64 %.151)\n  %.153 = load { i8*, i32, i8*, i8*, i32 }, { i8*, i32, i8*, i8*, i32 }* %.84, align 8\n  %.154 = extractvalue { i8*, i32, i8*, i8*, i32 } %.153, 2\n  %.156 = extractvalue { i8*, i32, i8*, i8*, i32 } %.153, 3\n  %.157 = bitcast i8* %.156 to i8* (i8*)*\n  %.158 = call i8* %.157(i8* %.154)\n  %.159 = icmp eq i8* %.158, null\n  br i1 %.159, label %entry.endif.endif.endif.e...if, label %entry.endif.endif.endif.e...endif, !prof !1\n\nentry.endif.endif.endif.endif.endif.endif.endif.if.else: ; preds = %entry.endif.endif.endif.endif.endif.endif.endif.if\n  %.172 = extractvalue { i8*, i32, i8*, i8*, i32 } %.143, 2\n  %.173 = call i8* @numba_unpickle(i8* %.148, i32 %.150, i8* %.172)\n  br label %entry.endif.endif.endif.endif.endif.endif.endif.if.endif\n\nentry.endif.endif.endif.endif.endif.endif.endif.if.endif: ; preds = %entry.endif.endif.endif.e...endif, %entry.endif.endif.endif.endif.endif.endif.endif.if.else\n  %.175 = phi i8* [ %.163, %entry.endif.endif.endif.e...endif ], [ %.173, %entry.endif.endif.endif.endif.endif.endif.endif.if.else ]\n  %.176.not = icmp eq i8* %.175, null\n  br i1 %.176.not, label %common.ret, label %entry.endif.endif.endif.e...if.1, !prof !1\n\nentry.endif.endif.endif.e...if:                   ; preds = %entry.endif.endif.endif.endif.endif.endif.endif.if.if\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @"".const.Error creating Python tuple from runtime exception arguments"", i64 0, i64 0))\n  br label %common.ret\n\nentry.endif.endif.endif.e...endif:                ; preds = %entry.endif.endif.endif.endif.endif.endif.endif.if.if\n  %.163 = call i8* @numba_runtime_build_excinfo_struct(i8* %.152, i8* nonnull %.158)\n  %.164 = bitcast { i8*, i32, i8*, i8*, i32 }* %.84 to i8*\n  call void @NRT_Free(i8* nonnull %.164)\n  br label %entry.endif.endif.endif.endif.endif.endif.endif.if.endif\n\nentry.endif.endif.endif.e...if.1:                 ; preds = %entry.endif.endif.endif.endif.endif.endif.endif.if.endif\n  call void @numba_do_raise(i8* nonnull %.175)\n  br label %common.ret\n\nentry.endif.endif.endif.e...endif.2.endif:        ; preds = %entry.endif.endif.endif.endif.endif.endif.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_SystemError, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @"".const.unknown error when calling native function"", i64 0, i64 0))\n  br label %common.ret\n}\n\ndeclare i32 @PyArg_UnpackTuple(i8*, i8*, i64, i64, ...) local_unnamed_addr\n\ndeclare void @PyErr_SetString(i8*, i8*) local_unnamed_addr\n\ndeclare i32 @NRT_adapt_ndarray_from_python(i8* nocapture, i8* nocapture) local_unnamed_addr\n\ndeclare i8* @PyList_GetItem(i8*, i64) local_unnamed_addr\n\ndeclare i8* @numba_unpickle(i8*, i32, i8*) local_unnamed_addr\n\ndeclare i8* @NRT_adapt_ndarray_to_python_acqref(i8* nocapture, i8*, i32, i32, i8*) local_unnamed_addr\n\ndeclare void @PyErr_Clear() local_unnamed_addr\n\ndeclare i8* @PyBytes_FromStringAndSize(i8*, i64) local_unnamed_addr\n\ndeclare i8* @numba_runtime_build_excinfo_struct(i8*, i8*) local_unnamed_addr\n\ndeclare void @NRT_Free(i8*) local_unnamed_addr\n\ndeclare void @numba_do_raise(i8*) local_unnamed_addr\n\ndeclare void @PyErr_SetNone(i8*) local_unnamed_addr\n\ndefine { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } @cfunc._ZN8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE({ i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.2) local_unnamed_addr {\nentry:\n  %.4 = alloca { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, align 8\n  %.fca.0.gep1 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4 to i8**\n  %.fca.1.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 1\n  %.fca.2.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 2\n  %.fca.3.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 3\n  %.fca.4.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 4\n  %.fca.5.0.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 5, i64 0\n  %.fca.6.0.gep = getelementptr inbounds { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }, { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4, i64 0, i32 6, i64 0\n  %excinfo = alloca { i8*, i32, i8*, i8*, i32 }*, align 8\n  %0 = bitcast { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* %.4 to i8*\n  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 8 dereferenceable(56) %0, i8 0, i64 56, i1 false)\n  store { i8*, i32, i8*, i8*, i32 }* null, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8\n  %extracted.meminfo = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 0\n  %extracted.data = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 4\n  %extracted.shape = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 5\n  %.8 = extractvalue [1 x i64] %extracted.shape, 0\n  %extracted.strides = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.1, 6\n  %.9 = extractvalue [1 x i64] %extracted.strides, 0\n  %extracted.meminfo.1 = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.2, 0\n  %extracted.data.1 = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.2, 4\n  %extracted.shape.1 = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.2, 5\n  %.10 = extractvalue [1 x i64] %extracted.shape.1, 0\n  %extracted.strides.1 = extractvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %.2, 6\n  %.11 = extractvalue [1 x i64] %extracted.strides.1, 0\n  %.12 = call i32 @_ZN8__main__16numba_vectorizedB3v11B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dE5ArrayIdLi1E1A7mutable7alignedE5ArrayIdLi1E1A7mutable7alignedE({ i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] }* nonnull %.4, { i8*, i32, i8*, i8*, i32 }** nonnull %excinfo, i8* %extracted.meminfo, i8* undef, i64 undef, i64 undef, double* %extracted.data, i64 %.8, i64 %.9, i8* %extracted.meminfo.1, i8* undef, i64 undef, i64 undef, double* %extracted.data.1, i64 %.10, i64 %.11) #2\n  %.13 = load { i8*, i32, i8*, i8*, i32 }*, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8\n  %.14.not = icmp eq i32 %.12, 0\n  %.20 = icmp sgt i32 %.12, 0\n  %.21 = select i1 %.20, { i8*, i32, i8*, i8*, i32 }* %.13, { i8*, i32, i8*, i8*, i32 }* undef\n  %.22.fca.0.load = load i8*, i8** %.fca.0.gep1, align 8\n  %.22.fca.1.load = load i8*, i8** %.fca.1.gep, align 8\n  %.22.fca.2.load = load i64, i64* %.fca.2.gep, align 8\n  %.22.fca.3.load = load i64, i64* %.fca.3.gep, align 8\n  %.22.fca.4.load = load double*, double** %.fca.4.gep, align 8\n  %.22.fca.5.0.load = load i64, i64* %.fca.5.0.gep, align 8\n  %.22.fca.6.0.load = load i64, i64* %.fca.6.0.gep, align 8\n  %.28 = insertvalue [1 x i64] poison, i64 %.22.fca.5.0.load, 0\n  %.29 = insertvalue [1 x i64] poison, i64 %.22.fca.6.0.load, 0\n  %inserted.meminfo = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } undef, i8* %.22.fca.0.load, 0\n  %inserted.parent = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.meminfo, i8* %.22.fca.1.load, 1\n  %inserted.nitems = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.parent, i64 %.22.fca.2.load, 2\n  %inserted.itemsize = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.nitems, i64 %.22.fca.3.load, 3\n  %inserted.data = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.itemsize, double* %.22.fca.4.load, 4\n  %inserted.shape = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.data, [1 x i64] %.28, 5\n  %inserted.strides = insertvalue { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %inserted.shape, [1 x i64] %.29, 6\n  %.35 = alloca i32, align 4\n  store i32 0, i32* %.35, align 4\n  br i1 %.14.not, label %common.ret, label %entry.if, !prof !25\n\nentry.if:                                         ; preds = %entry\n  %1 = icmp sgt i32 %.12, 0\n  call void @numba_gil_ensure(i32* nonnull %.35)\n  br i1 %1, label %entry.if.if, label %entry.if.endif\n\ncommon.ret:                                       ; preds = %entry, %.38, %entry.if.if.if.if\n  %common.ret.op = phi { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } [ zeroinitializer, %entry.if.if.if.if ], [ %inserted.strides, %.38 ], [ %inserted.strides, %entry ]\n  ret { i8*, i8*, i64, i64, double*, [1 x i64], [1 x i64] } %common.ret.op\n\n.38:                                              ; preds = %entry.if.endif, %entry.if.if.endif, %entry.if.if.endif.if, %entry.if.endif.endif.endif, %entry.if.endif.if\n  %.86 = call i8* @PyUnicode_FromString(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @"".const.<numba.core.cpu.CPUContext object at 0x7ef28e11a5e0>"", i64 0, i64 0))\n  call void @PyErr_WriteUnraisable(i8* %.86)\n  call void @Py_DecRef(i8* %.86)\n  call void @numba_gil_release(i32* nonnull %.35)\n  br label %common.ret\n\nentry.if.if:                                      ; preds = %entry.if\n  call void @PyErr_Clear()\n  %.41 = load { i8*, i32, i8*, i8*, i32 }, { i8*, i32, i8*, i8*, i32 }* %.21, align 8\n  %.42 = extractvalue { i8*, i32, i8*, i8*, i32 } %.41, 4\n  %.43 = icmp sgt i32 %.42, 0\n  %.46 = extractvalue { i8*, i32, i8*, i8*, i32 } %.41, 0\n  %.48 = extractvalue { i8*, i32, i8*, i8*, i32 } %.41, 1\n  br i1 %.43, label %entry.if.if.if, label %entry.if.if.else\n\nentry.if.endif:                                   ; preds = %entry.if\n  switch i32 %.12, label %entry.if.endif.endif.endif [\n    i32 -3, label %entry.if.endif.if\n    i32 -1, label %.38\n  ]\n\nentry.if.if.if:                                   ; preds = %entry.if.if\n  %.49 = sext i32 %.48 to i64\n  %.50 = call i8* @PyBytes_FromStringAndSize(i8* %.46, i64 %.49)\n  %.51 = load { i8*, i32, i8*, i8*, i32 }, { i8*, i32, i8*, i8*, i32 }* %.21, align 8\n  %.52 = extractvalue { i8*, i32, i8*, i8*, i32 } %.51, 2\n  %.54 = extractvalue { i8*, i32, i8*, i8*, i32 } %.51, 3\n  %.55 = bitcast i8* %.54 to i8* (i8*)*\n  %.56 = call i8* %.55(i8* %.52)\n  %.57 = icmp eq i8* %.56, null\n  br i1 %.57, label %entry.if.if.if.if, label %entry.if.if.if.endif, !prof !1\n\nentry.if.if.else:                                 ; preds = %entry.if.if\n  %.70 = extractvalue { i8*, i32, i8*, i8*, i32 } %.41, 2\n  %.71 = call i8* @numba_unpickle(i8* %.46, i32 %.48, i8* %.70)\n  br label %entry.if.if.endif\n\nentry.if.if.endif:                                ; preds = %entry.if.if.if.endif, %entry.if.if.else\n  %.73 = phi i8* [ %.61, %entry.if.if.if.endif ], [ %.71, %entry.if.if.else ]\n  %.74.not = icmp eq i8* %.73, null\n  br i1 %.74.not, label %.38, label %entry.if.if.endif.if, !prof !1\n\nentry.if.if.if.if:                                ; preds = %entry.if.if.if\n  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @"".const.Error creating Python tuple from runtime exception arguments.1"", i64 0, i64 0))\n  br label %common.ret\n\nentry.if.if.if.endif:                             ; preds = %entry.if.if.if\n  %.61 = call i8* @numba_runtime_build_excinfo_struct(i8* %.50, i8* nonnull %.56)\n  %.62 = bitcast { i8*, i32, i8*, i8*, i32 }* %.21 to i8*\n  call void @NRT_Free(i8* nonnull %.62)\n  br label %entry.if.if.endif\n\nentry.if.if.endif.if:                             ; preds = %entry.if.if.endif\n  call void @numba_do_raise(i8* nonnull %.73)\n  br label %.38\n\nentry.if.endif.if:                                ; preds = %entry.if.endif\n  call void @PyErr_SetNone(i8* nonnull @PyExc_StopIteration)\n  br label %.38\n\nentry.if.endif.endif.endif:                       ; preds = %entry.if.endif\n  call void @PyErr_SetString(i8* nonnull @PyExc_SystemError, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @"".const.unknown error when calling native function.2"", i64 0, i64 0))\n  br label %.38\n}\n\ndeclare void @numba_gil_ensure(i32*) local_unnamed_addr\n\ndeclare i8* @PyUnicode_FromString(i8*) local_unnamed_addr\n\ndeclare void @PyErr_WriteUnraisable(i8*) local_unnamed_addr\n\ndeclare void @Py_DecRef(i8*) local_unnamed_addr\n\ndeclare void @numba_gil_release(i32*) local_unnamed_addr\n\ndeclare noalias i8* @NRT_MemInfo_alloc_aligned(i64, i32) local_unnamed_addr\n\n; Function Attrs: mustprogress nofree noinline norecurse nounwind willreturn\ndefine linkonce_odr void @NRT_incref(i8* %.1) local_unnamed_addr #1 {\n.3:\n  %.4 = icmp eq i8* %.1, null\n  br i1 %.4, label %common.ret, label %.3.endif, !prof !1\n\ncommon.ret:                                       ; preds = %.3.endif, %.3\n  ret void\n\n.3.endif:                                         ; preds = %.3\n  %.7 = bitcast i8* %.1 to i64*\n  %.4.i = atomicrmw add i64* %.7, i64 1 monotonic, align 8\n  br label %common.ret\n}\n\n; Function Attrs: noinline\ndefine linkonce_odr void @NRT_decref(i8* %.1) local_unnamed_addr #2 {\n.3:\n  %.4 = icmp eq i8* %.1, null\n  br i1 %.4, label %common.ret1, label %.3.endif, !prof !1\n\ncommon.ret1:                                      ; preds = %.3, %.3.endif\n  ret void\n\n.3.endif:                                         ; preds = %.3\n  fence release\n  %.8 = bitcast i8* %.1 to i64*\n  %.4.i = atomicrmw sub i64* %.8, i64 1 monotonic, align 8\n  %.10 = icmp eq i64 %.4.i, 1\n  br i1 %.10, label %.3.endif.if, label %common.ret1, !prof !1\n\n.3.endif.if:                                      ; preds = %.3.endif\n  fence acquire\n  tail call void @NRT_MemInfo_call_dtor(i8* nonnull %.1)\n  ret void\n}\n\ndeclare void @NRT_MemInfo_call_dtor(i8*) local_unnamed_addr\n\n; Function Attrs: argmemonly nofree nounwind willreturn writeonly\ndeclare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #3\n\nattributes #0 = { mustprogress nofree nosync nounwind readnone speculatable willreturn }\nattributes #1 = { mustprogress nofree noinline norecurse nounwind willreturn }\nattributes #2 = { noinline }\nattributes #3 = { argmemonly nofree nounwind willreturn writeonly }\n\n!0 = !{i1 true}\n!1 = !{!""branch_weights"", i32 1, i32 99}\n!2 = !{!3, !5, !6, !8}\n!3 = distinct !{!3, !4, !""_ZN5numba2np8arrayobj18_ol_array_allocate12_3clocals_3e4implB2v4B42c8tJTIeFIjxB2IKSgI4CrvQClcaMQ5hEEUSJJgA_3dEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj: %retptr""}\n!4 = distinct !{!4, !""_ZN5numba2np8arrayobj18_ol_array_allocate12_3clocals_3e4implB2v4B42c8tJTIeFIjxB2IKSgI4CrvQClcaMQ5hEEUSJJgA_3dEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj""}\n!5 = distinct !{!5, !4, !""_ZN5numba2np8arrayobj18_ol_array_allocate12_3clocals_3e4implB2v4B42c8tJTIeFIjxB2IKSgI4CrvQClcaMQ5hEEUSJJgA_3dEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj: %excinfo""}\n!6 = distinct !{!6, !7, !""_ZN5numba2np8arrayobj15_call_allocatorB2v3B42c8tJTC_2fWQA93W1AaAIYBPIqRBFCjDSZRVAJmaQIAEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj: %retptr""}\n!7 = distinct !{!7, !""_ZN5numba2np8arrayobj15_call_allocatorB2v3B42c8tJTC_2fWQA93W1AaAIYBPIqRBFCjDSZRVAJmaQIAEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj""}\n!8 = distinct !{!8, !7, !""_ZN5numba2np8arrayobj15_call_allocatorB2v3B42c8tJTC_2fWQA93W1AaAIYBPIqRBFCjDSZRVAJmaQIAEN29typeref_5b_3cclass_20_27numba4core5types8npytypes14Array_27_3e_5dExj: %excinfo""}\n!9 = !{!10}\n!10 = distinct !{!10, !11}\n!11 = distinct !{!11, !""LVerDomain""}\n!12 = !{!13}\n!13 = distinct !{!13, !11}\n!14 = !{!15}\n!15 = distinct !{!15, !11}\n!16 = !{!10, !13}\n!17 = distinct !{!17, !18}\n!18 = !{!""llvm.loop.isvectorized"", i32 1}\n!19 = distinct !{!19, !20}\n!20 = !{!""llvm.loop.unroll.disable""}\n!21 = distinct !{!21, !18}\n!22 = distinct !{!22, !20}\n!23 = distinct !{!23, !20}\n!24 = distinct !{!24, !20}\n!25 = !{!""branch_weights"", i32 99, i32 1}\n'}"
