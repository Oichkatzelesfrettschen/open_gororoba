# Canonical TOML dataset migrated from legacy CSV.
# Generated by src/scripts/analysis/migrate_legacy_csv_to_toml.py

[dataset]
id = "LC-0025"
slug = "expanded_workstation_gpu_coverage_2007_2017"
source_csv = "data/csv/legacy/Expanded_Workstation_GPU_Coverage__2007-2017_.csv"
source_sha256 = "fb32b7391c4aef03ec377136ca593fc50428a69cbc2ed46e5cea3fb883f100a1"
source_size_bytes = 858
has_header = true
delimiter = ","
quotechar = "\""
row_count = 12
column_count = 5
header_value_sha256 = "16e9b9d4ff338a013618514679dffa19295fa262639e0f210ba9d6ac761a9e79"
row_value_sha256 = "954568ff4d380da44698f3029482ccc2f294212e4eea80b84f06b9cabd5812b8"
migrated_on = "2026-02-09"
migrated_by = "src/scripts/analysis/migrate_legacy_csv_to_toml.py"

header = [
  "gpu_model",
  "compute_capability",
  "cuda_toolkit_max_support",
  "fp64_performance_tflops",
  "best_workstation_use_in_2025",
]

original_header = [
  "GPU Model",
  "Compute Capability",
  "CUDA Toolkit Max Support",
  "FP64 Performance (TFLOPS)",
  "Best Workstation Use in 2025",
]

rows = [
  ["Quadro FX 5600 (2007)", "1.1", "6.5", "0.09", "Legacy CAD, OpenGL rendering"],
  ["Quadro FX 5800 (2008)", "1.3", "6.5", "0.2", "Scientific Visualization"],
  ["Tesla C1060 (2008)", "1.3", "6.5", "0.3", "Early HPC compute workloads"],
  ["Quadro 6000 (2010)", "2.0", "8.0", "0.5", "Legacy AI inference, OpenGL CAD"],
  ["Tesla C2050 (2010)", "2.0", "8.0", "0.5", "Legacy CUDA HPC"],
  ["Tesla K20 (2012)", "3.5", "10.2", "1.2", "FP64-intensive scientific computing"],
  ["Quadro K5000 (2012)", "3.5", "10.2", "1.4", "Workstation OpenGL, DirectX 11 CAD"],
  ["Tesla K80 (2014)", "3.7", "11.0", "2.9", "Entry-level AI acceleration, HPC"],
  ["Quadro M6000 (2015)", "5.2", "11.2", "3.0", "Deep learning inference, CUDA 11"],
  ["Tesla M40 (2015)", "5.2", "11.2", "3.5", "Modern HPC, physics simulations"],
  ["Quadro P6000 (2017)", "6.1", "11.8", "4.5", "AI/ML training, CUDA acceleration"],
  ["Tesla P100 (2017)", "6.0", "11.8", "5.3", "Best AI/HPC compute"],
]

[[column]]
index = 1
name = "gpu_model"
original_name = "GPU Model"
inferred_type = "string"
non_empty_count = 12
empty_count = 0

[[column]]
index = 2
name = "compute_capability"
original_name = "Compute Capability"
inferred_type = "float"
non_empty_count = 12
empty_count = 0

[[column]]
index = 3
name = "cuda_toolkit_max_support"
original_name = "CUDA Toolkit Max Support"
inferred_type = "float"
non_empty_count = 12
empty_count = 0

[[column]]
index = 4
name = "fp64_performance_tflops"
original_name = "FP64 Performance (TFLOPS)"
inferred_type = "float"
non_empty_count = 12
empty_count = 0

[[column]]
index = 5
name = "best_workstation_use_in_2025"
original_name = "Best Workstation Use in 2025"
inferred_type = "string"
non_empty_count = 12
empty_count = 0
