# Entrypoint markdown registry (TOML-first).
# Generated by src/scripts/analysis/normalize_entrypoint_docs_registry.py

[entrypoint_docs]
authoritative = true
updated = "2026-02-09"
document_count = 8

[[document]]
path = "AGENTS.md"
title = "Agent and Contributor Operating Manual"
body_markdown = '''
# Agent and Contributor Operating Manual

This is the canonical policy and operating contract for all assistants and
human contributors in this repository.

If any instruction in `CLAUDE.md` or `GEMINI.md` conflicts with this file,
`AGENTS.md` wins.

## 1. File Roles and Authority

| File | Role | Edit policy |
|---|---|---|
| `AGENTS.md` | Global policy and repo `/init` procedure | Canonical, tracked |
| `CLAUDE.md` | Claude-specific overlay | Tracked, must defer to `AGENTS.md` |
| `GEMINI.md` | Gemini-specific overlay | Tracked, must defer to `AGENTS.md` |
| `README.md` | Human-facing repo entrypoint | Tracked |
| `registry/*.toml` | Canonical machine-readable knowledge state | Canonical, tracked |
| `docs/**/*.md` | Generated mirrors and narrative exports | Generated, not canonical |

## 2. Repo Identity and Scope

open_gororoba is a research workbench centered on reproducible algebra,
physics, and data workflows with a Rust-first architecture.

Primary code surfaces:
- Rust workspace under `crates/`
- Python support layer under `src/gemini_physics/`
- Verification scripts under `src/verification/`
- Registry authority under `registry/`

Research claims are hypotheses unless backed by:
1. first-party source citation, and
2. reproducible in-repo verification path.

## 3. Non-Negotiable Hard Rules

### 3.1 ASCII-only
- All repo-authored code and docs must be ASCII-only.
- Exception: immutable transcripts under `convos/`.
- Validate with: `make ascii-check`

### 3.2 Warnings-as-errors
- Python checks and tests must run with `PYTHONWARNINGS=error`.
- Rust lint must pass with `-D warnings`.
- Treat all warnings as failures.

### 3.3 TOML-first documentation
- Authoritative state lives in `registry/*.toml`.
- Canonical data storage is TOML-only for raw, analyzed, narrative, equation,
  and planning artifacts.
- HDF5 or any other non-TOML format is export/projection only and must be
  generated from canonical TOML sources via Rust or approved tooling.
- Markdown in `docs/`, `reports/`, and `data/artifacts/` is generated or mirror
  output and is never the authoritative source.
- Do not treat mirrors as authoritative.
- Any new in-scope markdown file must have an explicit canonical TOML owner in
  `registry/markdown_owner_map.toml` and generated provenance headers.
- Unmapped in-scope markdown is a hard failure via:
  `PYTHONWARNINGS=error make registry-verify-markdown-owner`.

### 3.4 Source-first claims discipline
- Do not treat narrative text as proof.
- Every claim should be falsifiable and tied to verifiable evidence.

### 3.5 Provenance and reproducibility
- No large opaque binary commits.
- Track external data provenance and hashes.
- Tests must not rely on network.

### 3.6 Build profile parity and optimization discipline
- Keep dev, test, and production build semantics as aligned as feasible.
- Allowed profile divergence is limited to debug info and essential test harness
  instrumentation.
- Enforce warnings-as-errors in development and CI.
- Release optimization baseline is native CPU tuning with fat LTO; maintain a
  PGO-capable lane for final production calibration.

## 4. `/init` Procedure (Mandatory Session Startup)

Every agent session should follow this exact initialization flow.

1. Establish repo context
   - confirm cwd is repo root
   - capture branch, commit, and worktree status

2. Detect pre-existing local changes
   - list modified, staged, untracked files
   - never silently revert existing user changes

3. Load canonical policy and active objectives
   - read `AGENTS.md`
   - read current objective-relevant registry files

4. Validate toolchain readiness
   - check Python and Rust toolchain availability
   - confirm `make` targets are discoverable

5. Build a task plan before wide edits
   - define scoped tasks with dependencies
   - identify owner for each task when delegating to sub-agents

6. Choose execution lane
   - lane A: code and tests
   - lane B: registry and docs pipeline
   - lane C: data/provenance workflows

7. Execute with quality gates
   - run targeted checks as changes land
   - run final validation commands before commit

8. Close loop
   - update registry state first
   - regenerate mirrors
   - summarize outcomes and residual risk

## 5. Skills and Agent Delegation Protocol

### 5.1 Skills
- If a task matches an available skill, use it.
- Read only required sections of the skill file.
- Reuse skill scripts/assets instead of rewriting from scratch.
- If skill is unavailable, report and use best fallback.

### 5.2 Delegation
- Delegate only when it improves speed or quality.
- Assign explicit ownership by file or subsystem.
- Keep one integrator agent responsible for final merge and validation.
- Parallelize independent workstreams (search, audit, static reads).

### 5.3 Ownership handoff format
- Scope: what this agent owns
- Inputs: files and assumptions
- Outputs: expected artifacts
- Validation: commands/tests agent must run

## 6. MCP and CLI Tool Orchestration

Preferred order:
1. MCP filesystem/ripgrep/git tools for deterministic local operations
2. shell commands for build/test execution
3. network tools only when required by objective

Rules:
- Use ripgrep for repo search.
- Parallelize independent reads/searches.
- Avoid destructive git commands unless explicitly requested.
- Do not bypass reproducibility gates to speed up progress.

## 7. Task Tracking and Planning Workflow

Canonical planning state is TOML-first:
- `registry/roadmap.toml`
- `registry/todo.toml`
- `registry/next_actions.toml`

Narrative overlays:
- `registry/roadmap_narrative.toml`
- `registry/todo_narrative.toml`
- `registry/next_actions_narrative.toml`

Generated mirrors:
- `docs/ROADMAP.md`
- `docs/TODO.md`
- `docs/NEXT_ACTIONS.md`

Update policy:
1. update registry TOML first
2. regenerate mirrors
3. validate freshness checks

## 8. TOML-first Documentation Lifecycle

### 8.1 Canonical registries
- claims: `registry/claims.toml`
- insights: `registry/insights.toml`
- experiments: `registry/experiments.toml`
- binaries: `registry/binaries.toml`
- requirements: `registry/requirements.toml`
- narrative corpora:
  - `registry/docs_root_narratives.toml`
  - `registry/research_narratives.toml`
  - `registry/external_sources.toml`
  - `registry/data_artifact_narratives.toml`
  - `registry/reports_narratives.toml`
  - `registry/docs_convos.toml`
  - `registry/book_docs.toml`
- canonical legacy CSV data:
  - `registry/legacy_csv_datasets.toml`
  - `registry/data/legacy_csv/*.toml`
  - `registry/csv_inventory.toml`
- markdown ownership and origin governance:
  - `registry/markdown_owner_map.toml`
  - `registry/markdown_origin_audit.toml`
  - `registry/markdown_inventory.toml`
- CSV scroll lanes:
  - `registry/project_csv_split_policy.toml`
  - `registry/project_csv_canonical_datasets.toml`
  - `registry/project_csv_generated_artifacts.toml`
  - `registry/external_csv_holding_datasets.toml`
  - `registry/archive_csv_holding_datasets.toml`

### 8.2 Build and publish flow
- Validate data canon:
  - `PYTHONWARNINGS=error make registry-data`
- Validate markdown ownership gate:
  - `PYTHONWARNINGS=error make registry-verify-markdown-owner`
- Validate CSV corpus lane coverage:
  - `PYTHONWARNINGS=error make registry-verify-csv-corpus-coverage`
- Validate registries:
  - `PYTHONWARNINGS=error make registry`
- Publish mirrors:
  - `PYTHONWARNINGS=error make docs-publish`

### 8.3 Mirror discipline
- Generated markdown mirrors are read-only outputs.
- Never edit generated mirrors as source.
- If mirror content is wrong, fix source TOML and regenerate.

## 9. LLM Overlay Files Contract

`CLAUDE.md` and `GEMINI.md` must contain:
- assistant-specific operating notes
- `/init` quick checklist aligned with this file
- tool orchestration notes specific to that runtime

They must not:
- redefine hard rules
- override TOML-first policy
- carry stale numeric counts that drift from registry truth

## 10. Requirements and Navigator Policy

### 10.1 Requirements
- Canonical source:
  - `registry/requirements.toml`
  - `registry/requirements_narrative.toml`
- Generated outputs:
  - `REQUIREMENTS.md`
  - `docs/REQUIREMENTS.md`
  - `docs/requirements/*.md`

### 10.2 Navigator
- Navigator content must be managed TOML-first.
- Any `NAVIGATOR.md` output is a generated projection, not canonical source.

## 11. Validation Gate Checklist Before Commit

Run relevant gates for touched surfaces:

Core:
- `PYTHONWARNINGS=error make check`
- `make ascii-check`

Registry/docs:
- `PYTHONWARNINGS=error make registry-data`
- `PYTHONWARNINGS=error make registry-verify-markdown-owner`
- `PYTHONWARNINGS=error make registry-verify-csv-corpus-coverage`
- `PYTHONWARNINGS=error make registry`
- `PYTHONWARNINGS=error make docs-publish`

Rust-focused changes:
- `cargo build --workspace -j$(nproc)`
- `cargo test --workspace -j$(nproc)`
- `cargo clippy --workspace -j$(nproc) -- -D warnings`

If full gates are too expensive for iteration, run targeted checks while coding
and full gates before final handoff.

## 12. Quickstart Command Block

```bash
# Data canon + registry authority and mirror publish
PYTHONWARNINGS=error make registry-data
# Registry authority and mirror publish
PYTHONWARNINGS=error make registry
PYTHONWARNINGS=error make docs-publish

# Full quality gate
PYTHONWARNINGS=error make check
make ascii-check

# Rust strict gate
cargo build --workspace -j$(nproc)
cargo test --workspace -j$(nproc)
cargo clippy --workspace -j$(nproc) -- -D warnings
```

## 13. References

- `README.md` - human-facing entrypoint
- `CLAUDE.md` - Claude overlay
- `GEMINI.md` - Gemini overlay
- `Makefile` - build, registry, docs-publish targets
- `src/scripts/analysis/export_registry_markdown_mirrors.py` - mirror exporter
- `src/verification/verify_registry_mirror_freshness.py` - freshness gate
- `src/scripts/analysis/migrate_legacy_csv_to_toml.py` - legacy CSV canonicalizer
- `src/verification/verify_legacy_csv_toml_parity.py` - CSV parity/fidelity verifier
- `src/verification/verify_markdown_owner_map.py` - markdown owner mapping gate
- `src/verification/verify_csv_corpus_coverage.py` - CSV zone coverage gate
- `registry/` - canonical machine-readable project state

## 14. Rust-Maximal and PyO3 Bridge Policy (Appended)

This section is append-only and clarifies the intended long-term architecture:
maximize Rust for domain logic, and route Python through PyO3 bindings.

### 14.1 Rust-maximal implementation policy
- Rust-maximal execution is the default architecture policy for this repository.
- Every Python core algorithm MUST have a mapped Rust crate target and a PyO3 binding plan in registry TOML before merge.
- New production computation should be implemented in Rust workspace crates.
- Python-only implementations of core numerical or physics logic are not a final
  state and must be treated as transitional.
- If logic affects claims/evidence outputs, canonical implementation belongs in Rust.

### 14.2 Python usage policy via PyO3
- Python integration should call Rust through `crates/gororoba_py`.
- Python code may orchestrate workflows, visualization, and notebook ergonomics,
  but heavy computation and canonical algorithms should execute in Rust.
- When Python is necessary, wire bindings so Python and Rust use one shared
  implementation path instead of duplicated logic.

### 14.3 Wiring and acceptance requirements
- Expose Rust APIs with stable typed inputs/outputs and deterministic behavior.
- Bind APIs in `gororoba_py` with explicit function/class docs and error mapping.
- Add parity tests where feasible:
  - Rust-side tests for core behavior.
  - Python-side tests that call PyO3 bindings and validate expected outputs.
- Do not maintain divergent equation/model implementations in both Python and
  Rust without an explicit migration plan.

### 14.4 Transitional exceptions and migration discipline
- Existing Python verification/orchestration scripts can remain during migration.
- For each Python-heavy module retained, track:
  - target Rust crate/module,
  - binding plan in `gororoba_py`,
  - validation and parity criteria,
  - migration status in TOML planning registries.
- Migration work should preserve reproducibility and warnings-as-errors gates.

### 14.5 Recommended validation lane for Rust+PyO3 changes
- Rust quality:
  - `cargo build --workspace -j$(nproc)`
  - `cargo test --workspace -j$(nproc)`
  - `cargo clippy --workspace -j$(nproc) -- -D warnings`
- Python binding lane (when touched):
  - `PYTHONWARNINGS=error make test`
  - targeted tests invoking `gororoba_py` bindings
- Registry/documentation lane:
  - update canonical TOML first, then regenerate optional projections as needed.

### 14.6 Hard verifier and canonical mapping registry
- Canonical mapping registry:
  - `registry/python_core_algorithms.toml`
- Hard gate verifier:
  - `PYTHONWARNINGS=error python3 src/verification/verify_python_core_algorithms_pyo3.py`
  - `PYTHONWARNINGS=error make verify-python-core-algorithms`
- Enforcement rule:
  - any new in-scope Python core algorithm file must have a mapping entry with:
    - `rust_crate`
    - `rust_module`
    - `pyo3_binding_plan` (must reference `gororoba_py`)
    - valid `binding_status` token
'''

[[document]]
path = "CLAUDE.md"
title = "Claude Overlay for open_gororoba"
body_markdown = '''
# Claude Overlay for open_gororoba

This file is a Claude-specific overlay.
Global policy is canonical in `AGENTS.md`.

## 1. Authority and Scope

- Read `AGENTS.md` first in every session.
- If this file conflicts with `AGENTS.md`, follow `AGENTS.md`.
- Use this file only for Claude runtime behavior and execution style.

## 2. Claude `/init` Checklist

Run this sequence at session start:

1. repo state
   - branch, commit, worktree status
2. policy and objective load
   - open `AGENTS.md`
   - open objective-relevant registry TOML files
3. quality gate baseline
   - plan to run `PYTHONWARNINGS=error make registry-data`
   - plan to run `PYTHONWARNINGS=error make registry`
   - plan to run `PYTHONWARNINGS=error make docs-publish` when docs are touched
4. task plan
   - create explicit step list with dependencies
   - choose what can run in parallel

## 3. Claude Execution Contract

### 3.1 Planning and tracking
- Use granular task tracking for multi-step work.
- Keep implementation tied to registry-first updates.
- Close each task with validation evidence.

### 3.2 Skills usage
- If a listed skill matches the request, use it.
- Read only needed sections of the skill.
- Prefer skill scripts/templates over ad hoc reimplementation.

### 3.3 Agent delegation
- Delegate independent workstreams with explicit ownership.
- Require delegates to report:
  - files touched
  - commands run
  - unresolved risks

### 3.4 MCP orchestration defaults
- Prefer deterministic local tools:
  - filesystem ops via MCP
  - search via ripgrep
  - git state via git tools
- Parallelize independent searches and file reads.

## 4. TOML-first Documentation Rules

- Update authoritative `registry/*.toml` first.
- Treat markdown mirrors as generated outputs.
- Do not hand-edit generated mirrors to fix content.
- Regenerate mirrors after registry changes.

Core commands:

```bash
PYTHONWARNINGS=error make registry-data
PYTHONWARNINGS=error make registry
PYTHONWARNINGS=error make docs-publish
make ascii-check
```

## 5. Output and Handoff Standard

For every substantive task, provide:
- what changed
- why it changed
- what was validated
- what remains open

Use precise file references and include command outcomes in summary form.
'''

[[document]]
path = "GEMINI.md"
title = "Gemini Overlay for open_gororoba"
body_markdown = '''
# Gemini Overlay for open_gororoba

This file is a Gemini-specific overlay.
Global policy is canonical in `AGENTS.md`.

## 1. Authority and Scope

- Start with `AGENTS.md`.
- Use this file for Gemini runtime specifics only.
- If conflict exists, `AGENTS.md` is authoritative.

## 2. Gemini `/init` Checklist

1. capture repo state
   - branch, commit, worktree status
2. load canonical workflow
   - open `AGENTS.md`
   - open relevant `registry/*.toml` sources
3. establish quality-gate plan
   - `PYTHONWARNINGS=error make registry-data`
   - `PYTHONWARNINGS=error make registry`
   - `PYTHONWARNINGS=error make docs-publish` for docs pipeline work
4. build execution plan
   - define tasks, dependencies, and validation points

## 3. Gemini Execution Contract

### 3.1 Planner and tracker discipline
- Maintain explicit stepwise plan for multi-stage work.
- Track status transitions clearly.
- Keep todo and roadmap updates TOML-first.

### 3.2 Skills and tools
- Use matching skills when available.
- Prefer deterministic local MCP tools for file/search/git operations.
- Run parallel operations only when tasks are independent.

### 3.3 Delegation and integration
- Delegate work by subsystem boundaries.
- Require delegated reports with:
  - touched files
  - checks executed
  - blocking issues
- Integrate centrally and re-validate before completion.

## 4. TOML-first Documentation and Mirror Policy

- Canonical source is `registry/*.toml`.
- Markdown outputs are generated mirrors.
- Edit source TOML, then regenerate.

Core commands:

```bash
PYTHONWARNINGS=error make registry-data
PYTHONWARNINGS=error make registry
PYTHONWARNINGS=error make docs-publish
make ascii-check
```

## 5. Handoff Standard

Every final handoff should include:
- implemented changes
- validation evidence
- unresolved risks
- next recommended steps
'''

[[document]]
path = "README.md"
title = "Gemini Experiments: Evidence-First Algebra/Physics Sandbox"
body_markdown = '''
# Gemini Experiments: Evidence-First Algebra/Physics Sandbox

This repository is a research-style sandbox focused on reproducible, offline-checkable
math/physics experiments (with a heavy emphasis on Cayley-Dickson algebras and related
computational invariants).

Repo policy: treat narrative text as hypotheses unless it is backed by a primary source and
an in-repo check (test/verifier/script + artifact).

## Start here

- Canonical source of truth: `registry/*.toml` (authoring happens here)
- Generate docs mirrors for browsing: `PYTHONWARNINGS=error make docs-publish`
- Validate TOML registries only (no mirror tracking required): `PYTHONWARNINGS=error make registry`
- Navigator authority: `registry/navigator.toml` (generated view: `NAVIGATOR.md`)

README entry points (tracked and maintained):

- Contributor/agent contract: `AGENTS.md`
- Assistant compatibility shim: `CLAUDE.md`
- Assistant compatibility shim: `GEMINI.md`
- Curated datasets and theory index: `curated/README.md`
- Coq workflow entrypoint: `curated/01_theory_frameworks/README_COQ.md`
- Artifact conventions and provenance policy: `data/artifacts/README.md`
- CSV data conventions: `data/csv/README.md`

Quick commands:

- Full gate (tests + lint + verifiers): `PYTHONWARNINGS=error make check`
- Verification-only gate (no artifact generation): `PYTHONWARNINGS=error make smoke`
- Registry-only gate (TOML authority): `PYTHONWARNINGS=error make registry`
- Publish docs mirrors from TOML registries: `PYTHONWARNINGS=error make docs-publish`
- Full gate, parallel pytest workers (opt-in): `PYTHONWARNINGS=error make check-parallel`
- Tests only, parallel pytest workers (opt-in): `PYTHONWARNINGS=error make test-parallel`
- Opt-in experiments/simulations smoke: `PYTHONWARNINGS=error make experiments-smoke`
- Opt-in offline experiments suite (slower): `PYTHONWARNINGS=error make experiments`
- Opt-in metadata hygiene reports: `PYTHONWARNINGS=error make metadata-hygiene`
- Opt-in audit bundle (structure/network/pythonpath/provenance): `PYTHONWARNINGS=error make audits`
- Generate selected artifacts (optional): `make artifacts-motifs`, `make artifacts-materials`, `make artifacts-gwtc3`
- Run network-using artifact targets explicitly (opt-in): `GEMINI_ALLOW_NETWORK=1 make artifacts-net`

## What is in this repo

- Algebra engine and invariants under `src/gemini_physics/` (validated by tests under `tests/`)
- Offline-quality gates under `src/verification/`
- Script entrypoints under `src/scripts/` (some require opt-in network access; see Makefile targets)
- Cached external sources under `data/external/` with a local provenance registry

## Notes

- ASCII-only: repo-authored docs/code should remain ASCII-only (immutable transcripts under `convos/` are exempt).
- Warnings-as-errors: run checks/tests with `PYTHONWARNINGS=error` to catch fragile imports and deprecations early.
- Parallel tests + GPU notes: `docs/COMPUTING_SPECS.md`
- Naming: repo title is "Gemini Experiments"; the Python package name is `gemini-experiments` (see `pyproject.toml`).

### Artifact: Annotated Grand Warp Ring
- File: `data/artifacts/images/warp_ring_annotated.png` (~1.5 MB)
- SHA256: `b5e2fe84c603ea0d9b56d90c2472d859925e7b123a0326e46a9816b70245bf58`
- Summary: Publication-ready annotated visualization combining volumetric Sedenion glow with refractive starfield lensing; includes scale bar (10 Planck Lengths), callouts (Metamaterial Ergoregion, Sedenion ZD Projection), and legend (Toroidal Alcubierre metric, S16 algebra).
'''

[[document]]
path = "curated/README.md"
title = "Curated Artifacts (Legacy / Mixed Provenance)"
body_markdown = '''
# Curated Artifacts (Legacy / Mixed Provenance)

`curated/` is a legacy artifact store that predates the repo's current reproducibility guardrails.
It contains a **mix** of:

- reproducible outputs produced by scripts under `src/` (usually plots/CSVs written into `curated/`)
- AI-generated / hand-edited tables that are **not** currently tied to generating code

Treat anything in `curated/` as **non-authoritative** unless it is:
1) generated by a committed script, and
2) validated by tests or a verifier under `src/verification/`.

## Provenance snapshot

- `curated/PROVENANCE.local.json` records SHA256 + size + mtime for every file currently under `curated/`.
  This supports "what changed?" audits but does **not** by itself establish scientific provenance.

## Directory notes

- `curated/01_theory_frameworks/`: Coq stubs + theory-adjacent artifacts (many CSVs are not yet reproducible).
- `curated/02_simulations_pde_quantum/`: simulation/plot artifacts (some scripts write here, but most CSVs
  are not yet backed by validated models).
- `curated/03_benchmarks_numeric/`: numeric benchmark tables (largely not yet reproducible).
- `curated/04_observational_datasets/`: "observational" CSVs (requires cross-checking against first-party sources).
- `curated/05_summaries_indexes/`: summary/index artifacts.
'''

[[document]]
path = "curated/01_theory_frameworks/README_COQ.md"
title = "Coq Proofs: The Computational Substrate"
body_markdown = '''
# Coq Proofs: The Computational Substrate

## Overview
These `.v` files (`confine_theorems_*.v`) are a **large inventory of theorem statements** about a
proposed "Discrete Causal Lattice" model (threads, rights, delegation).

Important: the `confine_theorems_*.v` files in this repo currently contain **statements only** (no
definitions and no proofs). The `make coq` workflow compiles a generated "axioms" version of these
statements so that the Coq toolchain can at least typecheck the declarations and keep the interface
stable while proper proofs are developed.

## Physical Interpretation
While phrased in Computer Science terms ("Threads", "Rights"), this model corresponds to a **Discrete Spacetime** where:
*   **Thread** = A Point in Spacetime (Event).
*   **Send/Receive** = Causal Connection (Light Cone).
*   **Right/Grant** = Conservation of Information (No Signaling Condition).

## Lacunae & Resolution
*   **Original Claim**: These proofs verify "Quantum Gravity".
*   **Correction**: At present, they do **not** provide such proofs. They are a structured set of claims
    that would need (1) a formal model and (2) actual proofs.

### Build / typecheck
Run:
```bash
make coq
```

This generates `confine_theorems_*_axioms.v` (ignored by git) and compiles them with Coq.

## Next Steps
To make this physically rigorous, we define the mapping:
$$ \text{Thread}_i \leftrightarrow x^\mu_i \in \mathcal{M} $$
$$ \text{reachable}(i, j) \iff \Delta s^2_{ij} \ge 0 $$
'''

[[document]]
path = "data/csv/README.md"
title = "Data Index: CSV Datasets"
body_markdown = '''
# Data Index: CSV Datasets

This directory contains raw output from various simulation runs and theoretical models related to the Surreal-Noncommutative Quantum Gravity project.

## 1. Simulation Outputs (Active)
*   **`sedenion_field_metrics_3d.csv`**: Time-series data from `src/sedenion_field_sim.py`. Tracks `mean_associator` (non-associativity magnitude) and `mean_energy` over time in a 3D Sedenion field.
*   **`modular_chaos_N*.csv`**: Entropy evolution data from `src/modular_classical_sim.py` for different Hilbert space sizes $N$.
*   **`nonlocal_ZZ_slopes.csv`**: (Hypothetical/To-Be-Generated) Slope data from nonlocal spin chain runs.

## 2. Legacy/Static Data (Contextual)
*   **`Zero-Divisor_Adjacency_Matrix__*.csv`**: Adjacency lists for the zero-divisor graphs of Sedenions (16D), Pathions (32D), and Chingons (64D).
*   **`Spectrum_*.csv`**: Various FFT and spectral analysis dumps from previous "Gemini" sessions (e.g., `fft_2d_spectrum.csv`).
*   **`Refined_*.csv`**: Post-processed datasets from earlier "Refinement" phases.

## 3. Missing Metadata (Gaps)
*   **Units**: Most files lack headers specifying physical units (e.g., $t$ in seconds vs steps).
*   **Parameters**: Filenames often don't capture full parameter sets (e.g., coupling constants $J$, \alpha$). Use the corresponding `src/` scripts to trace provenance.
'''

[[document]]
path = "data/artifacts/README.md"
title = "README"
body_markdown = '''
data/artifacts conventions
=========================

This tree stores generated (derived) outputs. It is distinct from:
- data/external/: cached third-party inputs (with provenance).
- data/csv/: small, shareable derived tables (some are also artifacts).

Path convention
---------------

All artifacts should live under:

data/artifacts/<domain>/<name>.<ext>

Examples:
- data/artifacts/images/foo.png
- data/artifacts/manufacturing/bom.csv
- data/artifacts/reports/summary.md

This convention keeps outputs discoverable and enables automated hygiene checks.

Artifact manifest
-----------------

The file data/artifacts/ARTIFACTS_MANIFEST.csv is a small, explicit index of
artifacts that are referenced by canonical docs/verifiers.

Verifier:
- src/verification/verify_artifacts_manifest.py

Provenance sidecars
-------------------

Some artifacts are required to include a provenance sidecar:

<artifact>.<ext>.PROVENANCE.json

Example:
data/artifacts/images/foo.png.PROVENANCE.json

Schema (minimal):
- provenance_version: 1
- artifact_path: "data/artifacts/<domain>/<name>.<ext>"
- generator: path to the generating script (usually under src/scripts/)
- inputs: list of input paths (strings)
- parameters: JSON object (dict) of relevant knobs

Notes:
- Sidecars are intended to be stable and offline-checkable.
- Full reproducibility also depends on pinned externals under data/external/ and
  deterministic generator code paths.

Reorganization planning (safe, phase-gated)
-------------------------------------------

Historical artifacts may exist directly under data/artifacts/ (flat layout).
Do not move these casually. Use the opt-in plan and Phase 0 mover:

- Plan: `make artifacts-reorg-plan` -> reports/artifacts_reorg_plan.md
- Phase 0 dry-run: `make artifacts-phase0-dry`
- Phase 0 apply: `make artifacts-phase0-apply`
- Phase 0 rollback: `make artifacts-phase0-rollback LOG=reports/artifacts_phase0_moves_<ts>.json`

Phase 0 is intentionally conservative: it moves only artifacts that are both
unreferenced (by repo text) and unmanifested (not listed in ARTIFACTS_MANIFEST.csv).

Phase 1 (suggested):
- For artifacts that ARE referenced but not yet in ARTIFACTS_MANIFEST.csv, prefer
  adding them to the manifest first (no moves). This makes references auditable
  before any path changes.
- If the artifact is high-value, add a .PROVENANCE.json sidecar (inputs, generator,
  parameters) before relocating.

Phase 2 (suggested):
- Only after Phase 1 coverage exists, migrate referenced artifacts into
  data/artifacts/<domain>/... and update ALL references (docs, scripts, tests).
- Consider keeping a short "compatibility window" by leaving copies at old paths
  temporarily, but avoid long-lived duplication.
'''
