# Experiments registry -- strict TOML schema (Wave 5 batch 4).
# Generated by src/scripts/analysis/build_wave5_batch4_registries.py.

[experiments]
updated = "2026-02-10"
authoritative = true
experiment_count = 27
deterministic_count = 13
gpu_count = 1
seeded_count = 9
status_allowlist = ["active", "deprecated", "planned", "blocked"]

[[experiment]]
id = "E-001"
title = "Cayley-Dickson Motif Census"
binary = "motif-census"
binary_registered = true
binary_experiment_declared = "E-001"
method = "Exact enumeration of connected-component structure of diagonal zero-product graph for cross-assessor pairs at each CD doubling (dim=16,32,64,128,256)."
input = "None (purely algebraic)"
output = ["data/csv/motif_census_dim{N}.csv", "data/csv/motif_census_summary.csv"]
run = "cargo run --release --bin motif-census -- --dims 16,32,64,128,256 --details"
run_command_sha256 = "0ed18c7e96c0fdb05e6cddfe47a84d53d2e3541ba5afffac75daff84def69e53"
claims = ["C-100", "C-101", "C-102", "C-103", "C-104", "C-105", "C-106", "C-107", "C-108", "C-109", "C-110"]
claim_refs = ["C-100", "C-101", "C-102", "C-103", "C-104", "C-105", "C-106", "C-107", "C-108", "C-109", "C-110"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-001"
input_path_refs = []
output_path_refs = ["data/csv/motif_census_dim{N}.csv", "data/csv/motif_census_summary.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-002"
title = "Multi-Dataset GPU Ultrametric Sweep"
binary = "multi-dataset-ultrametric"
binary_registered = true
binary_experiment_declared = "E-002"
method = "For 9 catalogs: normalize, compute Euclidean distances, ultrametric fraction test with column-shuffled null. 10M triples x 1000 permutations. BH-FDR correction."
input = "data/external/ (CHIME/FRB, ATNF, GWOSC, Pantheon+, Gaia DR3, SDSS DR18, Fermi GBM, Hipparcos, McGill)"
output = ["data/csv/c071g_multi_dataset_ultrametric.csv"]
run = "cargo run --release --bin multi-dataset-ultrametric -- --explore --n-triples 10000000 --n-permutations 1000"
run_command_sha256 = "e59ef06282507cc0fb1674275f790190b68117da9cd1d56c88234535d1be4d23"
claims = ["C-071", "C-436", "C-437", "C-438", "C-439", "C-440"]
claim_refs = ["C-071", "C-436", "C-437", "C-438", "C-439", "C-440"]
deterministic = false
seed = 42
gpu = true
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-002"
input_path_refs = ["data/external/"]
output_path_refs = ["data/csv/c071g_multi_dataset_ultrametric.csv"]
dataset_refs = ["PC-0017"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-003"
title = "Real Cosmological Fit (Pantheon+ / DESI BAO)"
binary = "real-cosmo-fit"
binary_registered = true
binary_experiment_declared = "E-003"
method = "Joint chi-square over 1578 Pantheon+ SNe + 7 DESI DR1 BAO bins. Analytic M_B marginalization. Nelder-Mead. Lambda-CDM vs w0-CDM via delta-BIC."
input = "data/external/Pantheon+SH0ES.dat"
output = ["stdout"]
run = "cargo run --release --bin real-cosmo-fit"
run_command_sha256 = "419b37ec0b4ed9616f8b4a6b9a8a61ab46d40205ddffb339284c5068b95d4197"
claims = ["C-200", "C-201", "C-202", "C-203", "C-204", "C-205", "C-206", "C-207", "C-208", "C-209", "C-210"]
claim_refs = ["C-200", "C-201", "C-202", "C-203", "C-204", "C-205", "C-206", "C-207", "C-208", "C-209", "C-210"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-003"
input_path_refs = ["data/external/Pantheon+SH0ES.dat"]
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-004"
title = "Kerr Shadow Boundaries"
binary = "kerr-shadow"
binary_registered = true
binary_experiment_declared = "E-004"
method = "Bardeen shadow boundary (alpha, beta) for Kerr BH at given spin and inclination."
input = "None (analytic)"
output = ["stdout or --output file"]
run = "cargo run --release --bin kerr-shadow -- --spin 0.998 --n-points 1000 --inclination 17"
run_command_sha256 = "b8cceed694706bbb72a5d18f683846dd723aec40790c7c35c9f340318dc94182"
claims = ["C-301", "C-302", "C-303", "C-304", "C-305", "C-306", "C-307", "C-308", "C-309", "C-310"]
claim_refs = ["C-301", "C-302", "C-303", "C-304", "C-305", "C-306", "C-307", "C-308", "C-309", "C-310"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-004"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-005"
title = "Zero-Divisor Graph Invariants"
binary = "zd-search"
binary_registered = true
binary_experiment_declared = "E-005"
method = "Build sedenion ZD interaction graph, compute graph-theoretic invariants. Extend to dim=32."
input = "None (purely algebraic)"
output = ["stdout"]
run = "cargo run --release --bin zd-search -- --dim 16 --max-pairs 5000"
run_command_sha256 = "cc836cab950db27c227d6bd4407dfb5e5b4fccc93ecc7b5f96c6c38599781254"
claims = ["C-050", "C-051", "C-052", "C-053", "C-054", "C-055", "C-056", "C-057", "C-058", "C-059", "C-060"]
claim_refs = ["C-050", "C-051", "C-052", "C-053", "C-054", "C-055", "C-056", "C-057", "C-058", "C-059", "C-060"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-005"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-006"
title = "Gravastar TOV Parameter Sweep"
binary = "gravastar-sweep"
binary_registered = true
binary_experiment_declared = "E-006"
method = "Solve TOV for three-layer gravastar across polytropic indices and target masses."
input = "None (parametric sweep)"
output = ["data/csv/gravastar_sweep.csv"]
run = "cargo run --release --bin gravastar-sweep -- --n-gamma 32 --n-mass 32 --output data/csv/gravastar_sweep.csv"
run_command_sha256 = "cb2d95828c12d251641f827220bf3295a0efc4cdbaabb7ca8591ed31a2150b32"
claims = ["C-400", "C-401", "C-402", "C-403", "C-404", "C-405", "C-406", "C-407", "C-408", "C-409", "C-410"]
claim_refs = ["C-400", "C-401", "C-402", "C-403", "C-404", "C-405", "C-406", "C-407", "C-408", "C-409", "C-410"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-006"
input_path_refs = []
output_path_refs = ["data/csv/gravastar_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-007"
title = "Tensor Network / PEPS Entropy"
binary = "tensor-network"
binary_registered = true
binary_experiment_declared = "E-007"
method = "Classical tensor network simulator: Bell/GHZ states, random circuits, SVD entropy, PEPS boundary MPS."
input = "None (synthetic circuits)"
output = ["data/csv/entropy_scaling.csv"]
run = "cargo run --release --bin tensor-network -- scaling --n-min 2 --n-max 12 --output data/csv/entropy_scaling.csv"
run_command_sha256 = "3bdfb56d9470cbd4e3ab78c30ba39b3c9fdb08c6f24f5bbdb0f8b6e1d07d265b"
claims = ["C-350", "C-351", "C-352", "C-353", "C-354", "C-355", "C-356", "C-357", "C-358", "C-359", "C-360"]
claim_refs = ["C-350", "C-351", "C-352", "C-353", "C-354", "C-355", "C-356", "C-357", "C-358", "C-359", "C-360"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-007"
input_path_refs = []
output_path_refs = ["data/csv/entropy_scaling.csv"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-008"
title = "GWTC-3 Mass Clumping (Dip Test)"
binary = "mass-clumping"
binary_registered = true
binary_experiment_declared = "E-008"
method = "Hartigan dip test for multimodality of BBH mass distribution. Permutation-based p-value."
input = "data/external/gwosc_all_events.csv"
output = ["data/csv/gwtc3_mass_clumping_dip.csv"]
run = "cargo run --release --bin mass-clumping -- --n-permutations 10000 --seed 42"
run_command_sha256 = "ed3c2b072a68930190dad3e602856382bddef01b367b2addb6806c8893fb39f9"
claims = ["C-007"]
claim_refs = ["C-007"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-008"
input_path_refs = ["data/external/gwosc_all_events.csv"]
output_path_refs = ["data/csv/gwtc3_mass_clumping_dip.csv"]
dataset_refs = ["PC-0044"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-009"
title = "Negative-Dimension Eigenvalue Convergence"
binary = "neg-dim-eigen"
binary_registered = true
binary_experiment_declared = "E-009"
method = "Eigenvalues of H = T(k) + V(x) with fractional kinetic operator, imaginary-time evolution, epsilon->0 sweep."
input = "None (parametric)"
output = ["data/csv/neg_dim_convergence.csv"]
run = "cargo run --release --bin neg-dim-eigen -- sweep --alpha -1.5 --eps-start 0.5 --eps-end 0.01 --eps-steps 20 --output data/csv/neg_dim_convergence.csv"
run_command_sha256 = "2bf71ceb3ae9163bb4c2ffefdebf1c52eb9e054be93459f046faa5ebff6dd81d"
claims = ["C-420", "C-421", "C-422", "C-423", "C-424", "C-425"]
claim_refs = ["C-420", "C-421", "C-422", "C-423", "C-424", "C-425"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-009"
input_path_refs = []
output_path_refs = ["data/csv/neg_dim_convergence.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-010"
title = "Materials Science Baselines (JARVIS + AFLOW)"
binary = "materials-baseline"
binary_registered = true
binary_experiment_declared = "E-010"
method = "JARVIS-DFT and AFLOW datasets, Magpie-style featurization, OLS regression for formation energy and band gap."
input = "data/external/ (JARVIS JSON, AFLOW CSV)"
output = ["stdout"]
run = "cargo run --release --bin materials-baseline -- --data-dir data/external --seed 42"
run_command_sha256 = "35772f3c6cc257b32ee9edea6e592050bb8c803cc6a01a1f3e22d5b377a395ee"
claims = []
claim_refs = []
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-010"
input_path_refs = ["data/external/"]
output_path_refs = []
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-011"
title = "Cross-Stack Locality Comparison (Experiment A)"
binary = "cross-stack-locality"
binary_registered = true
binary_experiment_declared = "E-011"
method = "Compare adjacency-locality metrics across three independent constraint systems: Stack 1 (E10 Billiard): Wall-transition sequence from HyperbolicBilliard, E10 Dynkin graph. Metric: r_e8 = fraction of consecutive pairs that are E8-adjacent. Null: ColumnIndependentNull (uniform random generator selection). Stack 2 (ET DMZ Walk): Navigation sequences through de Marrais Emanation Table. Metric: r_dmz = fraction of consecutive ET cells that share a DMZ edge. Null: uniform random cell selection in the ET grid. Stack 3 (CD ZD Catamaran/Twist): Twist-product navigation across zero-divisor graph. Metric: r_zd = fraction of consecutive basis-pair transitions that are ZD-adjacent. Null: uniform random basis-pair selection. All three use the common abstract model: generator-driven piecewise geodesic dynamics (generator set G, constraint graph Gamma subset G x G, sequence s_1..s_n, locality ratio r = |{i : (s_i, s_{i+1}) in Gamma}| / (n-1)). Prediction (ALP, C-476): all three r values significantly exceed their nulls. Falsifier: one or more shows r consistent with uniform/random."
input = "None (purely algebraic / simulation)"
output = ["data/csv/cross_stack_locality_comparison.csv"]
run = "cargo run --release --bin cross-stack-locality -- --n-bounces 10000 --n-permutations 1000 --seed 42"
run_command_sha256 = "43d8015e68ae9ead4fc208d09f43bbef2a64890082224cf3529e6463dca298df"
claims = ["C-476"]
claim_refs = ["C-476"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-011"
input_path_refs = []
output_path_refs = ["data/csv/cross_stack_locality_comparison.csv"]
dataset_refs = ["PC-0033"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-012"
title = "ET Discrete Billiard (Experiment B)"
binary = "et-billiard"
binary_registered = true
binary_experiment_declared = "E-012"
method = "Treat the Emanation Table as a discrete billiard wall set. Walls: ET constraints define forbidden/allowed transitions in (S, row, col) space. Reflections: when a trajectory hits an ET \"wall\" (DMZ boundary), apply the ET rule update (fill/hide involution or strut-constant increment). Symbolic dynamics: record the sequence of wall types hit (DMZ, label-line, empty). Phase structure: compute Lyapunov exponent (or mixing time) as a function of strut constant S. Compare against spectroscopy band classification (Dense/Sparse/Mixed from spectroscopy_bands()). Prediction: spectroscopy band transitions correspond to qualitative phase changes in the toy billiard (e.g., Dense bands -> low Lyapunov, Sparse -> high Lyapunov). Falsifier: no correlation between spectroscopy classification and billiard dynamics."
input = "None (ET computation from emanation.rs)"
output = ["data/csv/et_billiard_phase_structure.csv"]
run = "cargo run --release --bin et-billiard -- --n-levels 4,5,6 --n-steps 10000 --seed 42"
run_command_sha256 = "486e4fdc996d9d591999f9b99f4fb913d77e4e05f0e8ee177561695f6116e5fc"
claims = ["C-476", "C-477"]
claim_refs = ["C-476", "C-477"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-012"
input_path_refs = []
output_path_refs = ["data/csv/et_billiard_phase_structure.csv"]
dataset_refs = ["PC-0034"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-013"
title = "Sky-Limit-Set Correspondence (Experiment C)"
binary = "sky-limit-set"
binary_registered = true
binary_experiment_declared = "E-013"
method = "Compare ET skybox pattern invariants to Coxeter group limit set invariants. Step 1: For each CD level N=4,5,6, compute the skybox (G x G grid) and extract: - box-kite count (= N-1) - emptiness clustering exponent (connected-component size distribution) - DMZ density (fraction of cells that are DMZ) - fill/hide period-doubling structure (from Four Corners rule) Step 2: For candidate Coxeter groups (A_{N-1}, B_{N-1}, D_{N-1}), compute limit set invariants from the Coxeter matrix: - rank - fractal dimension of limit set - invariant measure density Step 3: Compare skybox invariants (Step 1) to limit set invariants (Step 2) via correlation and matching tests. Prediction (C-477): systematic correspondence between skybox pattern invariants and Coxeter limit set invariants at matching rank. Falsifier: no Coxeter group at any rank produces invariants matching the ET skybox."
input = "None (ET computation + Coxeter matrix computation)"
output = ["data/csv/sky_limit_set_comparison.csv"]
run = "cargo run --release --bin sky-limit-set -- --n-levels 4,5,6 --coxeter-types A,B,D"
run_command_sha256 = "37973a488de5e55a2b2de39142b5f51c3bfaf4ba184779a2c13fe48ace1022bf"
claims = ["C-477"]
claim_refs = ["C-477"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-013"
input_path_refs = []
output_path_refs = ["data/csv/sky_limit_set_comparison.csv"]
dataset_refs = ["PC-0058"]
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-014"
title = "Dimensional Ladder APT Census (4D-4096D)"
binary = "dimensional-census"
binary_registered = true
binary_experiment_declared = ""
method = "Exhaustive and Monte Carlo Anti-Diagonal Parity Theorem verification across the full Cayley-Dickson dimensional ladder from dim=4 to dim=4096. Exhaustive mode: Enumerate ALL graph triangles in each zero-divisor component. For each triangle (a,b,c), compute eta via anti-diagonal parity formula: eta(a,b) = psi(lo_a, hi_b) XOR psi(hi_a, lo_b). Classify as pure (eta constant across 3 edges) or mixed (eta non-constant). Verify 1:3 pure:mixed ratio (Quarter Rule: pure*4 = total exactly). Verify Klein-four fiber symmetry: F(0,0) = F(0,1) = F(1,0) = F(1,1). Monte Carlo mode: Rejection-sample random node triples within components, accept only graph triangles (all 3 edges present), classify via APT. Deterministic with seed=42. Tier classification: dims 4-32 (TIER 0-1, <15s), dims 64-256 (TIER 2, ~5s release), dims 512-1024 (TIER 3, minutes-hours CPU), dims 2048-4096 (TIER 4, GPU Monte Carlo)."
input = "None (Cayley-Dickson structure tables computed on the fly)"
output = ["data/csv/apt_dimensional_census_summary.csv", "data/csv/apt_dimensional_census_details.csv"]
run = "cargo run --release --bin dimensional-census -- --slow --details"
run_command_sha256 = "ed72a3d2f1cac08e2a1787c6be706b5db2bda1acf02bb0f493ebc7107a7cd1be"
claims = ["C-570", "C-571", "C-572"]
claim_refs = ["C-570", "C-571", "C-572"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-014"
input_path_refs = []
output_path_refs = ["data/csv/apt_dimensional_census_summary.csv", "data/csv/apt_dimensional_census_details.csv"]
dataset_refs = ["PC-0002"]
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-015"
title = "GF(2) Separating Degree Formula Verification (dim 32-256)"
binary = "dimensional-census"
binary_registered = true
binary_experiment_declared = ""
method = "For each Cayley-Dickson dimension d in {32, 64, 128, 256}, compute the minimum-degree GF(2) polynomial that separates all motif classes in PG(log2(d)-2, 2). Uses greedy partition refinement for d=256 where brute-force is infeasible (16 classes, C(127,6) candidate tuples). Verifies the formula min_degree = log2(d) - 2 at each step."
input = "None (Cayley-Dickson structure tables computed on the fly)"
output = ["data/csv/separating_degree_formula_sweep.csv"]
run = "cargo test -p algebra_core --release --lib -- test_separating_degree_formula_universality --nocapture"
run_command_sha256 = "14fdeb04854fd5796e3e9e39d81ec504b61eb83076dad30cc7813352db6c7dd0"
claims = ["C-599", "C-600"]
claim_refs = ["C-599", "C-600"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-015"
input_path_refs = []
output_path_refs = ["data/csv/separating_degree_formula_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-016"
title = "A-infinity Homotopy Gravastar Obstruction Sweep"
binary = "gravastar-sweep"
binary_registered = true
binary_experiment_declared = "E-006"
method = "Construct a SedenionAInfinity algebra (m_2=CD product, m_3=associator) and compute the obstruction norm (Frobenius / dim^{3/2}). Map obstruction to Bowers-Liang anisotropy parameter lambda via linear coupling. Sweep coupling from 0 to 0.5 and solve the anisotropic gravastar TOV equation at each point to find the stability window."
input = "None (sedenion structure table + polytropic EOS computed on the fly)"
output = ["data/csv/gravastar_homotopy_obstruction_sweep.csv"]
run = "cargo test -p cosmology_core --release --lib -- homotopy_bridge --nocapture"
run_command_sha256 = "6d651a60d2cb84e45516b04ae4ec34d4552d8a8b1d5daadecafea37d50a8c41e"
claims = ["C-611", "C-612", "C-613", "C-614", "C-615"]
claim_refs = ["C-611", "C-612", "C-613", "C-614", "C-615"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-016"
input_path_refs = []
output_path_refs = ["data/csv/gravastar_homotopy_obstruction_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-017"
title = "7-Clique Multi-Resonator Entropy Trap Simulation"
binary = "entropy-trap"
binary_registered = false
binary_experiment_declared = ""
method = "Build a 7-channel TCMT multi-resonator system from sedenion box-kite components. Each channel is an independent KerrCavity with resonance frequency offset by the component index. Verify zero crosstalk for uncoupled channels, compute per-channel Shannon entropy and pairwise mutual information via 2D histogram binning, and sweep absorption spectrum across all 7 resonance frequencies."
input = "None (box-kite structure + normalized cavity parameters computed on the fly)"
output = ["data/csv/entropy_trap_7clique_absorption.csv", "data/csv/entropy_trap_7clique_summary.csv"]
run = "cargo test -p optics_core --release --lib -- entropy_trap --nocapture"
run_command_sha256 = "c1503da87e9b62691b7bbbaef9e04ac5610189a651a087c403289b9eb7ed05af"
claims = ["C-616", "C-617", "C-618", "C-619", "C-620"]
claim_refs = ["C-616", "C-617", "C-618", "C-619", "C-620"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-017"
input_path_refs = []
output_path_refs = ["data/csv/entropy_trap_7clique_absorption.csv", "data/csv/entropy_trap_7clique_summary.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-018"
title = "He-4 BEC Thermodynamics and Two-Fluid Dynamics"
binary = "he4-superfluid"
binary_registered = false
binary_experiment_declared = ""
method = "Compute ideal BEC critical temperature via zeta(3/2) formula, verify condensate fraction law 1-(T/T_c)^(3/2), validate Landau superfluid density fraction with exponent 5.6, and simulate 0D two-fluid relaxation dynamics using RK4 with relaxation timescales tau_rho = 1 us, tau_t = 100 us. Verify mass conservation, equilibrium relaxation, and thermal relaxation through the lambda transition."
input = "None (physical constants for He-4 at SVP)"
output = ["data/csv/he4_bec_condensate_fraction.csv", "data/csv/he4_two_fluid_evolution.csv"]
run = "cargo test -p quantum_core --release --lib -- superfluid --nocapture && cargo test -p quantum_core --release --lib -- two_fluid --nocapture"
run_command_sha256 = "62f72266ac1433acefee385a9b6f1c1706d540133379667da1f4ff09a1cbed02"
claims = ["C-621", "C-622", "C-623", "C-624", "C-625", "C-626", "C-627"]
claim_refs = ["C-621", "C-622", "C-623", "C-624", "C-625", "C-626", "C-627"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-018"
input_path_refs = []
output_path_refs = ["data/csv/he4_bec_condensate_fraction.csv", "data/csv/he4_two_fluid_evolution.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-019"
title = "Gross-Pitaevskii Ground State and Vortex Calculation"
binary = "he4-superfluid"
binary_registered = false
binary_experiment_declared = ""
method = "Solve the Gross-Pitaevskii equation using Strang split-operator method with FFT-based kinetic evolution. Compute ground states via imaginary-time propagation in a harmonic trap (omega=1), verifying energy recovery E=omega/2 for the linear case (g=0). Test that repulsive interactions (g=50) raise the energy above the linear value. Verify norm preservation during real-time evolution and density centering on the trap."
input = "None (harmonic trap potential, interaction parameter g)"
output = ["data/csv/he4_gpe_ground_state.csv"]
run = "cargo test -p quantum_core --release --lib -- gross_pitaevskii --nocapture"
run_command_sha256 = "9d692c6f364deae518f59c30c209f2abd7665638dd3bdfe8fad8fa9e9de75e3a"
claims = ["C-628", "C-629"]
claim_refs = ["C-628", "C-629"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-019"
input_path_refs = []
output_path_refs = ["data/csv/he4_gpe_ground_state.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-021"
title = "Tessarines vs. Mixed-Quaternions Categorical Distinction Census"
binary = ""
binary_registered = false
binary_experiment_declared = ""
method = ""
input = ""
output = []
run = ""
run_command_sha256 = "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
claims = []
claim_refs = []
deterministic = false
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-020"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "non_deterministic"

[[experiment]]
id = "E-022"
title = "Albert Algebra Commutativity and Exceptional Structure Census"
binary = ""
binary_registered = false
binary_experiment_declared = ""
method = ""
input = ""
output = []
run = ""
run_command_sha256 = "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
claims = []
claim_refs = []
deterministic = false
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-021"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "non_deterministic"

[[experiment]]
id = "E-023"
title = "Composition Algebra Taxonomy: Two-Axis Classification Framework"
binary = ""
binary_registered = false
binary_experiment_declared = ""
method = ""
input = ""
output = []
run = ""
run_command_sha256 = "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
claims = []
claim_refs = []
deterministic = false
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-022"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "non_deterministic"

[[experiment]]
id = "E-024"
title = "Registry Event Tracking Infrastructure"
binary = ""
binary_registered = false
binary_experiment_declared = ""
method = ""
input = ""
output = []
run = ""
run_command_sha256 = "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
claims = []
claim_refs = []
deterministic = false
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-023"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "non_deterministic"

[[experiment]]
id = "E-026"
title = "Third-Party Source Verification Infrastructure"
binary = ""
binary_registered = false
binary_experiment_declared = ""
method = ""
input = ""
output = []
run = ""
run_command_sha256 = "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
claims = []
claim_refs = []
deterministic = false
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-024"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "non_deterministic"

[[experiment]]
id = "E-027"
title = "Topology-Frustration Correlation via Persistent Homology (Thesis 1)"
binary = "e027-topology-analyzer"
binary_registered = true
binary_experiment_declared = ""
method = "VR persistent homology on velocity point cloud, CD psi-weighted triangle frustration, Pearson correlation + Fisher-Yates permutation test"
input = "Synthetic Poiseuille+vortex velocity field, SedenionField with random perturbation"
output = ["data/e027/e027_topology_NNNcubed.toml", "data/e027/betti_timeseries_NNNcubed.csv"]
run = "cargo run --bin e027-topology-analyzer -- --grid-size 16 --epsilon-steps 20 --max-points 100 --n-permutations 200"
run_command_sha256 = "1617ab44c55daf1fcca751119a46a33df1682dfe8c4972a30b0b9aa896e49ee0"
claims = ["C-657", "C-658", "C-659"]
claim_refs = ["C-657", "C-658", "C-659"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-025"
input_path_refs = []
output_path_refs = ["data/e027/e027_topology_NNNcubed.toml", "data/e027/betti_timeseries_NNNcubed.csv"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-028"
title = "Lepton Mass Ratio Filtration via Patricia Trie (Thesis 2 Validation)"
binary = "lattice-filtration-analyzer"
binary_registered = true
binary_experiment_declared = "E-028"
method = "Patricia trie survival depth spectrum for 256 sedenion pairs, k-means depth clustering, lepton mass ratio prediction vs PDG values, Fibonacci and sedenion collision storms with power-law latency classification"
input = "Sedenion multiplication table (algebra_core cd_basis_mul_sign), collision storm parameters"
output = ["data/evidence/e028_filtration_analysis.toml"]
run = "cargo run --release --bin lattice-filtration-analyzer -- --n-steps 5000 --seed 42"
run_command_sha256 = "46afd89413f92eeb158d27f92ff5a8630ca7f7958bceb23aff861f8914acb75a"
claims = []
claim_refs = []
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-026"
input_path_refs = []
output_path_refs = ["data/evidence/e028_filtration_analysis.toml"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-029"
title = "A-infinity Correction Tensor via Neural Homotopy Search (Thesis 3 Validation)"
binary = "neural-homotopy-trainer"
binary_registered = true
binary_experiment_declared = "E-029"
method = "Sedenion associator tensor m_3 construction, Burn MLP training (Autodiff+NdArray+Adam, 256->128->64->16), pentagon-constrained batch coordinate descent, perturbation robustness testing"
input = "Sedenion multiplication table (algebra_core cd_basis_mul_sign), Burn NdArray backend with Autodiff"
output = ["data/evidence/e029_neural_homotopy.toml", "data/evidence/e029_perturb/e029_neural_homotopy.toml", "data/evidence/e029_algebraic/e029_neural_homotopy.toml"]
run = "cargo run --release --bin neural-homotopy-trainer -- --n-steps 500 --n-restarts 5 --batch-size 8 --seed 42"
run_command_sha256 = "d4a6f2bc9e1a3c4d8f7b0e5a2c6d9f1b3e8a7c4d6f0b2e5a8c1d4f7b0e3a6c9d"
claims = ["C-671", "C-672", "C-673"]
claim_refs = ["C-671", "C-672", "C-673"]
deterministic = false
seed = 42
gpu = false
status = "complete"
status_token = "COMPLETE"
lineage_id = "XL-027"
input_path_refs = []
output_path_refs = ["data/evidence/e029_neural_homotopy.toml", "data/evidence/e029_perturb/e029_neural_homotopy.toml", "data/evidence/e029_algebraic/e029_neural_homotopy.toml"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-030"
title = "TX-1: Frustration-Modulated Collision Dynamics (T1 x T4)"
binary = "thesis-cross-tx1"
binary_registered = true
binary_experiment_declared = "E-030"
method = "3D toroidal random walk with CD product noise, frustration density modulates local noise amplitude via alpha parameter, return-time shell binning, power-law gamma fitting"
input = "SedenionField spatial variation (dim=16), deterministic xorshift seed"
output = ["data/thesis_lab/tx1/tx1_report.toml"]
run = "cargo run --release --bin thesis-cross-tx1 -- --grid_size 16 --n_steps 50000"
run_command_sha256 = ""
claims = []
claim_refs = []
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-028"
input_path_refs = []
output_path_refs = ["data/thesis_lab/tx1/tx1_report.toml"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-031"
title = "TX-2: Viscosity-to-Filtration Loop (T2 x T4)"
binary = "thesis-cross-tx2"
binary_registered = true
binary_experiment_declared = "E-031"
method = "Frustration -> viscosity -> LBM evolution -> velocity field -> lattice filtration -> latency law classification, lambda sweep for coupling strength"
input = "SedenionField spatial variation (dim=16), Kolmogorov shear forcing"
output = ["data/thesis_lab/tx2/tx2_report.toml"]
run = "cargo run --release --bin thesis-cross-tx2 -- --grid_size 16 --lbm_steps 500"
run_command_sha256 = ""
claims = []
claim_refs = []
deterministic = true
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-029"
input_path_refs = []
output_path_refs = ["data/thesis_lab/tx2/tx2_report.toml"]
dataset_refs = []
reproducibility_class = "fully_deterministic"

[[experiment]]
id = "E-033"
title = "Grand Synthesis: All Four Theses Pass Gate Simultaneously"
binary = "thesis-synthesis-engine"
binary_registered = true
binary_experiment_declared = "E-033"
method = "Orchestrated execution of T1 (spatial correlation), T2 (power-law viscosity), T3 (plateau detection + pentagon optimization), T4 (shell return-time power law). Each thesis evaluated independently with falsification gate."
input = "Sedenion algebra (CD basis), LBM viscosity model, neural homotopy model, shell return-time storm"
output = ["data/evidence/synthesis_final/synthesis_summary.toml", "data/evidence/synthesis_final/thesis1_evidence.toml", "data/evidence/synthesis_final/thesis2_evidence.toml", "data/evidence/synthesis_final/thesis3_evidence.toml", "data/evidence/synthesis_final/thesis4_evidence.toml"]
run = "cargo run --release --bin thesis-synthesis-engine -- --thesis all --output-dir data/evidence/synthesis_final"
run_command_sha256 = ""
claims = ["C-674"]
claim_refs = ["C-674"]
deterministic = false
seed = 42
gpu = false
status = "complete"
status_token = "COMPLETE"
lineage_id = "XL-031"
input_path_refs = []
output_path_refs = ["data/evidence/synthesis_final/synthesis_summary.toml"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-032"
title = "Thesis 2: 3D Associator-Coupled Shear Thickening"
binary = "thesis2-3d-thickening"
binary_registered = true
binary_experiment_declared = "E-032"
method = "SedenionField local associator norm -> coupling field, LBM evolve_non_newtonian with Kolmogorov forcing, sweep over alpha and power-law index, compare Newtonian vs non-Newtonian max velocity"
input = "SedenionField spatial variation (dim=16), Kolmogorov shear forcing"
output = ["data/thesis_lab/thesis2_3d/thesis2_3d.toml"]
run = "cargo run --release --bin thesis2-3d-thickening -- --grid_size 16 --lbm_steps 500"
run_command_sha256 = ""
claims = []
claim_refs = []
deterministic = true
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-030"
input_path_refs = []
output_path_refs = ["data/thesis_lab/thesis2_3d/thesis2_3d.toml"]
dataset_refs = []
reproducibility_class = "fully_deterministic"

