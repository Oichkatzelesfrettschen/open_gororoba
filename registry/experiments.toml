# Experiments registry -- strict TOML schema (Wave 5 batch 4).
# Generated by src/scripts/analysis/build_wave5_batch4_registries.py.

[experiments]
updated = "2026-02-10"
authoritative = true
experiment_count = 16
deterministic_count = 10
gpu_count = 1
seeded_count = 6
status_allowlist = ["active", "deprecated", "planned", "blocked"]

[[experiment]]
id = "E-001"
title = "Cayley-Dickson Motif Census"
binary = "motif-census"
binary_registered = true
binary_experiment_declared = "E-001"
method = "Exact enumeration of connected-component structure of diagonal zero-product graph for cross-assessor pairs at each CD doubling (dim=16,32,64,128,256)."
input = "None (purely algebraic)"
output = ["data/csv/motif_census_dim{N}.csv", "data/csv/motif_census_summary.csv"]
run = "cargo run --release --bin motif-census -- --dims 16,32,64,128,256 --details"
run_command_sha256 = "0ed18c7e96c0fdb05e6cddfe47a84d53d2e3541ba5afffac75daff84def69e53"
claims = ["C-100", "C-101", "C-102", "C-103", "C-104", "C-105", "C-106", "C-107", "C-108", "C-109", "C-110"]
claim_refs = ["C-100", "C-101", "C-102", "C-103", "C-104", "C-105", "C-106", "C-107", "C-108", "C-109", "C-110"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-001"
input_path_refs = []
output_path_refs = ["data/csv/motif_census_dim{N}.csv", "data/csv/motif_census_summary.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-002"
title = "Multi-Dataset GPU Ultrametric Sweep"
binary = "multi-dataset-ultrametric"
binary_registered = true
binary_experiment_declared = "E-002"
method = "For 9 catalogs: normalize, compute Euclidean distances, ultrametric fraction test with column-shuffled null. 10M triples x 1000 permutations. BH-FDR correction."
input = "data/external/ (CHIME/FRB, ATNF, GWOSC, Pantheon+, Gaia DR3, SDSS DR18, Fermi GBM, Hipparcos, McGill)"
output = ["data/csv/c071g_multi_dataset_ultrametric.csv"]
run = "cargo run --release --bin multi-dataset-ultrametric -- --explore --n-triples 10000000 --n-permutations 1000"
run_command_sha256 = "e59ef06282507cc0fb1674275f790190b68117da9cd1d56c88234535d1be4d23"
claims = ["C-071", "C-436", "C-437", "C-438", "C-439", "C-440"]
claim_refs = ["C-071", "C-436", "C-437", "C-438", "C-439", "C-440"]
deterministic = false
seed = 42
gpu = true
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-002"
input_path_refs = ["data/external/"]
output_path_refs = ["data/csv/c071g_multi_dataset_ultrametric.csv"]
dataset_refs = ["PC-0017"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-003"
title = "Real Cosmological Fit (Pantheon+ / DESI BAO)"
binary = "real-cosmo-fit"
binary_registered = true
binary_experiment_declared = "E-003"
method = "Joint chi-square over 1578 Pantheon+ SNe + 7 DESI DR1 BAO bins. Analytic M_B marginalization. Nelder-Mead. Lambda-CDM vs w0-CDM via delta-BIC."
input = "data/external/Pantheon+SH0ES.dat"
output = ["stdout"]
run = "cargo run --release --bin real-cosmo-fit"
run_command_sha256 = "419b37ec0b4ed9616f8b4a6b9a8a61ab46d40205ddffb339284c5068b95d4197"
claims = ["C-200", "C-201", "C-202", "C-203", "C-204", "C-205", "C-206", "C-207", "C-208", "C-209", "C-210"]
claim_refs = ["C-200", "C-201", "C-202", "C-203", "C-204", "C-205", "C-206", "C-207", "C-208", "C-209", "C-210"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-003"
input_path_refs = ["data/external/Pantheon+SH0ES.dat"]
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-004"
title = "Kerr Shadow Boundaries"
binary = "kerr-shadow"
binary_registered = true
binary_experiment_declared = "E-004"
method = "Bardeen shadow boundary (alpha, beta) for Kerr BH at given spin and inclination."
input = "None (analytic)"
output = ["stdout or --output file"]
run = "cargo run --release --bin kerr-shadow -- --spin 0.998 --n-points 1000 --inclination 17"
run_command_sha256 = "b8cceed694706bbb72a5d18f683846dd723aec40790c7c35c9f340318dc94182"
claims = ["C-301", "C-302", "C-303", "C-304", "C-305", "C-306", "C-307", "C-308", "C-309", "C-310"]
claim_refs = ["C-301", "C-302", "C-303", "C-304", "C-305", "C-306", "C-307", "C-308", "C-309", "C-310"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-004"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-005"
title = "Zero-Divisor Graph Invariants"
binary = "zd-search"
binary_registered = true
binary_experiment_declared = "E-005"
method = "Build sedenion ZD interaction graph, compute graph-theoretic invariants. Extend to dim=32."
input = "None (purely algebraic)"
output = ["stdout"]
run = "cargo run --release --bin zd-search -- --dim 16 --max-pairs 5000"
run_command_sha256 = "cc836cab950db27c227d6bd4407dfb5e5b4fccc93ecc7b5f96c6c38599781254"
claims = ["C-050", "C-051", "C-052", "C-053", "C-054", "C-055", "C-056", "C-057", "C-058", "C-059", "C-060"]
claim_refs = ["C-050", "C-051", "C-052", "C-053", "C-054", "C-055", "C-056", "C-057", "C-058", "C-059", "C-060"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-005"
input_path_refs = []
output_path_refs = []
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-006"
title = "Gravastar TOV Parameter Sweep"
binary = "gravastar-sweep"
binary_registered = true
binary_experiment_declared = "E-006"
method = "Solve TOV for three-layer gravastar across polytropic indices and target masses."
input = "None (parametric sweep)"
output = ["data/csv/gravastar_sweep.csv"]
run = "cargo run --release --bin gravastar-sweep -- --n-gamma 32 --n-mass 32 --output data/csv/gravastar_sweep.csv"
run_command_sha256 = "cb2d95828c12d251641f827220bf3295a0efc4cdbaabb7ca8591ed31a2150b32"
claims = ["C-400", "C-401", "C-402", "C-403", "C-404", "C-405", "C-406", "C-407", "C-408", "C-409", "C-410"]
claim_refs = ["C-400", "C-401", "C-402", "C-403", "C-404", "C-405", "C-406", "C-407", "C-408", "C-409", "C-410"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-006"
input_path_refs = []
output_path_refs = ["data/csv/gravastar_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-007"
title = "Tensor Network / PEPS Entropy"
binary = "tensor-network"
binary_registered = true
binary_experiment_declared = "E-007"
method = "Classical tensor network simulator: Bell/GHZ states, random circuits, SVD entropy, PEPS boundary MPS."
input = "None (synthetic circuits)"
output = ["data/csv/entropy_scaling.csv"]
run = "cargo run --release --bin tensor-network -- scaling --n-min 2 --n-max 12 --output data/csv/entropy_scaling.csv"
run_command_sha256 = "3bdfb56d9470cbd4e3ab78c30ba39b3c9fdb08c6f24f5bbdb0f8b6e1d07d265b"
claims = ["C-350", "C-351", "C-352", "C-353", "C-354", "C-355", "C-356", "C-357", "C-358", "C-359", "C-360"]
claim_refs = ["C-350", "C-351", "C-352", "C-353", "C-354", "C-355", "C-356", "C-357", "C-358", "C-359", "C-360"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-007"
input_path_refs = []
output_path_refs = ["data/csv/entropy_scaling.csv"]
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-008"
title = "GWTC-3 Mass Clumping (Dip Test)"
binary = "mass-clumping"
binary_registered = true
binary_experiment_declared = "E-008"
method = "Hartigan dip test for multimodality of BBH mass distribution. Permutation-based p-value."
input = "data/external/gwosc_all_events.csv"
output = ["data/csv/gwtc3_mass_clumping_dip.csv"]
run = "cargo run --release --bin mass-clumping -- --n-permutations 10000 --seed 42"
run_command_sha256 = "ed3c2b072a68930190dad3e602856382bddef01b367b2addb6806c8893fb39f9"
claims = ["C-007"]
claim_refs = ["C-007"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-008"
input_path_refs = ["data/external/gwosc_all_events.csv"]
output_path_refs = ["data/csv/gwtc3_mass_clumping_dip.csv"]
dataset_refs = ["PC-0042"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-009"
title = "Negative-Dimension Eigenvalue Convergence"
binary = "neg-dim-eigen"
binary_registered = true
binary_experiment_declared = "E-009"
method = "Eigenvalues of H = T(k) + V(x) with fractional kinetic operator, imaginary-time evolution, epsilon->0 sweep."
input = "None (parametric)"
output = ["data/csv/neg_dim_convergence.csv"]
run = "cargo run --release --bin neg-dim-eigen -- sweep --alpha -1.5 --eps-start 0.5 --eps-end 0.01 --eps-steps 20 --output data/csv/neg_dim_convergence.csv"
run_command_sha256 = "2bf71ceb3ae9163bb4c2ffefdebf1c52eb9e054be93459f046faa5ebff6dd81d"
claims = ["C-420", "C-421", "C-422", "C-423", "C-424", "C-425"]
claim_refs = ["C-420", "C-421", "C-422", "C-423", "C-424", "C-425"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-009"
input_path_refs = []
output_path_refs = ["data/csv/neg_dim_convergence.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-010"
title = "Materials Science Baselines (JARVIS + AFLOW)"
binary = "materials-baseline"
binary_registered = true
binary_experiment_declared = "E-010"
method = "JARVIS-DFT and AFLOW datasets, Magpie-style featurization, OLS regression for formation energy and band gap."
input = "data/external/ (JARVIS JSON, AFLOW CSV)"
output = ["stdout"]
run = "cargo run --release --bin materials-baseline -- --data-dir data/external --seed 42"
run_command_sha256 = "35772f3c6cc257b32ee9edea6e592050bb8c803cc6a01a1f3e22d5b377a395ee"
claims = []
claim_refs = []
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-010"
input_path_refs = ["data/external/"]
output_path_refs = []
dataset_refs = []
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-011"
title = "Cross-Stack Locality Comparison (Experiment A)"
binary = "cross-stack-locality"
binary_registered = true
binary_experiment_declared = "E-011"
method = "Compare adjacency-locality metrics across three independent constraint systems: Stack 1 (E10 Billiard): Wall-transition sequence from HyperbolicBilliard, E10 Dynkin graph. Metric: r_e8 = fraction of consecutive pairs that are E8-adjacent. Null: ColumnIndependentNull (uniform random generator selection). Stack 2 (ET DMZ Walk): Navigation sequences through de Marrais Emanation Table. Metric: r_dmz = fraction of consecutive ET cells that share a DMZ edge. Null: uniform random cell selection in the ET grid. Stack 3 (CD ZD Catamaran/Twist): Twist-product navigation across zero-divisor graph. Metric: r_zd = fraction of consecutive basis-pair transitions that are ZD-adjacent. Null: uniform random basis-pair selection. All three use the common abstract model: generator-driven piecewise geodesic dynamics (generator set G, constraint graph Gamma subset G x G, sequence s_1..s_n, locality ratio r = |{i : (s_i, s_{i+1}) in Gamma}| / (n-1)). Prediction (ALP, C-476): all three r values significantly exceed their nulls. Falsifier: one or more shows r consistent with uniform/random."
input = "None (purely algebraic / simulation)"
output = ["data/csv/cross_stack_locality_comparison.csv"]
run = "cargo run --release --bin cross-stack-locality -- --n-bounces 10000 --n-permutations 1000 --seed 42"
run_command_sha256 = "43d8015e68ae9ead4fc208d09f43bbef2a64890082224cf3529e6463dca298df"
claims = ["C-476"]
claim_refs = ["C-476"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-011"
input_path_refs = []
output_path_refs = ["data/csv/cross_stack_locality_comparison.csv"]
dataset_refs = ["PC-0031"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-012"
title = "ET Discrete Billiard (Experiment B)"
binary = "et-billiard"
binary_registered = true
binary_experiment_declared = "E-012"
method = "Treat the Emanation Table as a discrete billiard wall set. Walls: ET constraints define forbidden/allowed transitions in (S, row, col) space. Reflections: when a trajectory hits an ET \"wall\" (DMZ boundary), apply the ET rule update (fill/hide involution or strut-constant increment). Symbolic dynamics: record the sequence of wall types hit (DMZ, label-line, empty). Phase structure: compute Lyapunov exponent (or mixing time) as a function of strut constant S. Compare against spectroscopy band classification (Dense/Sparse/Mixed from spectroscopy_bands()). Prediction: spectroscopy band transitions correspond to qualitative phase changes in the toy billiard (e.g., Dense bands -> low Lyapunov, Sparse -> high Lyapunov). Falsifier: no correlation between spectroscopy classification and billiard dynamics."
input = "None (ET computation from emanation.rs)"
output = ["data/csv/et_billiard_phase_structure.csv"]
run = "cargo run --release --bin et-billiard -- --n-levels 4,5,6 --n-steps 10000 --seed 42"
run_command_sha256 = "486e4fdc996d9d591999f9b99f4fb913d77e4e05f0e8ee177561695f6116e5fc"
claims = ["C-476", "C-477"]
claim_refs = ["C-476", "C-477"]
deterministic = false
seed = 42
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-012"
input_path_refs = []
output_path_refs = ["data/csv/et_billiard_phase_structure.csv"]
dataset_refs = ["PC-0032"]
reproducibility_class = "seeded_stochastic_replay"

[[experiment]]
id = "E-013"
title = "Sky-Limit-Set Correspondence (Experiment C)"
binary = "sky-limit-set"
binary_registered = true
binary_experiment_declared = "E-013"
method = "Compare ET skybox pattern invariants to Coxeter group limit set invariants. Step 1: For each CD level N=4,5,6, compute the skybox (G x G grid) and extract: - box-kite count (= N-1) - emptiness clustering exponent (connected-component size distribution) - DMZ density (fraction of cells that are DMZ) - fill/hide period-doubling structure (from Four Corners rule) Step 2: For candidate Coxeter groups (A_{N-1}, B_{N-1}, D_{N-1}), compute limit set invariants from the Coxeter matrix: - rank - fractal dimension of limit set - invariant measure density Step 3: Compare skybox invariants (Step 1) to limit set invariants (Step 2) via correlation and matching tests. Prediction (C-477): systematic correspondence between skybox pattern invariants and Coxeter limit set invariants at matching rank. Falsifier: no Coxeter group at any rank produces invariants matching the ET skybox."
input = "None (ET computation + Coxeter matrix computation)"
output = ["data/csv/sky_limit_set_comparison.csv"]
run = "cargo run --release --bin sky-limit-set -- --n-levels 4,5,6 --coxeter-types A,B,D"
run_command_sha256 = "37973a488de5e55a2b2de39142b5f51c3bfaf4ba184779a2c13fe48ace1022bf"
claims = ["C-477"]
claim_refs = ["C-477"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-013"
input_path_refs = []
output_path_refs = ["data/csv/sky_limit_set_comparison.csv"]
dataset_refs = ["PC-0056"]
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-014"
title = "Dimensional Ladder APT Census (4D-4096D)"
binary = "dimensional-census"
binary_registered = true
binary_experiment_declared = ""
method = "Exhaustive and Monte Carlo Anti-Diagonal Parity Theorem verification across the full Cayley-Dickson dimensional ladder from dim=4 to dim=4096. Exhaustive mode: Enumerate ALL graph triangles in each zero-divisor component. For each triangle (a,b,c), compute eta via anti-diagonal parity formula: eta(a,b) = psi(lo_a, hi_b) XOR psi(hi_a, lo_b). Classify as pure (eta constant across 3 edges) or mixed (eta non-constant). Verify 1:3 pure:mixed ratio (Quarter Rule: pure*4 = total exactly). Verify Klein-four fiber symmetry: F(0,0) = F(0,1) = F(1,0) = F(1,1). Monte Carlo mode: Rejection-sample random node triples within components, accept only graph triangles (all 3 edges present), classify via APT. Deterministic with seed=42. Tier classification: dims 4-32 (TIER 0-1, <15s), dims 64-256 (TIER 2, ~5s release), dims 512-1024 (TIER 3, minutes-hours CPU), dims 2048-4096 (TIER 4, GPU Monte Carlo)."
input = "None (Cayley-Dickson structure tables computed on the fly)"
output = ["data/csv/apt_dimensional_census_summary.csv", "data/csv/apt_dimensional_census_details.csv"]
run = "cargo run --release --bin dimensional-census -- --slow --details"
run_command_sha256 = "ed72a3d2f1cac08e2a1787c6be706b5db2bda1acf02bb0f493ebc7107a7cd1be"
claims = ["C-570", "C-571", "C-572"]
claim_refs = ["C-570", "C-571", "C-572"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-014"
input_path_refs = []
output_path_refs = ["data/csv/apt_dimensional_census_summary.csv", "data/csv/apt_dimensional_census_details.csv"]
dataset_refs = ["PC-0002"]
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-015"
title = "GF(2) Separating Degree Formula Verification (dim 32-256)"
binary = "dimensional-census"
binary_registered = true
binary_experiment_declared = ""
method = "For each Cayley-Dickson dimension d in {32, 64, 128, 256}, compute the minimum-degree GF(2) polynomial that separates all motif classes in PG(log2(d)-2, 2). Uses greedy partition refinement for d=256 where brute-force is infeasible (16 classes, C(127,6) candidate tuples). Verifies the formula min_degree = log2(d) - 2 at each step."
input = "None (Cayley-Dickson structure tables computed on the fly)"
output = ["data/csv/separating_degree_formula_sweep.csv"]
run = "cargo test -p algebra_core --release --lib -- test_separating_degree_formula_universality --nocapture"
run_command_sha256 = "14fdeb04854fd5796e3e9e39d81ec504b61eb83076dad30cc7813352db6c7dd0"
claims = ["C-599", "C-600"]
claim_refs = ["C-599", "C-600"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-015"
input_path_refs = []
output_path_refs = ["data/csv/separating_degree_formula_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-016"
title = "A-infinity Homotopy Gravastar Obstruction Sweep"
binary = "gravastar-sweep"
binary_registered = true
binary_experiment_declared = ""
method = "Construct a SedenionAInfinity algebra (m_2=CD product, m_3=associator) and compute the obstruction norm (Frobenius / dim^{3/2}). Map obstruction to Bowers-Liang anisotropy parameter lambda via linear coupling. Sweep coupling from 0 to 0.5 and solve the anisotropic gravastar TOV equation at each point to find the stability window."
input = "None (sedenion structure table + polytropic EOS computed on the fly)"
output = ["data/csv/gravastar_homotopy_obstruction_sweep.csv"]
run = "cargo test -p cosmology_core --release --lib -- homotopy_bridge --nocapture"
run_command_sha256 = ""
claims = ["C-611", "C-612", "C-613", "C-614", "C-615"]
claim_refs = ["C-611", "C-612", "C-613", "C-614", "C-615"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-016"
input_path_refs = []
output_path_refs = ["data/csv/gravastar_homotopy_obstruction_sweep.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-017"
title = "7-Clique Multi-Resonator Entropy Trap Simulation"
binary = "entropy-trap"
binary_registered = false
binary_experiment_declared = ""
method = "Build a 7-channel TCMT multi-resonator system from sedenion box-kite components. Each channel is an independent KerrCavity with resonance frequency offset by the component index. Verify zero crosstalk for uncoupled channels, compute per-channel Shannon entropy and pairwise mutual information via 2D histogram binning, and sweep absorption spectrum across all 7 resonance frequencies."
input = "None (box-kite structure + normalized cavity parameters computed on the fly)"
output = ["data/csv/entropy_trap_7clique_absorption.csv", "data/csv/entropy_trap_7clique_summary.csv"]
run = "cargo test -p optics_core --release --lib -- entropy_trap --nocapture"
run_command_sha256 = ""
claims = ["C-616", "C-617", "C-618", "C-619", "C-620"]
claim_refs = ["C-616", "C-617", "C-618", "C-619", "C-620"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-017"
input_path_refs = []
output_path_refs = ["data/csv/entropy_trap_7clique_absorption.csv", "data/csv/entropy_trap_7clique_summary.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-018"
title = "He-4 BEC Thermodynamics and Two-Fluid Dynamics"
binary = "he4-superfluid"
binary_registered = false
binary_experiment_declared = ""
method = "Compute ideal BEC critical temperature via zeta(3/2) formula, verify condensate fraction law 1-(T/T_c)^(3/2), validate Landau superfluid density fraction with exponent 5.6, and simulate 0D two-fluid relaxation dynamics using RK4 with relaxation timescales tau_rho = 1 us, tau_t = 100 us. Verify mass conservation, equilibrium relaxation, and thermal relaxation through the lambda transition."
input = "None (physical constants for He-4 at SVP)"
output = ["data/csv/he4_bec_condensate_fraction.csv", "data/csv/he4_two_fluid_evolution.csv"]
run = "cargo test -p quantum_core --release --lib -- superfluid --nocapture && cargo test -p quantum_core --release --lib -- two_fluid --nocapture"
run_command_sha256 = ""
claims = ["C-621", "C-622", "C-623", "C-624", "C-625", "C-626", "C-627"]
claim_refs = ["C-621", "C-622", "C-623", "C-624", "C-625", "C-626", "C-627"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-018"
input_path_refs = []
output_path_refs = ["data/csv/he4_bec_condensate_fraction.csv", "data/csv/he4_two_fluid_evolution.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"

[[experiment]]
id = "E-019"
title = "Gross-Pitaevskii Ground State and Vortex Calculation"
binary = "he4-superfluid"
binary_registered = false
binary_experiment_declared = ""
method = "Solve the Gross-Pitaevskii equation using Strang split-operator method with FFT-based kinetic evolution. Compute ground states via imaginary-time propagation in a harmonic trap (omega=1), verifying energy recovery E=omega/2 for the linear case (g=0). Test that repulsive interactions (g=50) raise the energy above the linear value. Verify norm preservation during real-time evolution and density centering on the trap."
input = "None (harmonic trap potential, interaction parameter g)"
output = ["data/csv/he4_gpe_ground_state.csv"]
run = "cargo test -p quantum_core --release --lib -- gross_pitaevskii --nocapture"
run_command_sha256 = ""
claims = ["C-628", "C-629"]
claim_refs = ["C-628", "C-629"]
deterministic = true
gpu = false
status = "active"
status_token = "ACTIVE"
lineage_id = "XL-019"
input_path_refs = []
output_path_refs = ["data/csv/he4_gpe_ground_state.csv"]
dataset_refs = []
reproducibility_class = "deterministic_replay"


[[experiment]]
id = "E-021"
title = "Tessarines vs. Mixed-Quaternions Categorical Distinction Census"
date = "2026-02-10"
status = "complete"
methodology = "Exhaustive low-dimensional census at dims 2-8 comparing tensor product (tessarines C ⊗ C) with recursive doubling (Cayley-Dickson mixed-quaternions). Hypothesis: categorical distinction on commutativity and division algebra status."
findings = "VERIFIED: Tessarines exhibit 100% commutativity and zero-divisor structure. Cayley-Dickson dim=4 shows 0% commutativity and signature-dependent division status. The two algebras are categorically distinct and cannot be reconciled via signature reinterpretation."
claims_supported = ["C-633", "C-634", "C-635", "C-636", "C-640"]
insights = ["I-054", "I-055"]
code = ["crates/algebra_core/src/construction/tessarines.rs", "crates/algebra_core/tests/test_tessarines_census.rs", "crates/algebra_core/tests/test_exotic_octonions.rs"]
data_artifacts = ["docs/PHASE9_TESSARINES_COMPARATIVE_ANALYSIS.md"]
sprint = 35
phase = "Phase 9"

[[experiment]]
id = "E-022"
title = "Albert Algebra Commutativity and Exceptional Structure Census"
date = "2026-02-10"
status = "complete"
methodology = "Comprehensive test suite for J_3(O) (Albert algebra, 27D exceptional Jordan algebra). Test 1: 100% commutativity census (3 test classes: diagonal, mixed, octonion-heavy). Test 2: Jordan identity property verification. Test 3: Singh's delta^2 survey across trace-free elements. Test 4: Cross-validation with Phase 9 categorical distinction theorem. Test 5: Norm and invertibility analysis. Test 6: Exceptionality indicator (power-associativity)."
findings = "VERIFIED: Albert algebra exhibits 100% commutativity (6/6 test classes pass), confirming that exceptional Jordan algebras preserve the commutativity pattern from Phase 9 tessarines research. Singh's delta^2 survey shows mean=3.213 (range 2.505-3.747) vs predicted 3/8=0.375, indicating delta^2 is element-dependent, not universal. Exceptionality confirmed via structure (3x3 Hermitian octonion matrices) which cannot be embedded in associative algebras."
claims_supported = ["C-641", "C-642", "C-643", "C-644", "C-645"]
insights = ["I-057", "I-058"]
code = ["crates/algebra_core/src/construction/albert.rs", "crates/algebra_core/tests/test_albert_algebra.rs"]
cross_validation = "E-021 (tessarines 100% commutative) confirms Phase 9 finding; E-022 (Albert 100% commutative) extends pattern to exceptional algebras"
sprint = 35
phase = "Phase 10.1"

[[experiment]]
id = "E-023"
title = "Composition Algebra Taxonomy: Two-Axis Classification Framework"
date = "2026-02-10"
status = "complete"
methodology = "Comprehensive taxonomy framework for all composition algebras across two orthogonal axes: (1) Construction Method (tensor product vs recursive doubling vs exceptional) and (2) Metric Signature (gamma patterns controlling zero-divisor structure in CD family). Implemented composition_algebra_census.rs registry structure + test_composition_algebra_taxonomy.rs with 11 test classes: Axis 1 commutativity law, Axis 2 signature law, categorical distinction theorem, exceptional algebras, norm multiplicativity correlation, property matrix consistency, zero-divisor structure mapping, Phase 9-10 extension theorem, taxonomy coverage, and census export validation."
findings = "VERIFIED: (Axis 1) All tensor products 100% commutative; all CD algebras (dim>=4) 0% commutative - construction method determines commutativity universally. (Axis 2) Metric signature controls zero-divisor presence in CD family: gamma=-1 → division algebra (no ZD), gamma=+1 → zero-divisors. (Categorical Distinction Extended) Phase 9 tessarines≠CD distinction generalizes to all families: tensor products and recursive doubling are categorically distinct across all dimensions. (Exceptional Algebras) Albert algebra 100% commutative, non-division - exhibits commutativity of tensor products with structure of recursive doubling. (Norm Multiplicativity) Preserved iff division algebra (biconditional relationship verified). (Property Matrix) All three algebra classes pass consistency validation (division/ZD conflict, commutativity all-or-nothing, associativity constraints)."
claims_supported = ["C-646", "C-647", "C-648", "C-649", "C-650"]
insights = ["I-059", "I-060"]
code = ["crates/algebra_core/src/construction/composition_algebra_census.rs", "crates/algebra_core/tests/test_composition_algebra_taxonomy.rs"]
cross_validation = "E-021 (Phase 9) + E-022 (Phase 10.2) verify that construction method universally determines commutativity; E-023 formalizes two-axis taxonomy extending distinction to all families"
sprint = 35
phase = "Phase 10.3"

