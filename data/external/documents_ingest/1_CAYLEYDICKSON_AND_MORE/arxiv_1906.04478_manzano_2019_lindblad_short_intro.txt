                                                                    A short introduction to the Lindblad Master Equation

                                                                                                    Daniel Manzano1
                                                           1
                                                               Electromagnetism and Condensed Matter Department and Carlos I Institute for Theoretical
                                                                    and Computational Physics. University of Granada. E-18071 Granada. Spain âˆ—
                                                           The theory of open quantum system is one of the most essential tools for the development of
                                                        quantum technologies. Furthermore, the Lindblad (or Gorini-Kossakowski-Sudarshan-Lindblad)
                                                        Master Equation plays a key role as it is the most general generator of Markovian dynamics in
                                                        quantum systems. In this paper, we present this equation together with its derivation and methods
                                                        of resolution. The presentation tries to be as self-contained and straightforward as possible to be
                                                        useful to readers with no previous knowledge of this field.




arXiv:1906.04478v3 [quant-ph] 5 Feb 2020
                                                                                               I.   INTRODUCTION

                                              Open quantum system techniques are vital for many studies in quantum mechanics [1â€“3]. This happens because
                                           closed quantum systems are just an idealisation of real systems1 , as in Nature nothing can be isolated. In practical
                                           problems, the interaction of the system of interest with the environment cannot be avoided, and we require an approach
                                           in which the environment can be effectively removed from the equations of motion.
                                              The general problem addressed by Open Quantum Theory is sketched in Figure 1. In the most general picture, we
                                           have a total system that conforms a closed quantum system by itself. We are mostly interested in a subsystem of the
                                           total one (we call it just â€œsystemâ€ instead â€œtotal systemâ€). Therefore, the whole system is divided into our system of
                                           interest and an environment. The goal of Open Quantum Theory is to infer the equations of motions of the reduced
                                           systems from the equation of motion of the total system. For practical purposes, the reduced equations of motion
                                           should be easier to solve than the full dynamics of the system. Because of his requirement, several approximations
                                           are usually made in the derivation of the reduced dynamics.




                                                        FIG. 1: A total system divided into the system of interest, â€œSystemâ€, and the environment.



                                           âˆ— manzano@onsager.ugr.es
                                           1 The same happens with closed classical systems.
                                                                                                                        2

   One particular, and interesting, case of study is the dynamics of a system connected to several baths modelled by
a Markovian interaction. In this case the most general quantum dynamics is generated by the Lindblad equation
(also called Gorini-Kossakowski-Sudarshan-Lindblad equation) [4, 5]. It is difficult to overemphasize the importance
of this Master Equation. It plays an important role in fields as quantum optics [1, 6], condensed matter [7â€“10], atomic
physics [11, 12], quantum information [13, 14], decoherence [15, 16], and quantum biology [17â€“19].
   The purpose of this paper is to provide basic knowledge about the Lindblad Master Equation. In Section II,
the mathematical requirements are introduced while in Section III there is a brief review of quantum mechanical
concepts that are required to understand the paper. Section IV, includes a description of a mathematical framework,
the Fock-Liouville space, that is especially useful to work in this problem. In Section V, we define the concept of
CPT-Maps, derive the Lindblad Master Equation from two different approaches, and we discus several properties of
the equation. Finally, Section VI is devoted to the resolution of the master equation using different methods. To
deepen in the techniques of solving the Lindblad equation, an example consisting of a two-level system with decay
is analysed, illustrating the content of every section. The problems proposed are solved by the use of Mathematica
notebooks that can be found at [20].


                                           II.   MATHEMATICAL BASIS

   The primary mathematical tool in quantum mechanics is the theory of Hilbert spaces. This mathematical framework
allows extending many results from finite linear vector spaces to infinite ones. In any case, this tutorial deals only
with finite systems and, therefore, the expressions â€˜Hilbert spaceâ€™ and â€˜linear spaceâ€™ are equivalent. We assume that
the reader is skilled in operating in Hilbert spaces. To deepen in the field of Hilbert spaces we recommend the book
by Debnath and MikusinÌki [21]. If the reader needs a brief review of the main concepts required for understanding
this paper, we may recommend Nielsen and Chuangâ€™s Quantum Computing book [22]. It is also required some basic
knowledge about infinitesimal calculus, like integration, derivation, and the resolution of simple differential equations,
To help the readers, we have made a glossary of the most used mathematical terms. It can be used also as a checklist
of terms the reader should be familiar with.
Glossary:
   â€¢ H represents a Hilbert space, usually the space of pure states of a system.
   â€¢ |Ïˆi âˆˆ H represents a vector of the Hilbert space H (a column vector).
   â€¢ hÏˆ| âˆˆ H represents a vector of the dual Hilbert space of H (a row vector).
   â€¢ hÏˆ|Ï†i âˆˆ C is the scalar product of vectors |Ïˆi and |Ï†i.
                                                 p
   â€¢ |||Ïˆi|| is the norm of vector |Ïˆi. |||Ïˆi|| â‰¡ hÏˆ|Ïˆi.
   â€¢ B(H) represents the space of bounded operators acting on the Hilbert space B : H â†’ H.
   â€¢ 1H âˆˆ B(H) is the Identity Operator of the Hilbert space H s.t. 1H |Ïˆi = |Ïˆi, âˆ€|Ïˆi âˆˆ H.
   â€¢ |ÏˆihÏ†| âˆˆ B(H) is the operator such that (|ÏˆihÏ†|) |Ï•i = hÏ†|Ï•i|Ïˆi, âˆ€|Ï•i âˆˆ H.
   â€¢ Oâ€  âˆˆ B(H) is the Hermitian conjugate of the operator O âˆˆ B(H).
   â€¢ U âˆˆ B(H) is a unitary operator iff U U â€  = U â€  U = 1.
   â€¢ H âˆˆ B(H) is a Hermitian operator iff H = H â€  .
   â€¢ A âˆˆ B(H) is a positive operator (A > 0) iff hÏ†|A|Ï†i â‰¥ 0, âˆ€|Ï†i âˆˆ H
   â€¢ P âˆˆ B(H) is a proyector iff P P = P .
   â€¢ Tr [B] represents the trace of operator B.
   â€¢ Ï (L) represents the space of density matrices, meaning the space of bounded operators acting on H with trace
     1 and positive.
   â€¢ |Ïii is a vector in the Fock-Liouville space.
   â€¢ hhA|Bii = Tr Aâ€  B is the scalar product of operators A, B âˆˆ B(H) in the Fock-Liouville space.
                         

   â€¢ LÌƒ is the matrix representation of a superoperator in the Fock-Liouville space.
                                                                                                                         3

                   III.   (VERY SHORT) INTRODUCTION TO QUANTUM MECHANICS

   The purpose of this chapter is to refresh the main concepts of quantum mechanics necessary to understand the
Lindblad Master Equation. Of course, this is NOT a full quantum mechanics course. If a reader has no background
in this field, just reading this chapter would be insufficient to understand the remaining of this tutorial. Therefore,
if the reader is unsure of his/her capacities, we recommend to go first through a quantum mechanics course or to
read an introductory book carefully. There are many great quantum mechanics books in the market. For beginners,
we recommend Sakuraiâ€™s book [23] or Nielsen and Chuangâ€™s Quantum Computing book [22]. For more advanced
students, looking for a solid mathematical description of quantum mechanics methods, we recommend Galindo and
Pascual [24]. Finally, for a more philosophical discussion, you should go to Peresâ€™ book [25].
   We start stating the quantum mechanics postulates that we need to understand the derivation and application of
the Lindblad Master Equation. The first postulate is related to the concept of a quantum state.


Postulate 1 Associated to any isolated physical system, there is a complex Hilbert space H, known as the state space
of the system. The state of the system is entirely described by a state vector, which is a unit vector of the Hilbert space
(|Ïˆi âˆˆ H).


As quantum mechanics is a general theory (or a set of theories), it does not tell us which is the proper Hilbert
space for each system. This is usually done system by system. A natural question to ask is if there is a one-to-one
correspondence between unit vectors and physical states, meaning that if every unit vector corresponds to a physical
system. This is resolved by the following corollary that is a primary ingredient for quantum computation theory (see
Ref. [22] Chapter 7).


Corollary 1 All unit vectors of a finite Hilbert space correspond to possible physical states of a system.


Unit vectors are also called pure states. If we know the pure state of a system, we have all physical information
about it, and we can calculate the probabilistic outcomes of any potential measurement (see the next postulate). This
is a very improbable situation as experimental settings are not perfect, and in most cases, we have only imperfect
information about the state. Most generally, we may know that a quantum system can be in one state of a set {|Ïˆi i}
with probabilities pi . Therefore, our knowledge of the system is given by an ensemble of pure states described by the
set {|Ïˆi i, pi }. If more than one pi is different from zero the state is not pure anymore, and it is called a mixed state.
The mathematical tool that describes our knowledge of the system, in this case, is the density operator (or density
matrix).

                                                         X
                                                    Ïâ‰¡        pi |Ïˆi ihÏˆi |.                                           (1)
                                                          i

Density matrices are bounded operators that fulfil two mathematical conditions
   1. A density matrix Ï has unit trace (Tr[Ï] = 1).
   2. A density matrix is a positive matrix Ï > 0.
Any operator fulfilling these two properties is considered a density operator. It can be proved trivially that density
matrices are also Hermitian.
  If we are given a density matrix, it is easy to verify if it belongs to a pure or a mixed state. For pure states, and
only for them, Tr[Ï2 ] = Tr[Ï] = 1. Therefore, if Tr[Ï2 ] < 1 the system is mixed. The quantity Tr[Ï2 ] is called the
purity of the states, and it fulfils the bounds d1 â‰¤ Tr[Ï2 ] â‰¤ 1, being d the dimension of the Hilbert space.
                                        N
  If we fix an arbitrary basis {|ii}i=1 of the Hilbert space the density matrix in this basis is written as Ï =
PN
  i,j=1 Ïi,j |iihj|, or

                                                  ï£«                   ï£¶
                                                  Ï00 Ï01 Â· Â· Â· Ï0N
                                                ï£¬ Ï10 Ï11 Â· Â· Â· Ï1N ï£·
                                              Ï=ï£¬ .                .. ï£· ,                                              (2)
                                                ï£¬                     ï£·
                                                   .   .. . .
                                                ï£­ .     .      .    . ï£¸
                                                 ÏN 0 ÏN 1 Â· Â· Â· ÏN N
                                                                                                                       4

                                                       Ïii âˆˆ R+
                                                                      P            
where the diagonal elements are called populations            0 and      i Ïi,i = 1 , while the off-diagonal elements are
called coherences Ïi,j âˆˆ C and Ïi,j = Ïâˆ—j,i . Note that this notation is base-dependent.
                                           




          Box 1. State of a two-level system (qubit)
          The Hilbert space of a two-level system is just the two-dimension lineal space H2 . Examples of
          this kind of system are 12 -spins and two-level atoms. We can define a basis of it by the orthonormal
          vectors: {|0i, |1i}. A pure state of the system would be any unit vector of H2 . It can always be
                                                                  2     2
          expressed as a |Ïˆi = a|0i + b|1i with a, b âˆˆ C s. t. |a| + |b| = 1.
          A mixed state is therefore represented by a positive unit trace operator Ï âˆˆ O(H2 ).

                                                 
                                        Ï00 Ï01
                               Ï=                     = Ï00 |0ih0| + Ï01 |0ih1| + Ï10 |1ih0| + Ï11 |1ih1|,   (3)
                                        Ï10 Ï11

          ant it should fulfil Ï00 + Ï11 = 1 and Ï01 = Ïâˆ—10 .



Once we know the state of a system, it is natural to ask about the possible outcomes of experiments (see Ref. [23],
Section 1.4).


Postulate 2 All possible measurements in a quantum system are described by a Hermitian operator or observable.
Due to the Spectral Theorem we know that any observable O has a spectral decomposition in the form2
                                                                  X
                                                            O=          ai |ai ihai |,                               (4)
                                                                    i

being ai âˆˆ R the eigenvalues of the observable and |ai i their corresponding eigenvectors. The probability of obtaining
the result ai when measuring the property described by observable O in a state |Ïˆi is given by

                                                                                  2
                                                            P (ai ) = |hÏˆ|ai i| .                                    (5)
After the measurement we obtain the state |ai i if the outcome ai was measured. This is called the post-measurement
state.


   This postulate allow us to calculate the possible outputs of a system, the probability of these outcomes, as well as
the after-measurement state. A measurement usually changes the state, as it can only remain unchanged if it was
already in an eigenstate of the observable.
   It is possible to calculate the expectation value of the outcome of a measurement defined by operator O in a state
|Ïˆi by just applying the simple formula

                                                              hOi = hÏˆ|O|Ïˆi.                                         (6)
With a little algebra we can translate this postulate to mixed states. In this case, the probability of obtaining an
output ai that corresponds to an eigenvector |ai i is

                                                          P (ai ) = Tr [|ai ihai |Ï] ,                               (7)
and the expectation value of operator O is

                                                              hOi = Tr [OÏ] .                                        (8)


2 For simplicity, we assume a non-degenerated spectrum.
                                                                                                                        5


         Box 2. Measurement in a two-level system.
         A possible test to perform in our minimal model is to measure the energetic state of a system, as-
         suming that both states have a different energy. The observable corresponding to this measurement
         would be


                                                 H = E0 |0ih0| + E1 |1ih1|.                                    (9)

         This operator has two eigenvalues {E0 , E1 } with two corresponding eigenvectors {|0i, |1i}.
         If we have a pure state Ïˆ = a|0i + b|1i the probability of measuring the energy E0 would be
                          2     2                                                          2     2
         P (E0 ) = |h0|Ïˆi| = |a| . The probability of finding E1 would be P (E1 ) = |h1|Ïˆi| = |b| . The
                                                           2       2
         expected value of the measurement is hHi = E0 |a| + E1 |b| .
         In the more general case of having a mixed state Ï = Ï00 |0ih0| + Ï01 |0ih1| + Ï10 |1ih0| + Ï11 |1ih1| the
         probability of finding the ground state energy is P (0) = Tr [|0ih0|Ï] = Ï00 , and the expected value
         of the energy would be hHi = Tr [HÏ] = E0 Ï00 + E1 Ï11 .



Another natural question to ask is how quantum systems evolve. The time-evolution of a pure state of a closed
quantum system is given by the SchroÌˆdinger equation (see [24], Section 2.9).


Postulate 3 Time evolution of a pure state of a closed quantum system is given by the SchroÌˆdinger equation


                                                 d
                                                    |Ïˆ(t)i = âˆ’ihÌ„H|Ïˆ(t)i,                                             (10)
                                                 dt
where H is the Hamiltonian of the system and it is a Hermitian operator of the Hilbert space of the system state (from
now on we avoid including Planckâ€™s constant by selecting the units such that hÌ„ = 1).


The Hamiltonian of a system is the operator corresponding to its energy, and it can be non-trivial to realise.
  SchroÌˆdinger equation can be formally solved in the following way. If at t = 0 the state of a system is given by |Ïˆ(0)i
at time t it will be


                                                  |Ïˆ(t)i = eâˆ’iHt |Ïˆ(0)i.                                              (11)

As H is a Hermitian operator, the operator U = eâˆ’iHt is unitary. This gives us another way of phrasing Postulate 3.

  Postulate 3â€™ The evolution of a closed system is given by a unitary operator of the Hilbert space of the system

                                                    |Ïˆ(t)i = U |Ïˆ(0)i,                                                (12)

with U âˆˆ B (H) s.t. U U â€  = U â€  U = 1.

It is easy to prove that unitary operators preserve the norm of vectors and, therefore, transform pure states into pure
states. As we did with the state of a system, it is reasonable to wonder if any unitary operator corresponds to the
evolution of a real physical system. The answer is yes.


Lemma 1 All unitary evolutions of a state belonging to a finite Hilbert space can be constructed in several physical
realisations like photons and cold atoms.

The proof of this lemma can be found at [22].
                                                                                                                   6

  The time evolution of a mixed state can be calculated just by combining Eqs. (10) and (1), giving the von-Neumann
equation.


                                                   ÏÌ‡ = âˆ’i [H, Ï] â‰¡ LÏ,                                          (13)

where we have used the commutator [A, B] = AB âˆ’ BA, and L is the so-called Liouvillian superoperator.
  It is easy to prove that the Hamiltonian dynamics does not change the purity of a system

                                          2
                            d  2        dÏ
                               Tr Ï = Tr      = Tr [2ÏÏÌ‡] = âˆ’2iTr [Ï (HÏ âˆ’ ÏH)] = 0,                             (14)
                            dt             dt

where we have used the cyclic property of the trace. This result illustrates that the mixing rate of a state does not
change due to the quantum evolution.


         Box 3. Time evolution of a two-level system.
         The evolution of our isolated two-level system is described by its Hamiltonian

                                              Hfree = E0 |0ih0| + E1 |1ih1|,                             (15)

         As the states |0i and |1i are Hamiltonian eigenstates if at t = 0 the atom is at the excited state
         |Ïˆ(0)i = |1i after a time t the state would be |Ïˆ(t)i = eâˆ’iHt |1i = eâˆ’iE1 t |1i.
         As the system was already in an eigenvector of the Hamiltonian, its time-evolution consists only in
         adding a phase to the state, without changing its physical properties. (If an excited state does not
         change, why do atoms decay?) Without losing any generality we can fix the energy of the ground
         state as zero, obtaining

                                                     Hfree = E|1ih1|,                                    (16)

         with E â‰¡ E1 . To make the model more interesting we can include a driving that coherently
         switches between both states. The total Hamiltonian would be then


                                            H = E|1ih1| + â„¦ (|0ih1| + |1ih0|) ,                          (17)

         where â„¦ is the frequency of driving. By using the von-Neumann equation (13) we can calculate
         the populations (Ï00 , Ï11 ) as a function of time. The system is then driven between the states, and
         the populations present Rabi oscillations, as it is shown in Fig. 2.
                         Population

                          1.0


                          0.8


                          0.6


                          0.4


                          0.2


                                                                                          Time
                                        1            2           3             4      5

         FIG. 2: Population dynamics under a quantum dynamics (Parameters are â„¦ = 1, E = 1). The
         blue line represents Ï11 and the orange one Ï00 .
                                                                                                                        7

Finally, as we are interested in composite quantum systems, we need to postulate how to work with them.


Postulate 4 The state-space of a composite physical system, composed by N subsystems, is the tensor product of the
state space of each component H = H1 âŠ— H2 âŠ— Â· Â· Â· âŠ— HN . The state of the composite physical system is given by a
unit vector of H. Moreover, if each subsystem belonging to Hi is prepared in the state |Ïˆi i the total state is given by
|Ïˆi = |Ïˆ1 i âŠ— |Ïˆ2 i âŠ— Â· Â· Â· âŠ— |ÏˆN i.


The symbol âŠ— represents the tensor product of Hilbert spaces, vectors, and operators. If we have a composited mixed
state where each component is prepared in the state Ïi the total state is given by Ï = Ï1 âŠ— Ï2 âŠ— Â· Â· Â· âŠ— ÏN .
  States that can be expressed in the simple form |Ïˆi = |Ïˆ1 i âŠ— |Ïˆ2 i, in any specific basis, are very particular and they
are called separable states (For this discussion, we use a bipartite system as an example. The extension   P to a general
multipartite system is straightforward.) . In general, any arbitrary state should be described as |Ïˆi = i,j |Ïˆi i âŠ— |Ïˆj i
         P
(or Ï = i,j Ïi âŠ— Ïj for mixed states). Non-separable states are called entangled states.
  Now that we know how to compose systems, but we can be interested in going the other way around. If we have
a system belonging to a bipartite Hilbert space in the form H = Ha âŠ— Hb we can be interested in studying some
properties of the subsystem corresponding to one of the subspaces. To do so, we define the reduced density matrix. If
the state of our system is described by a density matrix Ï the reduced density operator of the subsystem a is defined
by the operator


                                                             Ïa â‰¡ Trb [Ï] ,                                          (18)

were Trb is the partial trace over subspace b and it is defined as [22]

                                  ï£®                              ï£¹                           ï£®            ï£¹
                                      X                                   X                   X
                              Trb ï£°          |ai ihaj | âŠ— |bk ihbl |ï£» â‰¡         |ai ihaj |Tr ï£°  |bk ihbl |ï£» .        (19)
                                   i,j,k,l                                i,j                 k,l


The concepts of reduced density matrix and partial trace are essential in the study of open quantum systems. If we
want to calculate the equation of motions of a system affected by an environment, we should trace out this environment
and deal only with the reduced density matrix of the system. This is the main idea of the theory of open quantum
systems.
                                                                                                        8


Box 4. Two two-level atoms
If we have two two-level systems,                     the total Hilbert space is given by
H = H2 âŠ— H 2 .               A basis of this Hilbert space would be given by the set
{|00i â‰¡ |0i1 âŠ— |0i2 , |01i â‰¡ |0i1 âŠ— |1i2 , |10i â‰¡ |1i1 âŠ— |0i2 , |11i â‰¡ |1i1 âŠ— |1i2 }. If both systems
are in their ground state, we can describe the total state by the separable vector


                                            |ÏˆiG = |00i.                                        (20)

A more complex, but still separable, state can be formed if both systems are in superposition.

                                    1                  1
                            |ÏˆiS = âˆš (|0i1 + |1i1 ) âŠ— âˆš (|0i2 + |1i2 )
                                     2                  2
                                   1
                                 = (|00i + |10i + |01i + |11i)                                  (21)
                                   2
An entangled state would be

                                             1
                                     |ÏˆiE = âˆš (|00i + |11i) .                                   (22)
                                              2
This state cannot be separated into a direct product of each subsystem. If we want to obtain a
reduced description of subsystem 1 (or 2) we have to use the partial trace. To do so, we need first
to calculate the density matrix corresponding to the pure state |ÏˆiE .

                                     1
                    ÏE = |ÏˆihÏˆ|E =     (|00ih00| + |00ih11| + |11ih00| + |11ih11|) .            (23)
                                     2
We can now calculate the reduced density matrix of the subsystem 1 by using the partial trace.


                      (1)                                 1
                     ÏE = h0|2 ÏE |0i2 + h1|2 ÏE |1i2 =     (|00ih00|1 + |11ih11|2 ) .          (24)
                                                          2
From this reduced density matrix, we can calculate all the measurement statistics of subsystem 1.
                                                                                                                        9

          IV.   THE FOCK-LIOUVILLE HILBERT SPACE. THE LIOUVILLE SUPEROPERATOR

   In this section, we revise a useful framework for both analytical and numerical calculations. It is clear that some
linear combinations of density matrices are valid density matrices (as long as they preserve positivity and trace 1).
Because of that, we can create a Hilbert space of density matrices just by defining a scalar product. This is clear
for finite systems because in this case scalar space and Hilbert space are the same things. It also happens to be true
for infinite spaces. This allows us to define a linear space of matrices, converting the matrices effectively into vectors
(Ï â†’ |Ïii). This is called Fock-Liouville space (FLS). The usual definition of the scalar product of matrices Ï† and Ï
is defined as hhÏ†|Ïii â‰¡ Tr Ï†â€  Ï . The Liouville super-operator from Eq. (13) is now an operator acting on the Hilbert
                                
space of density matrices. The main utility of the FLS is to allow the matrix representation of the evolution operator.



         Box 5. Time evolution of a two-level system.
         The density matrix of our system (3) can be expressed in the FLS as


                                                             Ï00
                                                            ï£« ï£¶
                                                            ï£¬Ï01 ï£·
                                                     |Ïii = ï£­ ï£¸ .                                          (25)
                                                             Ï10
                                                             Ï11


         The time evolution of a mixed state is given by the von-Neumann equation (13). The Liouvillian
         superoperator can now be expressed as a matrix


                                                   0  iâ„¦ âˆ’iâ„¦ 0
                                                ï£«               ï£¶
                                                ï£¬ iâ„¦ iE   0 âˆ’iâ„¦ ï£·
                                           LÌƒ = ï£­                 ,                                        (26)
                                                  âˆ’iâ„¦ 0 âˆ’iE iâ„¦ ï£¸
                                                   0 âˆ’iâ„¦ iâ„¦  0

         where each row is calculated just by observing the output of the operation âˆ’i [H, Ï] in the compu-
         tational basis of the density matrices space. The time evolution of the system now corresponds to
         the matrix equation d|Ïii
                                dt = LÌƒ|Ïii, that in matrix notation would be


                                      ÏÌ‡00      0  iâ„¦ âˆ’iâ„¦ 0     Ï00
                                     ï£« ï£¶ ï£«                   ï£¶ï£« ï£¶
                                     ï£¬ÏÌ‡01 ï£· ï£¬ iâ„¦ iE   0 âˆ’iâ„¦ ï£· ï£¬Ï01 ï£·
                                     ï£­ÏÌ‡ ï£¸ = ï£­ âˆ’iâ„¦ 0 âˆ’iE iâ„¦ ï£¸ ï£­Ï ï£¸                                         (27)
                                        10                       10
                                      ÏÌ‡11      0 âˆ’iâ„¦ iâ„¦  0     Ï11
                                                                                                                       10

                        V.   CPT-MAPS AND THE LINDBLAD MASTER EQUATION.

                                              A.   Completely positive maps

  The problem we want to study is to find the most general Markovian transformation set between density matrices.
Until now, we have seen that quantum systems can evolve in two way, by a coherent evolution given (Postulate 3) and
by collapsing after a measurement (Postulate 2). Many efforts have been made to unify these two ways of evolving
[16], without giving a definite answer so far. It is reasonable to ask what is the most general transformation that can
be performed in a quantum system, and what is the dynamical equation that describes this transformation.
  We are looking for maps that transform density matrices into density matrices. We define Ï(H) as the space of all
density matrices in the Hilbert space H. Therefore, we are looking for a map of this space onto itself, V : Ï(H) â†’ Ï(H).
To ensure that the output of the map is a density matrix this should fulfil the following properties

    â€¢ Trace preserving. Tr [VA] = Tr [A] , âˆ€A âˆˆ O(H).
    â€¢ Completely positive (see below).

   Any map that fulfils these two properties is called a completely positive and trace-preserving map (CPT-maps). The
first property is quite apparent, and it does not require more thinking. The second one is a little more complicated,
and it requires an intermediate definition.


Definition 1 A map V is positive iff âˆ€A âˆˆ B(H) s.t. A â‰¥ 0 â‡’ VA â‰¥ 0.


This definition is based in the idea that, as density matrices are positive, any physical map should transform positive
matrices into positive matrices. One could naively think that this condition must be sufficient to guarantee the
physical validity of a map. It is not. As we know, there exist composite systems, and our density matrix could be the
partial trace of a more complicated state. Because of that, we need to impose a more general condition.


Definition 2 A map V is completely positive iff âˆ€n âˆˆ N, V âŠ— 1n is positive.


To prove that not all positive maps are completely positive, we need a counterexample. A canonical example of an
operation that is positive but fails to be completely positive is the matrix transposition. If we have a Bell state in the
form |ÏˆB i = âˆš12 (|01i + |10i) its density matrix can be expressed as

                               1
                        ÏB =     (|0ih0| âŠ— |1ih1| + |1ih1| âŠ— |0ih0| + |0ih1| âŠ— |1ih0| + |1ih0| âŠ— |0ih1|) ,           (28)
                               2
with a matrix representation

                                                                         
                                         1     1 0       0 0       0 0       1 0
                                  ÏB =               âŠ—         +         âŠ—
                                         2     0 0       0 1       0 1       0 0
                                                                        
                                             0 0       0 1       0 1       0 0
                                         âŠ—         âŠ—         +         âŠ—           .                                 (29)
                                             1 0       0 0       0 0       1 0

A little algebra shows that the full form of this matrix is


                                                           0 0 0 0
                                                           ï£«       ï£¶
                                                         ï£¬0 1 1 0ï£·
                                                    ÏB = ï£­           ,                                               (30)
                                                           0 1 1 0ï£¸
                                                           0 0 0 0

and it is positive.
                                                                                                                 11




 FIG. 3: A total system (belonging to a Hilbert space HT , with states described by density matrices ÏT , and with
 dynamics determined by a Hamiltonian HT ) divided into the system of interest, â€˜Systemâ€™, and the environment.


   It is easy to check that the transformation 1 âŠ— T2 , meaning that we transpose the matrix of the second subsystem
leads to a non-positive matrix
                                                                          
                                           1    1 0       0 1       0 0       0 0
                            (1 âŠ— T2 ) ÏB =            âŠ—         +         âŠ—
                                           2    0 0       0 0       0 1       1 0
                                                                         
                                              0 0       0 0       0 0       0 1
                                          âŠ—         âŠ—         +         âŠ—           .                          (31)
                                              1 0       1 0       0 1       0 0
The total matrix is

                                                                0 0 0 1
                                                              ï£«         ï£¶
                                                              ï£¬0 1 0 0ï£·
                                               (1 âŠ— T2 ) ÏB = ï£­           ,                                    (32)
                                                                0 0 1 0ï£¸
                                                                1 0 0 0
with âˆ’1 as an eigenvalue. This example illustrates how the non-separability of quantum mechanics restrict the
operations we can perform in a subsystem. By imposing this two conditions, we can derive a unique master equation
as the generator of any possible Markovian CPT-map.


                      B.   Derivation of the Lindblad Equation from microscopic dynamics

  The most common derivation of the Lindblad master equation is based on Open Quantum Theory. The Lindblad
equation is then an effective motion equation for a subsystem that belongs to a more complicated system. This
derivation can be found in several textbooks like Breuer and Petruccioneâ€™s [2] as well as Gardiner and Zollerâ€™s [1].
Here, we follow the derivation presented in Ref. [26]. Our initial point is displayed in Figure 3. A total system
belonging to a Hilbert space HT is divided into our system of interest, belonging to a Hilbert space H, and the
environment living in HE .
  The evolution of the total system is given by the von Neumann equation (13).


                                                 ÏË™T (t) = âˆ’i [HT , ÏT (t)] .                                  (33)
                                                                                                                        12

As we are interested in the dynamics of the system, without the environment, we trace over the environment degrees
of freedom to obtain the reduced density matrix of the system Ï(t) = TrE [ÏT ]. To separate the effect of the total
hamiltonian in the system and the environment we divide it in the form HT = HS âŠ— 1E + 1S âŠ— HE + Î±HI , with
H âˆˆ H, HE âˆˆ HE , and HI âˆˆ HT , and being Î± a measure of the strength of the system-environment interaction.
Therefore, we have a part acting on the system, a part acting on the environment, and the interaction term. Without
losing any generality, the interaction term can be decomposed in the following way

                                                                  X
                                                          HI =            Si âŠ— Ei ,                                   (34)
                                                                      i

with Si âˆˆ B(H) and Ei âˆˆ B(HE )3 .
  To better describe the dynamics of the system, it is useful to work in the interaction picture (see Ref. [24] for
a detailed explanation about SchroÌˆdinger, Heisenberg, and interaction pictures). In the interaction picture, density
matrices evolve with time due to the interaction Hamiltonian, while operators evolve with the system and environment
Hamiltonian. An arbitrary operator O âˆˆ B(HT ) is represented in this picture by the time-dependent operator OÌ‚(t),
and its time evolution is


                                                  OÌ‚(t) = ei(H+HE )t O eâˆ’i(H+HE )t .                                  (35)

The time evolution of the total density matrix is given in this picture by

                                                    dÏÌ‚T (t)      h                i
                                                             = âˆ’iÎ± HÌ‚I (t), ÏÌ‚T (t) .                                 (36)
                                                       dt
This equation can be easily integrated to give

                                                                      Z t       h                i
                                            ÏÌ‚T (t) = ÏÌ‚T (0) âˆ’ iÎ±            ds HÌ‚I (s), ÏÌ‚T (s) .                   (37)
                                                                          0

By this formula, we can obtain the exact solution, but it still has the complication of calculating an integral in the
total Hilbert space. It is also troublesome the fact that the state ÏÌƒ(t) depends on the integration of the density matrix
in all previous time. To avoid that we can introduce Eq. (37) into Eq. (36) giving

                                                                    Z t h
                               dÏÌ‚T (t)      h                i                   h                ii
                                        = âˆ’iÎ± HÌ‚I (t), ÏÌ‚T (0) âˆ’ Î±2    ds HÌ‚I (t), HÌ‚I (s), ÏÌ‚T (s) .                 (38)
                                  dt                                 0

By applying this method one more time we obtain

                                                               Z t h
                          dÏÌ‚T (t)      h                i                   h                ii
                                   = âˆ’iÎ± HÌ‚I (t), ÏÌ‚T (0) âˆ’ Î±2    ds HÌ‚I (t), HÌ‚I (s), ÏÌ‚T (t) + O(Î±3 ).              (39)
                             dt                                 0

After this substitution, the integration of the previous states of the system is included only in the terms that are O(Î±3 )
or higher. At this moment, we perform our first approximation by considering that the strength of the interaction
between the system and the environment is small. Therefore, we can avoid high-orders in Eq. (39). Under this
approximation we have

                                                                     Z t h
                               dÏÌ‚T (t)      h                i
                                                                   2
                                                                                   h                ii
                                        = âˆ’iÎ± HÌ‚I (t), ÏÌ‚T (0) âˆ’ Î±      ds HÌ‚I (t), HÌ‚I (s), ÏÌ‚T (t) .                (40)
                                  dt                                  0

We are interested in finding an equation of motion for Ï, so we trace over the environment degrees of freedom



3 From now on we will not writethe identity operators of the Hamil-
                                                                               text.
  tonian parts explicitly when they can be inferred from the con-
                                                                                                                     13


                                                                       Z t
               dÏÌ‚(t)         dÏÌ‚T (t)           h                i
                                                                       2
                                                                                  h        h                ii
                      = TrE              = âˆ’iÎ±TrE HÌ‚I (t), ÏÌ‚T (0) âˆ’ Î±       dsTrE HÌ‚I (t), HÌ‚I (s), ÏÌ‚T (t) .     (41)
                dt               dt                                       0

This is not a closed time-evolution equation for ÏÌ‚(t), because the time derivative still depends on the full density
matrix ÏÌ‚T (t). To proceed, we need to make two more assumptions. First, we assume that t = 0 the system
and the environment have a separable state in the form ÏT (0) = Ï(0) âŠ— ÏE (0). This means that there are not
correlations between the system and the environment. This may be the case if the system and the environment have
not interacted at previous times or if the correlations between them are short-lived. Second, we assume that the
initial state of the environment is thermal, meaning that it is described by a density matrix in the form ÏE (0) =
exp (âˆ’HE /T ) /Tr[exp (âˆ’HE /T )], being T the temperature and taking the Boltzmann constant as kB = 1. By using
these assumptions, and the expansion of HI (34), we can calculate an expression for the first element of the r.h.s of
Eq. (41).

                   h                i X                h              i                 h              i
                TrE HÌ‚I (t), ÏÌ‚T (0) =   SÌ‚i (t)ÏÌ‚(0)TrE EÌ‚i (t)ÏÌ‚E (0) âˆ’ ÏÌ‚(0)SÌ‚i (t)TrE ÏÌ‚E (0)EÌ‚i (t) .         (42)
                                         i

To calculate the explicit value of this term, we may use that hEi i = Tr[Ei ÏE (0)] = 0 for all values of i. This
looks like a strongPassumption, but it is not. If our total
                                                          P Hamiltonian does not fulfil it, we can always     rewrite it
as HT = (H + Î± i hEi i Si ) + HE + Î±Hi0 , with Hi0 =         S
                                                            i i âŠ—  (E i âˆ’ hEi i). It is clear that now hEi
                                                                                                          0
                                                                                                            i = 0, with
Ei0 = Ei âˆ’ hEi i, and the system Hamiltonian is changed just by the addition of an energy shift that does no affect the
system dynamics. Because of that, we can assume that hEi i = 0 for all i. Using the cyclic property of the trace, it is
easy to prove that the term of Eq. (42) is equal to zero, and the equation of motion (41) reduces to

                                                       Z t        h        h                ii
                                      Ë™ = âˆ’Î±2
                                     ÏÌ‚(t)                   dsTrE HÌ‚I (t), HÌ‚I (s), ÏÌ‚T (t) .                     (43)
                                                        0

This equation still includes the entire state of the system and environment. To unravel the system from the envi-
ronment, we have to make a more restrictive assumption. As we are working in the weak coupling regime, we may
suppose that the system and the environment are non-correlated during all the time evolution. Of course, this is
only an approximation. Due to the interaction Hamiltonian, some correlations between system and environment are
expected to appear. On the other hand, we may assume that the timescales of correlation (Ï„corr ) and relaxation of the
environment (Ï„rel ) are much smaller than the typical system timescale (Ï„sys ), as the coupling strength is very small
(Î± <<). Therefore, under this strong assumption, we can assume that the environment state is always thermal and
is decoupled from the system state, ÏÌ‚T (t) = ÏÌ‚(t) âŠ— ÏÌ‚E (0). Eq. (43) then transforms into

                                                 Z t        h        h                        ii
                                 Ë™ÏÌ‚(t) = âˆ’Î±2          dsTrE HÌ‚I (t), HÌ‚I (s), ÏÌ‚(t) âŠ— ÏÌ‚E (0) .                   (44)
                                                  0

The equation of motion is now independent for the system and local in time. It is still non-Markovian, as it depends
on the initial state preparation of the system. We can obtain a Markovian equation by realising that the kernel in the
integration and that we can extend the upper limit of the integration to infinity with no real change in the outcome.
By doing so, and by changing the integral variable to s â†’ t âˆ’ s, we obtain the famous Redfield equation [? ].

                                             Z âˆ           h        h                            ii
                                Ë™ = âˆ’Î±2
                               ÏÌ‚(t)                  dsTrE HÌ‚I (t), HÌ‚I (s âˆ’ t), ÏÌ‚(t) âŠ— ÏÌ‚E (0) .                (45)
                                             0

It is known that this equation does not warrant the positivity of the map, and it sometimes gives rise to density
matrices that are non-positive. To ensure complete positivity, we need to perform one further approximation, the
rotating wave approximation. To do so, we need to use the spectrum of the superoperator HÌƒA â‰¡ [H, A], âˆ€A âˆˆ B(H).
The eigenvectors of this superoperator form a complete basis of space B(H) and, therefore, we can expand the
system-environment operators from Eq. (34) in this basis

                                                                    X
                                                             Si =       Si (Ï‰),                                    (46)
                                                                    Ï‰
                                                                                                                              14

where the operators Si (Ï‰) fulfils


                                                           [H, Si (Ï‰)] = âˆ’Ï‰Si (Ï‰),                                           (47)

being Ï‰ the eigenvalues of HÌƒ. It is easy to take also the Hermitian conjugated

                                                           h          i
                                                            H, Siâ€  (Ï‰) = Ï‰Siâ€  (Ï‰).                                           (48)

To apply this decomposition, we need to change back to the SchroÌˆdinger picture for the term of the interaction
Hamiltonian acting on the systemâ€™s Hilbert space. This is done by the expression SÌ‚k = eitH Sk eâˆ’itH . By using the
eigen-expansion (46) we arrive to


                                                                                     eiÏ‰t Skâ€  (Ï‰) âŠ— EÌƒkâ€  (t).
                                              X                                X
                                  HÌƒi (t) =         eâˆ’iÏ‰t Sk (Ï‰) âŠ— EÌƒk (t) =                                                 (49)
                                              k,Ï‰                              k,Ï‰

To combine this decomposition with Redfield equation (45), we first may expand the commutators.

                       Z âˆ                                       Z âˆ
         Ë™ = âˆ’Î±2 Tr
        ÏÌ‚(t)              ds HÌ‚I (t)HÌ‚I (t âˆ’ s)ÏÌ‚(t) âŠ— ÏÌ‚E (0) âˆ’     ds HÌ‚I (t)ÏÌ‚(t) âŠ— ÏÌ‚E (0)HÌ‚I (t âˆ’ s)
                        0                                          0
                      Z âˆ                                        Z âˆ                                     
                    âˆ’     ds HÌ‚I (t âˆ’ s)ÏÌ‚(t) âŠ— ÏÌ‚E (0)HÌ‚I (t) +     ds ÏÌ‚(t) âŠ— ÏÌ‚E (0)HÌ‚I (t âˆ’ s)HÌ‚I (t) .                  (50)
                        0                                               0

We now apply the eigenvalue decomposition in terms of Sk (Ï‰) for HÌ‚I (t âˆ’ s) and in terms of Skâ€  (Ï‰ 0 ) for HÌ‚I (t). By
using the permutation property of the trace and the fact that [HE , ÏE (0)] = 0, and after some non-trivial algebra we
obtain

                       X          0
                                                h                       i        0
                                                                                                h                       i
                Ë™ =
               ÏÌ‚(t)           ei(Ï‰ âˆ’Ï‰)t Î“kl (Ï‰) Sl (Ï‰)ÏÌ‚(t), Skâ€  (Ï‰ 0 ) + ei(Ï‰âˆ’Ï‰ )t Î“âˆ—lk (Ï‰ 0 ) Sl (Ï‰), ÏÌ‚(t)Skâ€  (Ï‰ 0 ) ,   (51)
                       Ï‰,Ï‰ 0
                        k,l

where the effect of the environment has been absorbed into the factors

                                                     Z âˆ              h                         i
                                       Î“kl (Ï‰) â‰¡           ds eiÏ‰s TrE EÌƒkâ€  (t)EÌƒl (t âˆ’ s)ÏE (0) ,                           (52)
                                                       0

where we are writing the environment operators of the interaction Hamiltonian in the interaction picture (EÌ‚l (t) =
eiHE t El eâˆ’iHE t ). At this point, we can already perform the rotating wave approximation. By considering the time-
dependency on Eq. (51), we conclude that the terms with |Ï‰ âˆ’ Ï‰ 0 | >> Î±2 will oscillate much faster than the typical
timescale of the system evolution. Therefore, they do not contribute to the evolution of the system. In the low-
coupling regime (Î± â†’ 0) we can consider that only the resonant terms, Ï‰ = Ï‰ 0 , contribute to the dynamics and
remove all the others. By applying this approximation to Eq. (51) reduces to

                                    X            h                    i          h                    i
                             Ë™ =
                            ÏÌ‚(t)          Î“kl (Ï‰) Sl (Ï‰)ÏÌ‚(t), Skâ€  (Ï‰) + Î“âˆ—lk (Ï‰) Sl (Ï‰), ÏÌ‚(t)Skâ€  (Ï‰) .                    (53)
                                     Ï‰
                                     k,l

To divide the dynamics into Hamiltonian and non-Hamiltonian we now decompose the operators Î“kl into Hermitian
and non-Hermitian parts, Î“kl (Ï‰) = 21 Î³kl (Ï‰) + iÏ€kl , with

                                                                           âˆ’i
                                                                Ï€kl (Ï‰) â‰¡     (Î“kl (Ï‰) âˆ’ Î“âˆ—kl (Ï‰))
                                                                Z âˆ        2
                                                                               h                  i
                                 Î³kl (Ï‰) â‰¡ Î“kl (Ï‰) + Î“âˆ—kl (Ï‰) =       dseiÏ‰s Tr EÌ‚kâ€  (s)El ÏÌ‚E (0) .                         (54)
                                                                      âˆ’âˆ
                                                                                                                            15

By these definitions we can separate the Hermitian and non-Hermitian parts of the dynamics and we can transform
back to the SchroÌˆdinger picture
                                                              
                                                                                   1n â€              o
                                                       Î³kl (Ï‰) Sl (Ï‰)Ï(t)Skâ€  (Ï‰) âˆ’
                                                    X
                    ÏÌ‡(t) = âˆ’i [H + HLs , Ï(t)] +                                    Sk Sl (Ï‰), Ï(t)   .                   (55)
                                                     Ï‰                             2
                                                     k,l

The Hamiltonian dynamics now is influenced by a term HLs = Ï‰,k,l Ï€kl (Ï‰)Skâ€  (Ï‰)Sl (Ï‰). This is usually called a Lamb
                                                               P
shift Hamiltonian and its role is to renormalize the system energy levels due to the interaction with the environment.
Eq. (55) is the first version of the Markovian Master Equation, but it is not in the Lindblad form yet.
  It can be easily proved that    the hmatrix formedi
                                                      by the coefficients Î³kl (Ï‰) is positive as they are the Fourierâ€™s
transform of a positive function Tr EÌ‚kâ€  (s)El ÏÌ‚E (0)            . Therefore, this matrix can be diagonalised. This means that
we can find a unitary operator, O, s.t.
                                                          ï£«                                     ï£¶
                                                  d1 (Ï‰)    0   Â·Â·Â·                        0
                                                ï£¬ 0      d2 (Ï‰) Â· Â· Â·                      0    ï£·
                                      OÎ³(Ï‰)Oâ€  = ï£¬ .                                             ï£·.                         (56)
                                                ï£¬                                               ï£·
                                                            ..   ..
                                                ï£­ ..         .      .                  0        ï£¸
                                                                  0       0    Â· Â· Â· dN (Ï‰)
We can now write the master equation in a diagonal form

                                                   X                             1        n                o
                   ÏÌ‡(t) = âˆ’i [H + HLs , Ï(t)] +              Li (Ï‰)Ï(t)Lâ€ i (Ï‰) âˆ’            â€ 
                                                                                            Li Li (Ï‰), Ï(t)    â‰¡ LÏ(t).    (57)
                                                    i,Ï‰
                                                                                       2

This is the celebrated Lindblad (or Lindblad-Gorini-Kossakowski-Sudarshan) Master Equation. In the simplest case,
there will be only one relevant frequency Ï‰, and the equation can be further simplified to

                                                           X                      1   n             o
                        ÏÌ‡(t) = âˆ’i [H + HLs , Ï(t)] +                 Li Ï(t)Lâ€ i âˆ’       â€ 
                                                                                        Li Li , Ï(t)    â‰¡ LÏ(t).           (58)
                                                              i
                                                                                  2
The operators Li are usually referred to as jump operators.


                          C.   Derivation of the Lindblad Equation as a CPT generator

   The second way of deriving Lindblad equation comes from the following question: What is the most general
(Markovian) way of mapping density matrix onto density matrices? This is usually the approach from quantum
information researchers that look for general transformations of quantum systems. We analyse this problem following
mainly Ref. [28].
   To start, we need to know what is the form of a general CPT-map.


Lemma 2 Any map V : B (H) â†’ B (H) that can be written in the form VÏ = V â€  ÏV with V âˆˆ B (H) is positive.


The proof of the lemma requires a little algebra and a known property of normal matrices

Proof.
If Ï â‰¥ 0 â‡’ Ï = Aâ€  A , with A âˆˆ B(H). Therefore, VÏ = V â€  ÏV â‡’ hÏˆ|V â€  ÏV |Ïˆi = hÏˆ|V â€  Aâ€  AV |Ïˆi = ||AV |Ïˆi|| â‰¥ 0.
Therefore, if Ï is positive, the output of the map is also positive.
End of the proof.

This is a sufficient condition for the positivity of a map, but it is not necessary. It could happen that there are maps
that cannot be written in this form, but they are still positive. To go further, we need a more general condition, and
this comes in the form of the next theorem.
                                                                                                                       16

Theorem 1 Choiâ€™s Theorem.
A linear map V : B(H) â†’ B(H) is completely positive iff it can be expressed as


                                                                  Viâ€  ÏVi
                                                           X
                                                   VÏ =                                                           (59)
                                                             i

with Vi âˆˆ B(H).


The proof of this theorem requires some algebra.

Proof
The â€˜ifâ€™ implication is a trivial consequence of the previous lemma. To prove the converse, we need to extend the
dimension of our system by the use of an auxiliary system. If d is the dimension of the Hilbert space of pure states,
H, we define a new Hilbert space of the same dimension HA .
  We define a maximally entangled pure state in the bipartition HA âŠ— H in the way

                                                          dâˆ’1
                                                          X
                                                  |Î“i â‰¡          |iiA âŠ— |ii,                                      (60)
                                                          i=0

being {|ii} and {|iiA } arbitrary orthonormal bases for H and HA .
  We can extend the action of our original map V, that acts on B(H) to our extended Hilbert space by defining the
map V2 : B(HA ) âŠ— B(H) â†’ B(HA ) âŠ— B(H) as


                                                   V2 â‰¡ 1B(HA ) âŠ— V.                                              (61)

Note that the idea behind this map is to leave the auxiliary subsystem invariant while applying the original map to
the original system. This map is positive because V is completely positive. This may appear trivial, but as it has been
explained before complete positivity is a more restrictive property than positivity, and we are looking for a condition
to ensure complete positivity.
  We can now apply the extended map to the density matrix corresponding to the maximally entangled state (60),
obtaining

                                                          dâˆ’1
                                                          X
                                            V2 |Î“ihÎ“| =           |iihj| âŠ— V|iihj|.                               (62)
                                                          i,j=0

Now we can use the maximal entanglement of the state |Î“i to relate the original map V and the action V2 |Î“ihÎ“| by
taking the matrix elements with respect to HA .


                                             V|iihj| = hi|A (V2 |Î“ihÎ“|) |jiA .                                    (63)

To relate this operation to the action of the map to an arbitrary vector |Ïˆi âˆˆ HA âŠ— H, we can expand it in this basis
as

                                                      dâˆ’1 X
                                                      X   dâˆ’1
                                              |Ïˆi =              Î±ij |iiA âŠ— |ji.                                  (64)
                                                      i=0 j=0

We can also define an operator V|Ïˆi âˆˆ B (H) s.t. it transforms |Î“i into |Ïˆi. Its explicit action would be written as

                       Pdâˆ’1                     P              P
                                                 dâˆ’1                dâˆ’1
        1A âŠ— V|Ïˆi |Î“i = i,j=0 Î±ij (1A âŠ— |jihi|)   k=0 |ki âŠ— |ki =    i,j,k=0 Î±ij (|ki âŠ— |ji) hi|ki
                                Pdâˆ’q                           Pdâˆ’1
                              = i,j,k=0 Î±ij (|ki âŠ— |ji) Î´i,k = i,j=0 Î±ij |ii âŠ— |ji = |Ïˆi.                         (65)
                                                                                                                            17

At this point, we have related the vectors in the extended space HA âŠ— H to operators acting on H. This can only be
done because the vector |Î“i is maximally entangled. We go now back to our extended map V2 . Its action on |Î“ihÎ“| is
given by Eq. (62) and as it is a positive map it can be expanded as

                                                                       2
                                                                      dX âˆ’1
                                                    V2 (|Î“ihÎ“|) =             |vl ihvl |.                                  (66)
                                                                        l=0

with |vl i âˆˆ HA âŠ— H. The vectors |vl i can be related to operators in H as in Eq. (65).


                                                       |vl i = (1A âŠ— Vl ) |Î“i.                                             (67)

Based on this result we can calculate the product of an arbitrary vector |iiA âˆˆ HA with |vl i.

                                                                                  dâˆ’1
                                                                                  X
                                     hi|A |vl i = hi|A (1A âŠ— Vl ) |Î“i = Vl              hi|kiA âŠ— |ki.                      (68)
                                                                                  k=0

This is the last ingredient we need for the proof.
  We come back to the original question, we want to characterise the map V. We do so by applying it to an arbitrary
basis element |iihj| of B (H).

                                                                           ï£® 2              ï£¹
                                                                            dX âˆ’1
         V (|iihj|) = (hi|A âŠ— 1A ) V2 (|Î“ihÎ“|) (|jiA âŠ— 1A ) = (hi|A âŠ— 1A ) ï£°      |vl ihvl |ï£» (|jiA âŠ— 1A )
                                                                                        l=0
                                             2                                                      2
                                              âˆ’1
                                             dX                                                    dX âˆ’1
                                         =         [(hi|A âŠ— 1A ) |vl i] [hvl | (|jiA âŠ— 1A )] =             Vl |iihj|Vl .   (69)
                                             l=0                                                   l=0

As |iihj| is an arbitrary element of a basis any operator can be expanded in this basis. Therefore, it is straightforward
to prove that

                                                                 2
                                                                dX âˆ’l
                                                        VÏ =            Vlâ€  ÏVl .
                                                                  l


End of the proof.

Thanks to Choiâ€™s Theorem, we know the general form of CP-maps, but there is still an issue to address. As density
matrices should have trace one, we need to require any physical maps to be also trace-preserving. This requirement
gives as a new constraint that completely defines all CPT-maps. This requirement comes from the following theorem.


Theorem 2 Choi-Krausâ€™ Theorem.
A linear map V : B(H) â†’ B(H) is completely positive and trace-preserving iff it can be expressed as


                                                                        Vlâ€  ÏVl
                                                                X
                                                         VÏ =                                                              (70)
                                                                  l

with Vl âˆˆ B(H) fulfilling


                                                               Vl Vlâ€  = 1H .
                                                          X
                                                                                                                           (71)
                                                           l
                                                                                                                          18

Proof.
We have already proved that this is a completely positive map, we only need to prove that it is also trace-preserving
and that all trace preserving-maps fulfil Eq. (71). The â€˜ifâ€™ proof is quite simple by applying the cyclic permutations
and linearity properties of the trace operator.

                                          ï£® 2           ï£¹      ï£®ï£« 2          ï£¶ ï£¹
                                           dX âˆ’1                 dX âˆ’1
                             Tr [VÏ] = Tr ï£°      V ÏV â€  ï£» = Tr ï£°ï£­
                                                        l        l     V â€  V ï£¸ Ïï£» = Tr [Ï] .l    l                      (72)
                                                l=1                                  l=1

We have to prove also that any map in the form (70) is trace-preserving only if the operators Vl fulfil (71). We start
by stating that if the map is trace-preserving by applying it to an any arbitrary element of a basis of B (H) we should
obtain


                                                Tr [V (|iihj|)] = Tr [|iihj|] = Î´i,j .                                  (73)
As the map has a form given by (70) we can calculate this same trace in an alternative way.

                                               ï£® 2                ï£¹      ï£® 2                ï£¹
                                                dX âˆ’1                     dX âˆ’1
                          Tr [V (|iihj|)] = Tr ï£°      V |iihj|V â€  ï£» = Tr ï£°
                                                             l               l  V â€  V |iihj|ï£»        l   l
                                                  l=1                                      l=1
                                                    ï£« 2              ï£¶           ï£« 2        ï£¶
                                                      dXâˆ’1                         dXâˆ’1
                                                            â€                             â€ 
                                            X
                                        =       hk| ï£­      V V |iihj|ï£¸ |ki = hj| ï£­
                                                                     l       l          V V ï£¸ |ii,             l   l    (74)
                                            k               l=1                                          l=1

where {|ki} is an arbitrary basis of H. As both equalities should be right we obtain

                                                      ï£« 2          ï£¶
                                                        dXâˆ’1
                                                  hj| ï£­      V V â€  ï£¸ |ii = Î´i,j ,
                                                                         l       l                                      (75)
                                                             l=1

and therefore, the condition (71) should be fulfilled.
End of the proof.

Operators Vi of a map fulfilling condition (71) are called Krauss operators. Because of that, sometimes CPT-maps
are also called Krauss maps, especially when they are presented as a collection of Krauss operators. Both concepts
are ubiquitous in quantum information science. Krauss operators can also be time-dependent as long as they fulfil
relation (71) for all times.
   At this point, we already know the form of CPT-maps, but we do not have a master equation, that is a continuous
set of differential equations. This means that we know how to perform an arbitrary operation in a system, but we do
not have an equation to describe its time evolution. To do so, we need to find a time-independent generator L such
that

                                                             d
                                                                Ï (t) = LÏ(t),                                          (76)
                                                             dt
and therefore our CPT-map could be expressed as V(t) = eLt . The following calculation is about founding the explicit
                                                                                                          d2
expression of L. We start by choosing an orthonormal basis of the bounded space of operators B(H), {Fi }i=1 . To be
orthonormal it should satisfy the following condition

                                                                 h      i
                                                 hhFi |Fj ii â‰¡ Tr Fiâ€  Fj = Î´i,j .                                       (77)

Without any loss of generality, we select one of the elements of the basis to be proportional to the identity, Fd2 = âˆš1d 1H .
It is trivial to prove that the norm of this element is one, and it is easy to see from Eq. (77) that all the other elements
of the basis should have trace zero.
                                                                                                                           19



                                           Tr [Fi ] = 0   âˆ€i = 1, . . . , d2 âˆ’ 1.                                (78)
                                               P
The closure relation of this basis is 1B(H) = i |Fi iihhFi |. Therefore, the Krauss operators can be expanded in this
basis by using the Fock-Liouville notation

                                                                         2
                                                                        d
                                                                        X
                                                             Vl (t) =         hhFi |Vl (t)ii|Fi ii.                       (79)
                                                                        i=1

As the map V(t) is in the form (59) we can apply (79) to obtain4 .

                           ï£® 2                                       ï£¹
                            d                   d2                       d2
                                                   Fjâ€  hhVl (t)|Fj iiï£» =    ci,j (t)Fi ÏFjâ€  ,
                          X X                   X                        X
                  V(t)Ï =  ï£° hhFi |Vl (t)iiFi Ï                                                                           (80)
                             l     i=1                          j=1                             i,j=1
                                                                                        P
where we have absorved the sumation over the Krauss operators in the terms ci,j (t) = l hhFi |Vl iihhVl |Fj ii. We go
back now to the original problem by applying this expansion into the time-derivative of Eq. (76)

                                                                     ï£« 2                         ï£¶
                                                                          d
                                 dÏ        1                             X                  â€ 
                                    = lim    (V(âˆ†t)Ï âˆ’ Ï) = lim ï£­             ci,j (âˆ†t)Fi ÏFj âˆ’ Ïï£¸
                                 dt  âˆ†tâ†’0 âˆ†t                   âˆ†tâ†’0
                                                                        i,j=1
                                          ï£« 2                        2
                                            dXâˆ’1                    dX âˆ’1
                                    = lim ï£­      ci,j (âˆ†t)Fi ÏFjâ€  +       ci,d2 Fi ÏFdâ€ 2
                                         âˆ†tâ†’0
                                                     i,j=0                            i=1
                                              2
                                                                                                          ï£¶
                                             dX âˆ’1
                                         +           cd2 ,j (âˆ†t)Fd2 ÏFjâ€  + cd2 ,d2 (âˆ†t)Fd2 ÏFdâ€ 2 âˆ’ Ïï£¸ ,                   (81)
                                             j=1


where we have separated the summations to take into account that Fd2 = âˆš1d 1H . By using this property this equation
simplifies to

                                                 ï£« 2
                                                   d âˆ’1                          d2 âˆ’1
                                  dÏ          1 ï£­X                            1 X
                                     = lim                ci,j (âˆ†t)Fi ÏFjâ€  + âˆš         ci,d2 (âˆ†t)Fi Ï
                                  dt   âˆ†tâ†’0 âˆ†t
                                                   i,j=1
                                                                               d i=1
                                            2
                                                                                       ï£¶
                                           dX âˆ’1
                                        1                           1
                                     + âˆš         cd2 ,j (âˆ†t)ÏFjâ€  + cd2 ,d2 (âˆ†t)Ï âˆ’ Ïï£¸ .                                   (82)
                                         d j=1                      d

The next step is to eliminate the explicit dependence with time. To do so, we define new constants to absorb all the
time intervals.

                                                                   ci,j (âˆ†t)
                                                       gi,j â‰¡ lim                 (i, j < d2 ),
                                                                âˆ†tâ†’0  âˆ†t
                                                                   ci,d2 (âˆ†t)
                                                      gi,d2 â‰¡ lim                  (i < d2 ),
                                                              âˆ†tâ†’0     âˆ†t
                                                                   cd2 ,j (âˆ†t)
                                                      gd2 ,j â‰¡ lim                 (j < d2 ),                             (83)
                                                              âˆ†tâ†’0      âˆ†t
                                                                   cd2 ,d2 (âˆ†t) âˆ’ d
                                                     gd2 ,d2 â‰¡ lim                  .
                                                              âˆ†tâ†’0         âˆ†t


4   For simplicity, in this discussion we omit the explicit time-                     dependency of the density matrix.
                                                                                                                                20

Introducing these coefficients in Eq (82) we obtain an equation with no explicit dependence in time.

                               2                            2                        2
                             dX âˆ’1                    d âˆ’1                  d âˆ’1
                        dÏ                         1 X                   1 X                   gd2 ,d2
                           =       gi,j Fi ÏFjâ€  + âˆš        gi,d2 Fi Ï + âˆš        gd2 ,j ÏFjâ€  +         Ï.
                        dt   i,j=1
                                                    d i=1                 d j=1                  d
                                                                                                                           (84)
As we are already summing up over all the Krauss operators it is useful to define a new operator

                                                                  d2 âˆ’1
                                                            1 X
                                                        F â‰¡âˆš       gi,d2 Fi .                                              (85)
                                                             d i=1

Applying it to Eq. (82).

                                               2
                                            dX âˆ’1
                                       dÏ                                     gd2 ,d2
                                          =       gi,j Fi ÏFjâ€  + F Ï + ÏF â€  +         Ï.                                   (86)
                                       dt   i,j=1
                                                                                d

At this point, we want to separate the dynamics of the density matrix into a Hermitian (equivalent to von Neunmann
equation) and an incoherent part. We split the operator F in two to obtain a Hermitian and anti-Hermitian part.

                                                       F + Fâ€     F âˆ’ Fâ€ 
                                           F =                +i        â‰¡ G âˆ’ iH,                                          (87)
                                                         2         2i
where we have used the notation H for the Hermitian part for obvious reasons. If we take this definition to Eq. (86)
we obtain

                                       dÏ                                      gd2 ,d2
                                          = gi,j Fi ÏFjâ€  + {G, Ï} âˆ’ i [H, Ï] +         Ï.                                  (88)
                                       dt                                        d
                                                                    gd2 ,d2
We define now the last operator for this proof, G2 â‰¡ G +              2d , and the expression of the time derivative leads to


                                                   2
                                              dX âˆ’1
                                         dÏ
                                            =       gi,j Fi ÏFjâ€  + {G2 , Ï} âˆ’ i [H, Ï] .                                   (89)
                                         dt   i,j=1

Until now we have imposed the complete positivity of the map, as we have required it to be written in terms of Krauss
maps, but we have not used the trace-preserving property. We impose now this property, and by using the cyclic
property of the trace, we obtain a new condition

                                                     ï£® 2                   ï£¹
                                                     dXâˆ’1
                                           dÏ                â€ 
                                        Tr      = Tr ï£°      Fj Fi Ï + 2G2 Ïï£» = 0.                                          (90)
                                           dt         i,j=1

Therefore, G2 should fulfil

                                                                d2 âˆ’1
                                                            1 X
                                                       G2 =         gi,j Fjâ€  Fi Ï.                                         (91)
                                                            2 i,j=1

By applying this condition, we arrive at the Lindblad master equation

                                                      2
                                                    dX  âˆ’1                          o
                                   dÏ                                     1n â€ 
                                      = âˆ’i [H, Ï] +        gi,j Fi ÏFjâ€  âˆ’   Fj Fi , Ï   .                                  (92)
                                   dt               i,j=1
                                                                          2
                                                                                                                      21

Finally, by definition the coefficients gi,j can be arranged to form a Hermitian, and therefore diagonalisable, matrix.
By diagonalising it, we obtain the diagonal form of the Lindblad master equation.


                              d                  X            1n          o
                                 Ï = âˆ’i [H, Ï] +  Î“k Lk ÏLâ€ k âˆ’   Lk Lâ€ k , Ï   â‰¡ LÏ.                                  (93)
                              dt                               2
                                                   k



                                D.    Properties of the Lindblad Master Equation

  Some interesting properties of the Lindblad equation are:
                                                                                                        d
                                                                                                              
   â€¢ Under a Lindblad dynamics, if all the jump operators are Hermitian, the purity of a system fulfils dt Tr Ï2 â‰¤
     0. The proof is given in A.
   â€¢ The Lindblad Master Equation is invariant under unitary transformations of the jump operators

                                          p                        X p
                                                         Î“0i L0i =
                                                        p
                                              Î“i Li â†’               vij Î“j Lj ,                                      (94)
                                                                  j

     with v representing a unitary matrix. It is also invariant under inhomogeneous transformations in the form



                                     Li â†’ L0i = Li + ai
                                                      1 X  âˆ—              
                                     H â†’ H0 = H +         Î“j aj Aj âˆ’ aj Aâ€ j + b,                                     (95)
                                                     2i j

     where ai âˆˆ C and b âˆˆ R. The proof of this can be found in Ref. [2] (Section 3).
   â€¢ Thanks to the previous properties it is possible to find traceless jump operators without loss of generality.
                                                                                                       22


Box 6. A master equation for a two-level system with decay.
Continuing our example of a two-level atom, we can make it more realistic by including the pos-
sibility of atom decay by the emission of a photon. This emission happens due to the interaction
of the atom with the surrounding vacuum statea . The complete quantum system would be in
this case the â€˜atom+vacuumâ€™ system and its time evolution should be given by the von Neumann
equation (13), where H represents the total â€˜atom+vacuumâ€™ Hamiltonian. This system belongs to
an infinite-dimension Hilbert space, as the radiation field has infinite modes. If we are interested
only in the time dependence state of the atom, we can derive a Markovian master equation for the
reduced density matrix of the atom (see for instance Refs. [1, 2]). The master equation we will
study is

                                                                   
                             d                        âˆ’  +  1 + âˆ’
                                Ï(t) = âˆ’i [H, Ï] + Î“ Ïƒ ÏÏƒ âˆ’   Ïƒ Ïƒ ,Ï ,                         (96)
                             dt                             2

where Î“ is the coupling between the atom and the vacuum.
In the Fock-Liouvillian space (following the same ordering as in Eq. (3)) the Liouvillian corre-
sponding to evolution (96) is

                                    ï£«                      ï£¶
                                     0    iâ„¦     âˆ’iâ„¦    Î“
                                  ï£¬ iâ„¦ âˆ’iE âˆ’ Î“    0    âˆ’iâ„¦ ï£·
                                L=ï£¬
                                  ï£­ âˆ’iâ„¦
                                             2
                                                     Î“
                                                           ï£·.                                  (97)
                                           0   âˆ’iE âˆ’ 2 iâ„¦ ï£¸
                                     0   âˆ’iâ„¦     iâ„¦    âˆ’Î“

Expressing explicitly the set of differential equations we obtain


                                 ÏÌ‡00 = iâ„¦Ï01 âˆ’ iâ„¦Ï10 + Î“Ï11
                                                        
                                                       Î“
                                 ÏÌ‡01 = iâ„¦Ï00 âˆ’ iE âˆ’        Ï01 âˆ’ iâ„¦Ï11
                                                       2
                                                          
                                                        Î“
                                 ÏÌ‡10 = âˆ’iâ„¦Ï00 âˆ’iE âˆ’         Ï10 + iâ„¦Ï11                       (98)
                                                         2
                                 ÏÌ‡10 = âˆ’iâ„¦Ï01 + iâ„¦Ï10 âˆ’ Î“Ï11

a This is why atoms decay.
                                                                                                                         23

                              VI.       RESOLUTION OF THE LINDBLAD MASTER EQUATION

                                                       A.        Integration

   To calculate the time evolution of a system determined by a Master Equation in the form (96) we need to solve a
set of equations with as many equations as the dimension of the density matrix. In our example, this means to solve
a 4 variable set of equations, but the dimension of the problem increases exponentially with the system size. Because
of this, for bigger systems techniques for dimension reduction are required.
   To solve systems of partial differential equations there are several canonical algorithms. This can be done analytically
only for a few simple systems and by using sophisticated techniques as damping bases [29]. In most cases, we have
to rely on numerical approximated methods. One of the most popular approaches is the 4th -order Runge-Kutta
algorithm (see, for instance, [30] for an explanation of the algorithm). By integrating the equations of motion, we can
calculate the density matrix at any time t.
   The steady-state of a system can be obtained by evolving it for a long time (t â†’ âˆ). Unfortunately, this method
presents two difficulties. First, if the dimension of the system is big, the computing time would be huge. This means
that for systems beyond a few qubits, it will take too long to reach the steady-state. Even worse is the problem of
stability of the algorithms for integrating differential equations. Due to small errors in the calculation of derivatives by
the use of finite differences, the trace of the density matrix may not be constantly equal to one. This error accumulates
during the propagation of the state, giving non-physical results after a finite time. One solution to this problem is the
use of algorithms specifically designed to preserve the trace, as Crank-Nicholson algorithm [31]. The problem with
this kind of algorithms is that they consume more computational power than Runge-Kutta, and therefore they are
not useful to calculate the long-time behaviour of big systems. An analysis of different methods and their advantages
and disadvantages can be found at Ref. [32].



         Box 7. Time dependency of the two-level system with decay.
         In this box we show some results of solving Eq (96) and calculating the density matrix as a function
         of time. A Mathematica notebook solving this problem can be found at [20]. To illustrate the time
         behaviour of this system, we calculate the evolution for different state parameters. In all cases,
         we start with an initial state that represents the state being excited Ï11 = 1, with no coherence
         between different states, meaning Ï01 = Ï10 = 0. If the decay parameter Î“ is equal to zero, the
         problem reduces to solve von Neumann equation, and the result is displayed in Figure 2. The other
         extreme case would be a system with no coherent dynamics (â„¦ = 0) but with decay. In this case,
         we observe an exponential decay of the population of the excited state. Finally, we can calculate
         the dynamics of a system with both coherent driving and decay. In this case, both behaviours
         coexist, and there are oscillations and decay.
                 Population                                             Population

                  1.0                                                    1.0


                  0.8                                                    0.8


                  0.6                                                    0.6


                  0.4                                                    0.4


                  0.2                                                    0.2


                                                                 Time                                     Time
                                    5       10    15        20                       2   4   6   8   10



         FIG. 4: Left: Population dynamics under a pure incoherent dynamics (Î“ = 0.1, n = 1, â„¦ =
         0, E = 1). Right: Population dynamics under both coherent and incoherent dynamics (Î“ =
         0.1, n = 1, â„¦ = 1, E = 1). In both the blue lines represent Ï11 and the orange one Ï00 .
                                                                                                                       24

                                                 B.        Diagonalisation

  As we have discussed before, in the Fock-Liouville space the Liouvillian corresponds to a complex matrix (in general
complex, non-hermitian, and non-symmetric). By diagonalising it we can calculate both the time-dependent and the
steady-state of the density matrices. For most purposes, in the short time regime integrating the differential equations
may be more efficient than diagonalising. This is due to the high dimensionality of the Liouvillian that makes the
diagonalisation process very costly in computing power. On the other hand, in order to calculate the steady-state,
the diagonalisation is the most used method due to the problems of integrating the equation of motions discussed in
the previous section.
  Let see first how we use diagonalisation to calculate the time evolution of a system. As the Liouvillian matrix is
non-Hermitian, we cannot apply the spectral theorem to it, and it may have different left and right eigenvectors. For
a specific eigenvalue Î›i we can obtain the eigenvectors |Î›R           L
                                                           i ii and |Î›i ii s. t.



                                                                LÌƒ |Î›R           R
                                                                     i ii = Î›i |Î›i ii
                                                                hhÎ›L              L
                                                                   i | LÌƒ = Î›i hhÎ›i |                                (99)

An arbitrary system can be expanded in the eigenbasis of LÌƒ as [1, 33]

                                                           X
                                            |Ï(0)ii =           |Î›R      L
                                                                  i iihhÎ›i |Ï(0)ii.                                 (100)
                                                            i

Therefore, the state of the system at a time t can be calculated in the form

                                                       X
                                           |Ï(t)ii =        eÎ›i t |Î›R      L
                                                                    i iihhÎ›i |Ï(0)ii.                               (101)
                                                       i

Note that in this case to calculate the state a time t we do not need to integrate into the interval [0, t], as we have to
do if we use a numerical solution of the differential set of equations. This is an advantage when we want to calculate
long-time behaviour. Furthermore, to calculate the steady-state of a system, we can look to the eigenvector that has
zero eigenvalue, as this is the only one that survives when t â†’ âˆ.
   For any finite system, Evansâ€™ Theorem ensures the existence of at least one zero eigenvalue of the Liouvillian
matrix [34, 35]. The eigenvector corresponding to this zero eigenvalue would be the steady-state of the system. In
exceptional cases, a Liouvillian can present more than one zero eigenvalues due to the presence of symmetry in the
system [26, 27, 36]. This is a non-generic case, and for most purposes, we can assume the existence of a unique
fixed point in the dynamics of the system. Therefore, diagonalising can be used to calculate the steady-state without
calculating the full evolution of the system. This can be done even analytically for small systems, and when numerical
approaches are required this technique gives better precision than integrating the equations of motion. The spectrum
of Liouvillian superoperators has been analysed in several recent papers [33, 37].
                                                                                                                         25


   Box 8. Spectrum-analysis of the Liouvillian for the two-level system with decay.
   Here we diagonalise (97) and obtain its steady state. A Mathematica notebook solving this problem
   can be downloaded from [20]. This specific case is straightforward to diagonalize as the dimension
   of the system is very low. We obtain 4 different eigenvalues, two of them are real while the other
   two form a conjugated pair. Figure 5 sisplays the spectrum of the superoperator L given in (97).


                                                                                             2



                                                                                             1




                  -0.4              -0.3               -0.2              -0.1



                                                                                            -1



                                                                                            -2



   FIG. 5: Spectrum of the Liouvillian matrix given by (97) for the general case of both coherent and
   incoherent dynamics (Î“ = 0.2, n = 1, â„¦ = 0, E = 1).

   As there only one zero eigenvalue we can conclude that there is only one steady-state, and any
   initial density matrix will evolve to it after an infinite-time evolution. By selecting the right
   eigenvector corresponding to the zero-eigenvalue and normalizing it we obtain the density matrix.
   This can be done even analytically. The result is the matrix:

                         (1+n)(4 E 2 +(Î“+2n Î“)2 )+4(1+2n)â„¦2
                         ï£«                                                                  ï£¶
                                                                   2(âˆ’2 Eâˆ’i(Î“+2nÎ“))â„¦
                            (1+2n)(4 E 2 +(Î“+2n Î“)2 +8â„¦2 )    (1+2n)(4 E 2 +(Î“+2n Î“)2 +8 â„¦2 ) ï£¸
                 ÏSS = ï£­                                      n(4E 2 +(Î“+2nÎ“)2 )+4(1+2n)â„¦2
                                                                                                      (102)
                                2(âˆ’2 E+i(Î“+2n Î“))â„¦
                            (1+2n)(4 E 2 +(Î“+2n Î“)2 +8â„¦2 )    (1+2n)(4 E 2 +(Î“+2nÎ“)2 +8 â„¦2 )




                                           VII.   ACKNOWLEDGEMENTS


   The author wants to acknowledge the Spanish Ministry and the Agencia EspanÌƒola de InvestigacioÌn (AEI) for
financial support under grant FIS2017-84256-P (FEDER funds).




[1] C.W. Gardiner and P. Zoller. Quantum Noise. Springer, Berlin, 2000.
[2] H.P. Breuer and F. Petruccione. The theory of open quantum systems. Oxford University Press, 2002.
[3] A. Rivas and S. Huelga. Open Quantum Systems. An Introduction. Springer, New York, 2012.
[4] G. Lindblad. On the generators of quantum dynamical semigroups. Commun. Math. Phys., 119:48, 1976.
[5] V. Gorini, A. Kossakowski, and E.C. Sudarsahan. Completely positive semigroups of n-level systems. J. Math. Phys.,
    17:821, 1976.
[6] D. Manzano and E. Kyoseva. An atomic symmetry-controlled thermal switch. Scientific Reports, 6:31161, 2016.
[7] T. Prosen. Open xxz spin chain: Nonequilibrium steady state and a strict bound on ballistic transport. Phys. Rev. Lett.,
    106:217206, 2011.
                                                                                                                           26

 [8] D. Manzano, M. Tiersch, A. Asadian, and H.J. Briegel. Quantum transport efficiency and Fourierâ€™s law. Phys. Rev. E,
     86:061118, 2012.
 [9] D. Manzano, C. Chuang, and J. Cao. Quantum transport in d-dimensional lattices. New J. Physics, 18:043044, 2015.
[10] B. Olmos, I. Lesanovsky, and J.P. Garrahan Facilitated Spin Models of Dissipative Quantum Glasses Phys. Rev. Lett.,
     109:020403, 2012.
[11] J. Metz, M. Trupke, andA. Beige Robust Entanglement through Macroscopic Quantum Jumps Phys. Rev. Lett., 97:040503,
     2006.
[12] R. Jones, J. A. Needham, I. Lesanovsky, F. Intravaia, Beatriz Olmos Modified dipole-dipole interaction and dissipation in
     an atomic ensemble near surfaces Phys. Rev. A, 97:053841, 2018.
[13] D.A. Lidar, I.L. Chuang, and K. B. Whaley. Decoherence-free subspaces for quantum computation. Phys. Rev. Lett.,
     81(12):2594, 1998.
[14] B. Kraus, H. P. BuÌˆchler, S. Diehl, A. Kantian, A. Micheli, and P. Zoller. Preparation of entangled states by quantum
     markov processes. Phys. Rev. A, 2008.
[15] T.A. Brun. Continuous measurements, quantum trajectories, and decoherent histories. Phys. Rev. A, 61:042107, 2000.
[16] M. Schlosshauer. Decoherence and the Quantum-to-Classical Transition. Springer, New York, 2007.
[17] M. Plenio and S. Huelga. Dephasing-assisted transport: quantum networks and biomolecules. New J. Phys., 10:113019,
     2008.
[18] M. Mohseni, P. Rebentrost, S. Lloyd, and A. Aspuru-Guzik. Enviroment-assisted quantum walks in photosynthetic energy
     transfer. Journal of Chemical Physics, 129:174106, 2008.
[19] D. Manzano. Quantum transport in quantum networks and photosynthetic complexes at the steady state. PLoS ONE,
     8(2):e57041, 2013.
[20] https://ic1.ugr.es/manzano/Descargas/Lindblad/Lindblad_Manzano.zip
[21] L. Debnath and P. MikusinÌki. Introduction to Hilbert Spaces with Applications. Elsevier Academic Press, 2005.
[22] M.A. Nielsen and I.L. Chuang. Quantum Computation and Quantum Information. Cambridge Univ. Press, Cambridge,
     2000.
[23] J.J. Sakurai. Modern Quantum Mechanics. Addison-Wesley Publishing Co., 1994.
[24] A. Galindo and P. Pascual. Quantum Mechanics I. Springer, Berlin, 1990.
[25] A. Peres. Quantum Theory: Concepts and Methods. Kluwer Academic Publishers, 1995.
[26] D. Manzano and P.I. Hurtado. Harnessing symmetry to control quantum transport. Adv. Phys, 67:1, 2018.
[27] D. Manzano and P.I. Hurtado. Symmetry and the thermodynamics of currents in open quantum systems Phys. Rev. B,
     90:125138, 2014.
[28] M.M. Wilde. Quantum Information Theory. Cambridge Univ. Press, Cambridge, 2017.
[29] H.J. Briegel and B.G. Englert. Quantum optical master equation: The use of damping bases. Phys. Rev. A, 47:3311, 1993.
[30] W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. Numerical Recipes. Cambridge Univ. Press, Cambridge,
     2007.
[31] A. Goldberg, H. Schey, and J.L. Schwartz. Computer-generated motion pictures of one-dimensional quantum-mechanical
     transmission and reflection phenomena. Am. J. Phys., 35:177, 1967.
[32] M. Riesch and C. Jirauschek. Analyzing the positivity preservation of numerical methods for the liouville-von neumann
     equation. J. Comp. Phys., 390:290, 2019.
[33] J. Thingna, D. Manzano, and J. Cao. Dynamical signatures of molecular symmetries in nonequilibrium quantum transport.
     Scientific Reports, 6:28027, 2016.
[34] D.E. Evans. Irreducible quantum dynamical semigroups. Commun. Math. Phys., 54:293, 1977.
[35] D.E. Evans and H. Hance-Olsen. The generators of positive semigroups. Journal of Positive Analysis, 32:207, 1979.
[36] B. BucÌŒa and T. Prosen. A note on symmetry reductions of the Lindblad equation: Transport in constrained open spin
     chains. New J. Physics, 14:073007, 2012.
[37] V.V. Albert and L. Jiang. Symmetries and conserved quantities in Lindblad master equations. Phys. Rev. A, 89:022118,
     2014.
                                                                                                                                                       27

                                                                       d
                                                                          Tr Ï2 â‰¤ 0
                                                                             
                                                  Appendix A: Proof of dt

  In this  
          appendix we proof that under the Lindblad dynamics given by Eq. (93) the purity of a density matrix fulfils
      d
that dt Tr Ï2 â‰¤ 0 if all the jump operators of the Lindblad dynamics are Hermitian.
  We start just by interchanging the trace and the derivative. As the trace is a linear operation it commutes with
the derivation, and we have

                                                                     2
                                                      d              dÏ
                                                         Tr Ï2 = Tr
                                                            
                                                                         = Tr [2ÏÏÌ‡] ,                                                               (A1)
                                                      dt              dt

where we have used the cyclic property of the trace operator5 . By inserting the Lindblad Eq. (93) into the r.h.s of
(A1) we obtain


                                    d            i
                                       Tr Ï2 = âˆ’ Tr [(2Ï (HÏ âˆ’ ÏH))]
                                          
                                    dt           hÌ„      h          i           h         i
                                                    Î“k Tr Ï Lk Ï Lâ€ k âˆ’ 2   Î“k Tr Ï2 Lâ€ k Lk .
                                                 X                       X
                                              +2                                                                                                     (A2)
                                                             k                                       k


The first term is zero. Therefore, the inequality we want to prove becomes equivalent to

                                                           h          i X      h          i
                                                      Î“k Tr Ï Lk Ï Lâ€ k â‰¤  Î“k Tr Ï2 Lâ€ k Lk
                                                X
                                                                                                                                                     (A3)
                                                  k                                    k


As the density matrix is Hermitian we can diagonalize it to obtain its eigenvalues (Î›i âˆˆ R) and its corresponding
eigenvectors (|Î›i i). The density matrix is diagonal in its own eigenbasis and can be expressed as6

                                                                            X
                                                                 Ï â†’ ÏÌƒ =           Î›i |Î›i ihÎ›i |,                                                   (A4)
                                                                            i

where we assume an ordering of the eigenvalues in the form Î›0 â‰¥ Î›1 â‰¥ Â· Â· Â· â‰¥ Î›d .
  We rename the jump operators in this basis as LÌƒi a. Expanding each term of the inequality (A3) in this basis we
obtain

                                                         ï£®                !    ï£«                ï£¶ ï£¹
                                    h          i X
                               Î“k Tr Ï Lk Ï Lâ€ k =
                           X                               X                     X
                                                   Î“k Tr ï£°   Î›i |Î›i ihÎ›i | LÌƒk ï£­   Î›j |Î›j ihÎ›j |ï£¸ LÌƒk ï£»
                           k                                 k                  i                                  j
                                                                                                              
                                                 h                             i X X                         2
                                                     â€ 
                           X        X
                     =         Î“k         Î›i Î›j Tr LÌƒk |Î›i ihÎ›i |LÌƒk |Î›j ihÎ›j | = Î“k Î›i Î›j Tr hÎ›i |LÌƒk |Î›j i
                           k        i,j                                                      k           i,j
                                                                                                                                             (k)
                                                                                                                   X            X
                                                                                                               =           Î“k         Î›i Î›j xij ,    (A5)
                                                                                                                       k        i,j


                                                                                      2
                                                       (k)
where we have introduced the oefficients xij â‰¡ hÎ›i |LÌƒk |Î›j i . As the operators Lk are Hermitian these coefficients
       (k)     (k)
fulfil xij = xji
  The second term is expanded as



5 This property is used along all the demonstration without ex-
                                                                                     6 This eigenbasis changes with time, of course, but the proof is
 plicitly mentioning it.                                                                  valid as the inequality should be fulfilled at any time.
                                                                                                                                                                                  28


                                                                                 ï£®                         !ï£«               ï£¶          ï£¹
                                         h            i
                               Î“k Tr Ï2 Lâ€ k Lk =                                                               Î›j |Î›j ihÎ›j |ï£¸ LÌƒâ€ k LÌƒk ï£»
                          X                                    X                      X                      X
                                                                        Î“k Tr ï£°               Î›i |Î›i ihÎ›i | ï£­
                          k                                        k                  i                                        j
                                                        h                                       i                                        h                   i
                                                            LÌƒk |Î›i ihÎ›j |LÌƒâ€ k hÎ›i |Î›j i                                           Î›2i Tr LÌƒk |Î›i ihÎ›i |LÌƒâ€ k
                          X             X                                                               X              X
                      =            Î“k        Î›i Î›j Tr                                               =            Î“k
                           k            ij                                                                  k              i
                                                                                                        ï£®                               ï£«                   ï£¶ï£¹

                                                                                              Î›2i Tr ï£°LÌƒk |Î›i ihÎ›i |LÌƒâ€ k ï£­
                                                                             X        X                                                     X
                                                                        =        Î“k                                                                 |Î›j ihÎ›j |ï£¸ï£»
                                                                             k        i                                                         j
                                                  X           X              h                               i X X
                                              =       Î“k               Î›2i Tr hÎ›j |LÌƒk |Î›i i + hÎ›i |LÌƒk |Î›j i = Î“k Î›2i xij ,                                                    (A6)
                                                  k           ij                                                                            k         ij
                                                                                                                                         P
where we have used the closure relation in the density matrix eigenbasis, 1H =                                                                  j |Î›j ihÎ›j |.   The inequality can be
written now as

                                                        X              X                       X            X
                                                               Î“k            Î›i Î›j xij â‰¤            Î“k                Î›2i xij .                                                 (A7)
                                                          k             ij                      k               ij

As xij = xji we can re-order the ij sum in the following way

                                    ï£«                        ï£¶         ï£«                           ï£¶
                                               (k)       (k)                         (k)       (k)
                 X         X         X                          X    X  X
                                       2Î›i Î›j xij + Î›2i xii ï£¸ â‰¤           Î›2i + Î›2j xij + Î›2i xii ï£¸ .
                                                                                   
                      Î“k            ï£­                             Î“k   ï£­                                                                                                        (A8)
                  k            i        jâ‰¤i                                               k             i            j<i


Therefore, we can reduce the proof of this inequality to the proof of a set of inequalities

                                                          (k)            (k)
                                                  2Î›i Î›j xij â‰¤ Î›2i + Î›2j xij                                     âˆ€ (k, i, j) .                                                  (A9)

It is obvious that (A9) â‡’ (A8) (but not the other way around). The inequalities (A9) are easily proved just by taking
                     (k)
into account that xij â‰¥ 0 and applying the Triangular Inequality.
