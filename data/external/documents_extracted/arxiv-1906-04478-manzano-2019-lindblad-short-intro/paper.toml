equations = []
full_text = """
A short introduction to the Lindblad Master Equation\r
Daniel Manzano1\r
1Electromagnetism and Condensed Matter Department and Carlos I Institute for Theoretical\r
and Computational Physics. University of Granada. E-18071 Granada. Spain ∗\r
The theory of open quantum system is one of the most essential tools for the development of\r
quantum technologies. Furthermore, the Lindblad (or Gorini-Kossakowski-Sudarshan-Lindblad)\r
Master Equation plays a key role as it is the most general generator of Markovian dynamics in\r
quantum systems. In this paper, we present this equation together with its derivation and methods\r
of resolution. The presentation tries to be as self-contained and straightforward as possible to be\r
useful to readers with no previous knowledge of this field.\r
I. INTRODUCTION\r
Open quantum system techniques are vital for many studies in quantum mechanics [1–3]. This happens because\r
closed quantum systems are just an idealisation of real systems1, as in Nature nothing can be isolated. In practical\r
problems, the interaction of the system of interest with the environment cannot be avoided, and we require an approach\r
in which the environment can be effectively removed from the equations of motion.\r
The general problem addressed by Open Quantum Theory is sketched in Figure 1. In the most general picture, we\r
have a total system that conforms a closed quantum system by itself. We are mostly interested in a subsystem of the\r
total one (we call it just “system” instead “total system”). Therefore, the whole system is divided into our system of\r
interest and an environment. The goal of Open Quantum Theory is to infer the equations of motions of the reduced\r
systems from the equation of motion of the total system. For practical purposes, the reduced equations of motion\r
should be easier to solve than the full dynamics of the system. Because of his requirement, several approximations\r
are usually made in the derivation of the reduced dynamics.\r
FIG. 1: A total system divided into the system of interest, “System”, and the environment.\r
∗ manzano@onsager.ugr.es\r
1 The same happens with closed classical systems.\r
arXiv:1906.04478v3 [quant-ph] 5 Feb 2020

2\r
One particular, and interesting, case of study is the dynamics of a system connected to several baths modelled by\r
a Markovian interaction. In this case the most general quantum dynamics is generated by the Lindblad equation\r
(also called Gorini-Kossakowski-Sudarshan-Lindblad equation) [4, 5]. It is difficult to overemphasize the importance\r
of this Master Equation. It plays an important role in fields as quantum optics [1, 6], condensed matter [7–10], atomic\r
physics [11, 12], quantum information [13, 14], decoherence [15, 16], and quantum biology [17–19].\r
The purpose of this paper is to provide basic knowledge about the Lindblad Master Equation. In Section II,\r
the mathematical requirements are introduced while in Section III there is a brief review of quantum mechanical\r
concepts that are required to understand the paper. Section IV, includes a description of a mathematical framework,\r
the Fock-Liouville space, that is especially useful to work in this problem. In Section V, we define the concept of\r
CPT-Maps, derive the Lindblad Master Equation from two different approaches, and we discus several properties of\r
the equation. Finally, Section VI is devoted to the resolution of the master equation using different methods. To\r
deepen in the techniques of solving the Lindblad equation, an example consisting of a two-level system with decay\r
is analysed, illustrating the content of every section. The problems proposed are solved by the use of Mathematica\r
notebooks that can be found at [20].\r
II. MATHEMATICAL BASIS\r
The primary mathematical tool in quantum mechanics is the theory of Hilbert spaces. This mathematical framework\r
allows extending many results from finite linear vector spaces to infinite ones. In any case, this tutorial deals only\r
with finite systems and, therefore, the expressions ‘Hilbert space’ and ‘linear space’ are equivalent. We assume that\r
the reader is skilled in operating in Hilbert spaces. To deepen in the field of Hilbert spaces we recommend the book\r
by Debnath and Mikusi´nki [21]. If the reader needs a brief review of the main concepts required for understanding\r
this paper, we may recommend Nielsen and Chuang’s Quantum Computing book [22]. It is also required some basic\r
knowledge about infinitesimal calculus, like integration, derivation, and the resolution of simple differential equations,\r
To help the readers, we have made a glossary of the most used mathematical terms. It can be used also as a checklist\r
of terms the reader should be familiar with.\r
Glossary:\r
• H represents a Hilbert space, usually the space of pure states of a system.\r
• |ψi ∈ H represents a vector of the Hilbert space H (a column vector).\r
• hψ| ∈ H represents a vector of the dual Hilbert space of H (a row vector).\r
• hψ|φi ∈ C is the scalar product of vectors |ψi and |φi.\r
• |||ψi|| is the norm of vector |ψi. |||ψi|| ≡ p\r
hψ|ψi.\r
• B(H) represents the space of bounded operators acting on the Hilbert space B : H → H.\r
• 1H ∈ B(H) is the Identity Operator of the Hilbert space H s.t. 1H|ψi = |ψi, ∀|ψi ∈ H.\r
• |ψihφ| ∈ B(H) is the operator such that (|ψihφ|)|ϕi = hφ|ϕi|ψi, ∀|ϕi ∈ H.\r
• O† ∈ B(H) is the Hermitian conjugate of the operator O ∈ B(H).\r
• U ∈ B(H) is a unitary operator iff UU† = U\r
†U = 1.\r
• H ∈ B(H) is a Hermitian operator iff H = H†.\r
• A ∈ B(H) is a positive operator (A > 0) iff hφ|A|φi ≥ 0, ∀|φi ∈ H\r
• P ∈ B(H) is a proyector iff P P = P.\r
• Tr [B] represents the trace of operator B.\r
• ρ (L) represents the space of density matrices, meaning the space of bounded operators acting on H with trace\r
1 and positive.\r
• |ρii is a vector in the Fock-Liouville space.\r
• hhA|Bii = Tr \u0002A†B\r
\u0003\r
is the scalar product of operators A, B ∈ B(H) in the Fock-Liouville space.\r
• L˜ is the matrix representation of a superoperator in the Fock-Liouville space.

3\r
III. (VERY SHORT) INTRODUCTION TO QUANTUM MECHANICS\r
The purpose of this chapter is to refresh the main concepts of quantum mechanics necessary to understand the\r
Lindblad Master Equation. Of course, this is NOT a full quantum mechanics course. If a reader has no background\r
in this field, just reading this chapter would be insufficient to understand the remaining of this tutorial. Therefore,\r
if the reader is unsure of his/her capacities, we recommend to go first through a quantum mechanics course or to\r
read an introductory book carefully. There are many great quantum mechanics books in the market. For beginners,\r
we recommend Sakurai’s book [23] or Nielsen and Chuang’s Quantum Computing book [22]. For more advanced\r
students, looking for a solid mathematical description of quantum mechanics methods, we recommend Galindo and\r
Pascual [24]. Finally, for a more philosophical discussion, you should go to Peres’ book [25].\r
We start stating the quantum mechanics postulates that we need to understand the derivation and application of\r
the Lindblad Master Equation. The first postulate is related to the concept of a quantum state.\r
Postulate 1 Associated to any isolated physical system, there is a complex Hilbert space H, known as the state space\r
of the system. The state of the system is entirely described by a state vector, which is a unit vector of the Hilbert space\r
(|ψi ∈ H).\r
As quantum mechanics is a general theory (or a set of theories), it does not tell us which is the proper Hilbert\r
space for each system. This is usually done system by system. A natural question to ask is if there is a one-to-one\r
correspondence between unit vectors and physical states, meaning that if every unit vector corresponds to a physical\r
system. This is resolved by the following corollary that is a primary ingredient for quantum computation theory (see\r
Ref. [22] Chapter 7).\r
Corollary 1 All unit vectors of a finite Hilbert space correspond to possible physical states of a system.\r
Unit vectors are also called pure states. If we know the pure state of a system, we have all physical information\r
about it, and we can calculate the probabilistic outcomes of any potential measurement (see the next postulate). This\r
is a very improbable situation as experimental settings are not perfect, and in most cases, we have only imperfect\r
information about the state. Most generally, we may know that a quantum system can be in one state of a set {|ψii}\r
with probabilities pi. Therefore, our knowledge of the system is given by an ensemble of pure states described by the\r
set {|ψii, pi}. If more than one piis different from zero the state is not pure anymore, and it is called a mixed state.\r
The mathematical tool that describes our knowledge of the system, in this case, is the density operator (or density\r
matrix).\r
ρ ≡\r
X\r
i\r
pi|ψiihψi|. (1)\r
Density matrices are bounded operators that fulfil two mathematical conditions\r
1. A density matrix ρ has unit trace (Tr[ρ] = 1).\r
2. A density matrix is a positive matrix ρ > 0.\r
Any operator fulfilling these two properties is considered a density operator. It can be proved trivially that density\r
matrices are also Hermitian.\r
If we are given a density matrix, it is easy to verify if it belongs to a pure or a mixed state. For pure states, and\r
only for them, Tr[ρ\r
2\r
] = Tr[ρ] = 1. Therefore, if Tr[ρ\r
2\r
] < 1 the system is mixed. The quantity Tr[ρ\r
2\r
] is called the\r
purity of the states, and it fulfils the bounds 1\r
d ≤ Tr[ρ\r
2\r
] ≤ 1, being d the dimension of the Hilbert space.\r
If we fix an arbitrary basis {|ii}N\r
i=1 of the Hilbert space the density matrix in this basis is written as ρ = PN\r
i,j=1 ρi,j |iihj|, or\r
ρ =\r
\r
\r
ρ00 ρ01 · · · ρ0N\r
ρ10 ρ11 · · · ρ1N\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
ρN0 ρN1 · · · ρNN\r
\r
\r
, (2)

4\r
where the diagonal elements are called populations ρii ∈ R\r
+\r
0\r
and P\r
i\r
ρi,i = 1\u0001\r
, while the off-diagonal elements are\r
called coherences ρi,j ∈ C and ρi,j = ρ\r
∗\r
j,i\u0001\r
. Note that this notation is base-dependent.\r
Box 1. State of a two-level system (qubit)\r
The Hilbert space of a two-level system is just the two-dimension lineal space H2. Examples of\r
this kind of system are 1\r
2\r
-spins and two-level atoms. We can define a basis of it by the orthonormal\r
vectors: {|0i, |1i}. A pure state of the system would be any unit vector of H2. It can always be\r
expressed as a |ψi = a|0i + b|1i with a, b ∈ C s. t. |a|\r
2 + |b|2 = 1.\r
A mixed state is therefore represented by a positive unit trace operator ρ ∈ O(H2).\r
ρ =\r
\u0012\r
ρ00 ρ01\r
ρ10 ρ11\u0013\r
= ρ00|0ih0| + ρ01|0ih1| + ρ10|1ih0| + ρ11|1ih1|, (3)\r
ant it should fulfil ρ00 + ρ11 = 1 and ρ01 = ρ\r
∗\r
10.\r
Once we know the state of a system, it is natural to ask about the possible outcomes of experiments (see Ref. [23],\r
Section 1.4).\r
Postulate 2 All possible measurements in a quantum system are described by a Hermitian operator or observable.\r
Due to the Spectral Theorem we know that any observable O has a spectral decomposition in the form2\r
O =\r
X\r
i\r
ai|aiihai|, (4)\r
being ai ∈ R the eigenvalues of the observable and |aii their corresponding eigenvectors. The probability of obtaining\r
the result ai when measuring the property described by observable O in a state |ψi is given by\r
P(ai) = |hψ|aii|2. (5)\r
After the measurement we obtain the state |aii if the outcome ai was measured. This is called the post-measurement\r
state.\r
This postulate allow us to calculate the possible outputs of a system, the probability of these outcomes, as well as\r
the after-measurement state. A measurement usually changes the state, as it can only remain unchanged if it was\r
already in an eigenstate of the observable.\r
It is possible to calculate the expectation value of the outcome of a measurement defined by operator O in a state\r
|ψi by just applying the simple formula\r
hOi = hψ|O|ψi. (6)\r
With a little algebra we can translate this postulate to mixed states. In this case, the probability of obtaining an\r
output ai that corresponds to an eigenvector |aii is\r
P(ai) = Tr [|aiihai|ρ] , (7)\r
and the expectation value of operator O is\r
hOi = Tr [Oρ] . (8)\r
2 For simplicity, we assume a non-degenerated spectrum.

5\r
Box 2. Measurement in a two-level system.\r
A possible test to perform in our minimal model is to measure the energetic state of a system, as\u0002suming that both states have a different energy. The observable corresponding to this measurement\r
would be\r
H = E0|0ih0| + E1|1ih1|. (9)\r
This operator has two eigenvalues {E0, E1} with two corresponding eigenvectors {|0i, |1i}.\r
If we have a pure state ψ = a|0i + b|1i the probability of measuring the energy E0 would be\r
P(E0) = |h0|ψi|2 = |a|\r
2\r
. The probability of finding E1 would be P(E1) = |h1|ψi|2 = |b|\r
2\r
. The\r
expected value of the measurement is hHi = E0 |a|\r
2 + E1 |b|2\r
.\r
In the more general case of having a mixed state ρ = ρ00|0ih0| + ρ01|0ih1| + ρ10|1ih0| + ρ11|1ih1| the\r
probability of finding the ground state energy is P(0) = Tr [|0ih0|ρ] = ρ00, and the expected value\r
of the energy would be hHi = Tr [Hρ] = E0ρ00 + E1ρ11.\r
Another natural question to ask is how quantum systems evolve. The time-evolution of a pure state of a closed\r
quantum system is given by the Schr¨odinger equation (see [24], Section 2.9).\r
Postulate 3 Time evolution of a pure state of a closed quantum system is given by the Schr¨odinger equation\r
d\r
dt|ψ(t)i = −i¯hH|ψ(t)i, (10)\r
where H is the Hamiltonian of the system and it is a Hermitian operator of the Hilbert space of the system state (from\r
now on we avoid including Planck’s constant by selecting the units such that ¯h = 1).\r
The Hamiltonian of a system is the operator corresponding to its energy, and it can be non-trivial to realise.\r
Schr¨odinger equation can be formally solved in the following way. If at t = 0 the state of a system is given by |ψ(0)i\r
at time t it will be\r
|ψ(t)i = e\r
−iHt|ψ(0)i. (11)\r
As H is a Hermitian operator, the operator U = e\r
−iHt is unitary. This gives us another way of phrasing Postulate 3.\r
Postulate 3’ The evolution of a closed system is given by a unitary operator of the Hilbert space of the system\r
|ψ(t)i = U|ψ(0)i, (12)\r
with U ∈ B (H) s.t. UU† = U\r
†U = 1.\r
It is easy to prove that unitary operators preserve the norm of vectors and, therefore, transform pure states into pure\r
states. As we did with the state of a system, it is reasonable to wonder if any unitary operator corresponds to the\r
evolution of a real physical system. The answer is yes.\r
Lemma 1 All unitary evolutions of a state belonging to a finite Hilbert space can be constructed in several physical\r
realisations like photons and cold atoms.\r
The proof of this lemma can be found at [22].

6\r
The time evolution of a mixed state can be calculated just by combining Eqs. (10) and (1), giving the von-Neumann\r
equation.\r
ρ˙ = −i[H, ρ] ≡ Lρ, (13)\r
where we have used the commutator [A, B] = AB − BA, and L is the so-called Liouvillian superoperator.\r
It is easy to prove that the Hamiltonian dynamics does not change the purity of a system\r
d\r
dtTr \u0002\r
ρ\r
2\r
\u0003\r
= Tr \u0014\r
dρ2\r
dt \u0015\r
= Tr [2ρρ˙] = −2iTr [ρ (Hρ − ρH)] = 0, (14)\r
where we have used the cyclic property of the trace. This result illustrates that the mixing rate of a state does not\r
change due to the quantum evolution.\r
Box 3. Time evolution of a two-level system.\r
The evolution of our isolated two-level system is described by its Hamiltonian\r
Hfree = E0|0ih0| + E1|1ih1|, (15)\r
As the states |0i and |1i are Hamiltonian eigenstates if at t = 0 the atom is at the excited state\r
|ψ(0)i = |1i after a time t the state would be |ψ(t)i = e\r
−iHt|1i = e−iE1t\r
|1i.\r
As the system was already in an eigenvector of the Hamiltonian, its time-evolution consists only in\r
adding a phase to the state, without changing its physical properties. (If an excited state does not\r
change, why do atoms decay?) Without losing any generality we can fix the energy of the ground\r
state as zero, obtaining\r
Hfree = E|1ih1|, (16)\r
with E ≡ E1. To make the model more interesting we can include a driving that coherently\r
switches between both states. The total Hamiltonian would be then\r
H = E|1ih1| + Ω (|0ih1| + |1ih0|), (17)\r
where Ω is the frequency of driving. By using the von-Neumann equation (13) we can calculate\r
the populations (ρ00, ρ11) as a function of time. The system is then driven between the states, and\r
the populations present Rabi oscillations, as it is shown in Fig. 2.\r
1 2 3 4 5\r
Time\r
0.2\r
0.4\r
0.6\r
0.8\r
1.0\r
Population\r
FIG. 2: Population dynamics under a quantum dynamics (Parameters are Ω = 1, E = 1). The\r
blue line represents ρ11 and the orange one ρ00.

7\r
Finally, as we are interested in composite quantum systems, we need to postulate how to work with them.\r
Postulate 4 The state-space of a composite physical system, composed by N subsystems, is the tensor product of the\r
state space of each component H = H1 ⊗ H2 ⊗ · · · ⊗ HN . The state of the composite physical system is given by a\r
unit vector of H. Moreover, if each subsystem belonging to Hi is prepared in the state |ψii the total state is given by\r
|ψi = |ψ1i ⊗ |ψ2i ⊗ · · · ⊗ |ψN i.\r
The symbol ⊗ represents the tensor product of Hilbert spaces, vectors, and operators. If we have a composited mixed\r
state where each component is prepared in the state ρi the total state is given by ρ = ρ1 ⊗ ρ2 ⊗ · · · ⊗ ρN .\r
States that can be expressed in the simple form |ψi = |ψ1i ⊗ |ψ2i, in any specific basis, are very particular and they\r
are called separable states (For this discussion, we use a bipartite system as an example. The extension to a general\r
multipartite system is straightforward.) . In general, any arbitrary state should be described as |ψi =\r
P\r
i,j |ψii ⊗ |ψj i\r
(or ρ =\r
P\r
i,j ρi ⊗ ρj for mixed states). Non-separable states are called entangled states.\r
Now that we know how to compose systems, but we can be interested in going the other way around. If we have\r
a system belonging to a bipartite Hilbert space in the form H = Ha ⊗ Hb we can be interested in studying some\r
properties of the subsystem corresponding to one of the subspaces. To do so, we define the reduced density matrix. If\r
the state of our system is described by a density matrix ρ the reduced density operator of the subsystem a is defined\r
by the operator\r
ρa ≡ Trb [ρ] , (18)\r
were Trb is the partial trace over subspace b and it is defined as [22]\r
Trb\r
\r
\r
X\r
i,j,k,l\r
|aiihaj | ⊗ |bkihbl|\r
\r
 ≡\r
X\r
i,j\r
|aiihaj |Tr\r
\r
\r
X\r
k,l\r
|bkihbl|\r
\r
 . (19)\r
The concepts of reduced density matrix and partial trace are essential in the study of open quantum systems. If we\r
want to calculate the equation of motions of a system affected by an environment, we should trace out this environment\r
and deal only with the reduced density matrix of the system. This is the main idea of the theory of open quantum\r
systems.

8\r
Box 4. Two two-level atoms\r
If we have two two-level systems, the total Hilbert space is given by\r
H = H2 ⊗ H2. A basis of this Hilbert space would be given by the set\r
{|00i ≡ |0i1 ⊗ |0i2, |01i ≡ |0i1 ⊗ |1i2, |10i ≡ |1i1 ⊗ |0i2, |11i ≡ |1i1 ⊗ |1i2}. If both systems\r
are in their ground state, we can describe the total state by the separable vector\r
|ψiG = |00i. (20)\r
A more complex, but still separable, state can be formed if both systems are in superposition.\r
|ψiS =\r
1\r
√\r
2\r
(|0i1 + |1i1) ⊗\r
1\r
√\r
2\r
(|0i2 + |1i2)\r
=\r
1\r
2\r
(|00i + |10i + |01i + |11i) (21)\r
An entangled state would be\r
|ψiE =\r
1\r
√\r
2\r
(|00i + |11i). (22)\r
This state cannot be separated into a direct product of each subsystem. If we want to obtain a\r
reduced description of subsystem 1 (or 2) we have to use the partial trace. To do so, we need first\r
to calculate the density matrix corresponding to the pure state |ψiE.\r
ρE = |ψihψ|E =\r
1\r
2\r
(|00ih00| + |00ih11| + |11ih00| + |11ih11|). (23)\r
We can now calculate the reduced density matrix of the subsystem 1 by using the partial trace.\r
ρ\r
(1)\r
E = h0|2ρE|0i2 + h1|2ρE|1i2 =\r
1\r
2\r
(|00ih00|1 + |11ih11|2). (24)\r
From this reduced density matrix, we can calculate all the measurement statistics of subsystem 1.

9\r
IV. THE FOCK-LIOUVILLE HILBERT SPACE. THE LIOUVILLE SUPEROPERATOR\r
In this section, we revise a useful framework for both analytical and numerical calculations. It is clear that some\r
linear combinations of density matrices are valid density matrices (as long as they preserve positivity and trace 1).\r
Because of that, we can create a Hilbert space of density matrices just by defining a scalar product. This is clear\r
for finite systems because in this case scalar space and Hilbert space are the same things. It also happens to be true\r
for infinite spaces. This allows us to define a linear space of matrices, converting the matrices effectively into vectors\r
(ρ → |ρii). This is called Fock-Liouville space (FLS). The usual definition of the scalar product of matrices φ and ρ\r
is defined as hhφ|ρii ≡ Tr \u0002φ\r
†ρ\r
\u0003\r
. The Liouville super-operator from Eq. (13) is now an operator acting on the Hilbert\r
space of density matrices. The main utility of the FLS is to allow the matrix representation of the evolution operator.\r
Box 5. Time evolution of a two-level system.\r
The density matrix of our system (3) can be expressed in the FLS as\r
|ρii =\r
\r
\r
ρ00\r
ρ01\r
ρ10\r
ρ11\r
\r
 . (25)\r
The time evolution of a mixed state is given by the von-Neumann equation (13). The Liouvillian\r
superoperator can now be expressed as a matrix\r
L˜ =\r
\r
\r
0 iΩ −iΩ 0\r
iΩ iE 0 −iΩ\r
−iΩ 0 −iE iΩ\r
0 −iΩ iΩ 0\r
\r
 , (26)\r
where each row is calculated just by observing the output of the operation −i[H, ρ] in the compu\u0002tational basis of the density matrices space. The time evolution of the system now corresponds to\r
the matrix equation d|ρii\r
dt = L| ˜ ρii, that in matrix notation would be\r
\r
\r
ρ˙00\r
ρ˙01\r
ρ˙10\r
ρ˙11\r
\r
 =\r
\r
\r
0 iΩ −iΩ 0\r
iΩ iE 0 −iΩ\r
−iΩ 0 −iE iΩ\r
0 −iΩ iΩ 0\r
\r
\r
\r
\r
ρ00\r
ρ01\r
ρ10\r
ρ11\r
\r
 (27)

10\r
V. CPT-MAPS AND THE LINDBLAD MASTER EQUATION.\r
A. Completely positive maps\r
The problem we want to study is to find the most general Markovian transformation set between density matrices.\r
Until now, we have seen that quantum systems can evolve in two way, by a coherent evolution given (Postulate 3) and\r
by collapsing after a measurement (Postulate 2). Many efforts have been made to unify these two ways of evolving\r
[16], without giving a definite answer so far. It is reasonable to ask what is the most general transformation that can\r
be performed in a quantum system, and what is the dynamical equation that describes this transformation.\r
We are looking for maps that transform density matrices into density matrices. We define ρ(H) as the space of all\r
density matrices in the Hilbert space H. Therefore, we are looking for a map of this space onto itself, V : ρ(H) → ρ(H).\r
To ensure that the output of the map is a density matrix this should fulfil the following properties\r
• Trace preserving. Tr [VA] = Tr [A] , ∀A ∈ O(H).\r
• Completely positive (see below).\r
Any map that fulfils these two properties is called a completely positive and trace-preserving map (CPT-maps). The\r
first property is quite apparent, and it does not require more thinking. The second one is a little more complicated,\r
and it requires an intermediate definition.\r
Definition 1 A map V is positive iff ∀A ∈ B(H) s.t. A ≥ 0 ⇒ VA ≥ 0.\r
This definition is based in the idea that, as density matrices are positive, any physical map should transform positive\r
matrices into positive matrices. One could naively think that this condition must be sufficient to guarantee the\r
physical validity of a map. It is not. As we know, there exist composite systems, and our density matrix could be the\r
partial trace of a more complicated state. Because of that, we need to impose a more general condition.\r
Definition 2 A map V is completely positive iff ∀n ∈ N, V ⊗ 1n is positive.\r
To prove that not all positive maps are completely positive, we need a counterexample. A canonical example of an\r
operation that is positive but fails to be completely positive is the matrix transposition. If we have a Bell state in the\r
form |ψBi = √\r
1\r
2\r
(|01i + |10i) its density matrix can be expressed as\r
ρB =\r
1\r
2\r
(|0ih0| ⊗ |1ih1| + |1ih1| ⊗ |0ih0| + |0ih1| ⊗ |1ih0| + |1ih0| ⊗ |0ih1|), (28)\r
with a matrix representation\r
ρB =\r
1\r
2\r
\u001A\u0012 1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
0 1 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\r
+\r
\u0012\r
0 1\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\u001B . (29)\r
A little algebra shows that the full form of this matrix is\r
ρB =\r
\r
\r
0 0 0 0\r
0 1 1 0\r
0 1 1 0\r
0 0 0 0\r
\r
 , (30)\r
and it is positive.

11\r
FIG. 3: A total system (belonging to a Hilbert space HT , with states described by density matrices ρT , and with\r
dynamics determined by a Hamiltonian HT ) divided into the system of interest, ‘System’, and the environment.\r
It is easy to check that the transformation 1 ⊗ T2, meaning that we transpose the matrix of the second subsystem\r
leads to a non-positive matrix\r
(1 ⊗ T2) ρB =\r
1\r
2\r
\u001A\u0012 1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\u001B . (31)\r
The total matrix is\r
(1 ⊗ T2) ρB =\r
\r
\r
0 0 0 1\r
0 1 0 0\r
0 0 1 0\r
1 0 0 0\r
\r
 , (32)\r
with −1 as an eigenvalue. This example illustrates how the non-separability of quantum mechanics restrict the\r
operations we can perform in a subsystem. By imposing this two conditions, we can derive a unique master equation\r
as the generator of any possible Markovian CPT-map.\r
B. Derivation of the Lindblad Equation from microscopic dynamics\r
The most common derivation of the Lindblad master equation is based on Open Quantum Theory. The Lindblad\r
equation is then an effective motion equation for a subsystem that belongs to a more complicated system. This\r
derivation can be found in several textbooks like Breuer and Petruccione’s [2] as well as Gardiner and Zoller’s [1].\r
Here, we follow the derivation presented in Ref. [26]. Our initial point is displayed in Figure 3. A total system\r
belonging to a Hilbert space HT is divided into our system of interest, belonging to a Hilbert space H, and the\r
environment living in HE.\r
The evolution of the total system is given by the von Neumann equation (13).\r
ρ˙T (t) = −i[HT , ρT (t)] . (33)

12\r
As we are interested in the dynamics of the system, without the environment, we trace over the environment degrees\r
of freedom to obtain the reduced density matrix of the system ρ(t) = TrE[ρT ]. To separate the effect of the total\r
hamiltonian in the system and the environment we divide it in the form HT = HS ⊗ 1E + 1S ⊗ HE + αHI , with\r
H ∈ H, HE ∈ HE, and HI ∈ HT , and being α a measure of the strength of the system-environment interaction.\r
Therefore, we have a part acting on the system, a part acting on the environment, and the interaction term. Without\r
losing any generality, the interaction term can be decomposed in the following way\r
HI =\r
X\r
i\r
Si ⊗ Ei, (34)\r
with Si ∈ B(H) and Ei ∈ B(HE)\r
3\r
.\r
To better describe the dynamics of the system, it is useful to work in the interaction picture (see Ref. [24] for\r
a detailed explanation about Schr¨odinger, Heisenberg, and interaction pictures). In the interaction picture, density\r
matrices evolve with time due to the interaction Hamiltonian, while operators evolve with the system and environment\r
Hamiltonian. An arbitrary operator O ∈ B(HT ) is represented in this picture by the time-dependent operator Oˆ(t),\r
and its time evolution is\r
Oˆ(t) = e\r
i(H+HE)t O e−i(H+HE)t\r
. (35)\r
The time evolution of the total density matrix is given in this picture by\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (t)\r
i\r
. (36)\r
This equation can be easily integrated to give\r
ρˆT (t) = ˆρT (0) − iα Z t\r
0\r
ds h\r
Hˆ\r
I (s), ρˆT (s)\r
i\r
. (37)\r
By this formula, we can obtain the exact solution, but it still has the complication of calculating an integral in the\r
total Hilbert space. It is also troublesome the fact that the state ˜ρ(t) depends on the integration of the density matrix\r
in all previous time. To avoid that we can introduce Eq. (37) into Eq. (36) giving\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α\r
2\r
Z t\r
0\r
ds hHˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (s)\r
ii . (38)\r
By applying this method one more time we obtain\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α\r
2\r
Z t\r
0\r
ds h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii + O(α\r
3\r
). (39)\r
After this substitution, the integration of the previous states of the system is included only in the terms that are O(α\r
3\r
)\r
or higher. At this moment, we perform our first approximation by considering that the strength of the interaction\r
between the system and the environment is small. Therefore, we can avoid high-orders in Eq. (39). Under this\r
approximation we have\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α\r
2\r
Z t\r
0\r
ds hHˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (40)\r
We are interested in finding an equation of motion for ρ, so we trace over the environment degrees of freedom\r
3 From now on we will not writethe identity operators of the Hamil\u0002tonian parts explicitly when they can be inferred from the con\u0002text.

13\r
dρˆ(t)\r
dt = TrE\r
\u0014\r
dρˆT (t)\r
dt \u0015\r
= −iαTrE\r
h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α\r
2\r
Z t\r
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (41)\r
This is not a closed time-evolution equation for ˆρ(t), because the time derivative still depends on the full density\r
matrix ˆρT (t). To proceed, we need to make two more assumptions. First, we assume that t = 0 the system\r
and the environment have a separable state in the form ρT (0) = ρ(0) ⊗ ρE(0). This means that there are not\r
correlations between the system and the environment. This may be the case if the system and the environment have\r
not interacted at previous times or if the correlations between them are short-lived. Second, we assume that the\r
initial state of the environment is thermal, meaning that it is described by a density matrix in the form ρE(0) =\r
exp (−HE/T) /Tr[exp (−HE/T)], being T the temperature and taking the Boltzmann constant as kB = 1. By using\r
these assumptions, and the expansion of HI (34), we can calculate an expression for the first element of the r.h.s of\r
Eq. (41).\r
TrE\r
h\r
Hˆ\r
I (t), ρˆT (0)i\r
=\r
X\r
i\r
\u0010\r
Sˆ\r
i(t)ˆρ(0)TrE\r
h\r
Eˆ\r
i(t)ˆρE(0)i\r
− ρˆ(0)Sˆ\r
i(t)TrE\r
h\r
ρˆE(0)Eˆ\r
i(t)\r
i\u0011 . (42)\r
To calculate the explicit value of this term, we may use that hEii = Tr[EiρE(0)] = 0 for all values of i. This\r
looks like a strong assumption, but it is not. If our total Hamiltonian does not fulfil it, we can always rewrite it\r
as HT = (H + α\r
P\r
i\r
hEii Si) + HE + αH0\r
i\r
, with H0\r
i =\r
P\r
i Si ⊗ (Ei − hEii). It is clear that now hE0\r
i\r
i = 0, with\r
E0\r
i = Ei − hEii, and the system Hamiltonian is changed just by the addition of an energy shift that does no affect the\r
system dynamics. Because of that, we can assume that hEii = 0 for all i. Using the cyclic property of the trace, it is\r
easy to prove that the term of Eq. (42) is equal to zero, and the equation of motion (41) reduces to\r
˙ρˆ(t) = −α\r
2\r
Z t\r
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (43)\r
This equation still includes the entire state of the system and environment. To unravel the system from the envi\u0002ronment, we have to make a more restrictive assumption. As we are working in the weak coupling regime, we may\r
suppose that the system and the environment are non-correlated during all the time evolution. Of course, this is\r
only an approximation. Due to the interaction Hamiltonian, some correlations between system and environment are\r
expected to appear. On the other hand, we may assume that the timescales of correlation (τcorr) and relaxation of the\r
environment (τrel) are much smaller than the typical system timescale (τsys), as the coupling strength is very small\r
(α <<). Therefore, under this strong assumption, we can assume that the environment state is always thermal and\r
is decoupled from the system state, ˆρT (t) = ˆρ(t) ⊗ ρˆE(0). Eq. (43) then transforms into\r
˙ρˆ(t) = −α\r
2\r
Z t\r
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆ(t) ⊗ ρˆE(0)ii . (44)\r
The equation of motion is now independent for the system and local in time. It is still non-Markovian, as it depends\r
on the initial state preparation of the system. We can obtain a Markovian equation by realising that the kernel in the\r
integration and that we can extend the upper limit of the integration to infinity with no real change in the outcome.\r
By doing so, and by changing the integral variable to s → t − s, we obtain the famous Redfield equation [? ].\r
˙ρˆ(t) = −α\r
2\r
Z ∞\r
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s − t), ρˆ(t) ⊗ ρˆE(0)ii . (45)\r
It is known that this equation does not warrant the positivity of the map, and it sometimes gives rise to density\r
matrices that are non-positive. To ensure complete positivity, we need to perform one further approximation, the\r
rotating wave approximation. To do so, we need to use the spectrum of the superoperator HA˜ ≡ [H, A], ∀A ∈ B(H).\r
The eigenvectors of this superoperator form a complete basis of space B(H) and, therefore, we can expand the\r
system-environment operators from Eq. (34) in this basis\r
Si =\r
X\r
ω\r
Si(ω), (46)

14\r
where the operators Si(ω) fulfils\r
[H, Si(ω)] = −ωSi(ω), (47)\r
being ω the eigenvalues of H˜ . It is easy to take also the Hermitian conjugated\r
h\r
H, S†\r
i\r
(ω)\r
i\r
= ωS†\r
i\r
(ω). (48)\r
To apply this decomposition, we need to change back to the Schr¨odinger picture for the term of the interaction\r
Hamiltonian acting on the system’s Hilbert space. This is done by the expression Sˆ\r
k = e\r
itHSke−itH. By using the\r
eigen-expansion (46) we arrive to\r
H˜\r
i(t) = X\r
k,ω\r
e\r
−iωtSk(ω) ⊗ E˜\r
k(t) = X\r
k,ω\r
e\r
iωtS\r
†\r
k\r
(ω) ⊗ E˜†\r
k\r
(t). (49)\r
To combine this decomposition with Redfield equation (45), we first may expand the commutators.\r
˙ρˆ(t) = −α\r
2Tr \u0014Z ∞\r
0\r
ds Hˆ\r
I (t)HˆI (t − s)ˆρ(t) ⊗ ρˆE(0) −\r
Z ∞\r
0\r
ds Hˆ\r
I (t)ˆρ(t) ⊗ ρˆE(0)HˆI (t − s)\r
−\r
Z ∞\r
0\r
ds Hˆ\r
I (t − s)ˆρ(t) ⊗ ρˆE(0)HˆI (t) + Z ∞\r
0\r
ds ρˆ(t) ⊗ ρˆE(0)Hˆ\r
I (t − s)HˆI (t)\r
\u0015\r
. (50)\r
We now apply the eigenvalue decomposition in terms of Sk(ω) for Hˆ\r
I (t − s) and in terms of S\r
†\r
k\r
(ω\r
0\r
) for Hˆ\r
I (t). By\r
using the permutation property of the trace and the fact that [HE, ρE(0)] = 0, and after some non-trivial algebra we\r
obtain\r
˙ρˆ(t) = X\r
ω,ω0\r
k,l\r
\u0010\r
e\r
i(ω\r
0−ω)t Γkl(ω)\r
h\r
Sl(ω)ˆρ(t), S†\r
k\r
(ω\r
0\r
)\r
i\r
+ e\r
i(ω−ω\r
0\r
)t Γ∗\r
lk(ω\r
0\r
)\r
h\r
Sl(ω), ρˆ(t)S\r
†\r
k\r
(ω\r
0\r
)\r
i\u0011 , (51)\r
where the effect of the environment has been absorbed into the factors\r
Γkl(ω) ≡\r
Z ∞\r
0\r
ds eiωsTrE\r
h\r
E˜†\r
k\r
(t)E˜\r
l(t − s)ρE(0)i\r
, (52)\r
where we are writing the environment operators of the interaction Hamiltonian in the interaction picture (Eˆ\r
l(t) =\r
e\r
iHEtEle−iHEt\r
). At this point, we can already perform the rotating wave approximation. By considering the time\u0002dependency on Eq. (51), we conclude that the terms with |ω − ω\r
0\r
| >> α2 will oscillate much faster than the typical\r
timescale of the system evolution. Therefore, they do not contribute to the evolution of the system. In the low\u0002coupling regime (α → 0) we can consider that only the resonant terms, ω = ω\r
0\r
, contribute to the dynamics and\r
remove all the others. By applying this approximation to Eq. (51) reduces to\r
˙ρˆ(t) = X\r
ω\r
k,l\r
\u0010\r
Γkl(ω)\r
h\r
Sl(ω)ˆρ(t), S†\r
k\r
(ω)\r
i\r
+ Γ∗\r
lk(ω)\r
h\r
Sl(ω), ρˆ(t)S\r
†\r
k\r
(ω)\r
i\u0011 . (53)\r
To divide the dynamics into Hamiltonian and non-Hamiltonian we now decompose the operators Γkl into Hermitian\r
and non-Hermitian parts, Γkl(ω) = 1\r
2\r
γkl(ω) + iπkl, with\r
πkl(ω) ≡\r
−i\r
2\r
(Γkl(ω) − Γ\r
∗\r
kl(ω))\r
γkl(ω) ≡ Γkl(ω) + Γ∗\r
kl(ω) = Z ∞\r
−∞\r
dseiωsTr hEˆ†\r
k\r
(s)ElρˆE(0)i. (54)

15\r
By these definitions we can separate the Hermitian and non-Hermitian parts of the dynamics and we can transform\r
back to the Schr¨odinger picture\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
ω\r
k,l\r
γkl(ω)\r
\u0012\r
Sl(ω)ρ(t)S\r
†\r
k\r
(ω) −\r
1\r
2\r
n\r
S\r
†\r
kSl(ω), ρ(t)\r
o\u0013\r
. (55)\r
The Hamiltonian dynamics now is influenced by a term HLs =\r
P\r
ω,k,l πkl(ω)S\r
†\r
k\r
(ω)Sl(ω). This is usually called a Lamb\r
shift Hamiltonian and its role is to renormalize the system energy levels due to the interaction with the environment.\r
Eq. (55) is the first version of the Markovian Master Equation, but it is not in the Lindblad form yet.\r
It can be easily proved that the matrix formed by the coefficients γkl(ω) is positive as they are the Fourier’s\r
transform of a positive function \u0010Tr hEˆ†\r
k\r
(s)ElρˆE(0)i\u0011. Therefore, this matrix can be diagonalised. This means that\r
we can find a unitary operator, O, s.t.\r
Oγ(ω)O\r
† =\r
\r
\r
d1(ω) 0 · · · 0\r
0 d2(ω) · · · 0\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
. 0\r
0 0 · · · dN (ω)\r
\r
\r
. (56)\r
We can now write the master equation in a diagonal form\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
i,ω\r
\u0012\r
Li(ω)ρ(t)L\r
†\r
i\r
(ω) −\r
1\r
2\r
n\r
L\r
†\r
iLi(ω), ρ(t)\r
o\u0013\r
≡ Lρ(t). (57)\r
This is the celebrated Lindblad (or Lindblad-Gorini-Kossakowski-Sudarshan) Master Equation. In the simplest case,\r
there will be only one relevant frequency ω, and the equation can be further simplified to\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
i\r
\u0012\r
Liρ(t)L\r
†\r
i −\r
1\r
2\r
n\r
L\r
†\r
iLi\r
, ρ(t)\r
o\u0013\r
≡ Lρ(t). (58)\r
The operators Li are usually referred to as jump operators.\r
C. Derivation of the Lindblad Equation as a CPT generator\r
The second way of deriving Lindblad equation comes from the following question: What is the most general\r
(Markovian) way of mapping density matrix onto density matrices? This is usually the approach from quantum\r
information researchers that look for general transformations of quantum systems. We analyse this problem following\r
mainly Ref. [28].\r
To start, we need to know what is the form of a general CPT-map.\r
Lemma 2 Any map V : B (H) → B (H) that can be written in the form Vρ = V\r
†ρV with V ∈ B (H) is positive.\r
The proof of the lemma requires a little algebra and a known property of normal matrices\r
Proof.\r
If ρ ≥ 0 ⇒ ρ = A†A , with A ∈ B(H). Therefore, Vρ = V\r
†ρV ⇒ hψ|V†ρV |ψi = hψ|V†A†AV |ψi = ||AV |ψi|| ≥ 0.\r
Therefore, if ρ is positive, the output of the map is also positive.\r
End of the proof.\r
This is a sufficient condition for the positivity of a map, but it is not necessary. It could happen that there are maps\r
that cannot be written in this form, but they are still positive. To go further, we need a more general condition, and\r
this comes in the form of the next theorem.

16\r
Theorem 1 Choi’s Theorem.\r
A linear map V : B(H) → B(H) is completely positive iff it can be expressed as\r
Vρ =\r
X\r
i\r
V\r
†\r
i\r
ρVi(59)\r
with Vi ∈ B(H).\r
The proof of this theorem requires some algebra.\r
Proof\r
The ‘if’ implication is a trivial consequence of the previous lemma. To prove the converse, we need to extend the\r
dimension of our system by the use of an auxiliary system. If d is the dimension of the Hilbert space of pure states,\r
H, we define a new Hilbert space of the same dimension HA.\r
We define a maximally entangled pure state in the bipartition HA ⊗ H in the way\r
|Γi ≡ X\r
d−1\r
i=0\r
|iiA ⊗ |ii, (60)\r
being {|ii} and {|iiA} arbitrary orthonormal bases for H and HA.\r
We can extend the action of our original map V, that acts on B(H) to our extended Hilbert space by defining the\r
map V2 : B(HA) ⊗ B(H) → B(HA) ⊗ B(H) as\r
V2 ≡ 1B(HA) ⊗ V. (61)\r
Note that the idea behind this map is to leave the auxiliary subsystem invariant while applying the original map to\r
the original system. This map is positive because V is completely positive. This may appear trivial, but as it has been\r
explained before complete positivity is a more restrictive property than positivity, and we are looking for a condition\r
to ensure complete positivity.\r
We can now apply the extended map to the density matrix corresponding to the maximally entangled state (60),\r
obtaining\r
V2|ΓihΓ| =\r
X\r
d−1\r
i,j=0\r
|iihj| ⊗ V|iihj|. (62)\r
Now we can use the maximal entanglement of the state |Γi to relate the original map V and the action V2|ΓihΓ| by\r
taking the matrix elements with respect to HA.\r
V|iihj| = hi|A (V2|ΓihΓ|)|jiA. (63)\r
To relate this operation to the action of the map to an arbitrary vector |ψi ∈ HA ⊗ H, we can expand it in this basis\r
as\r
|ψi =\r
X\r
d−1\r
i=0\r
X\r
d−1\r
j=0\r
αij |iiA ⊗ |ji. (64)\r
We can also define an operator V|ψi ∈ B (H) s.t. it transforms |Γi into |ψi. Its explicit action would be written as\r
\r
1A ⊗ V|ψi\r
\u0001\r
|Γi =\r
Pd−1\r
i,j=0 αij (1A ⊗ |jihi|)\r
\u0010Pd−1\r
k=0 |ki ⊗ |ki\r
\u0011\r
=\r
Pd−1\r
i,j,k=0 αij (|ki ⊗ |ji)hi|ki\r
=\r
Pd−q\r
i,j,k=0 αij (|ki ⊗ |ji) δi,k =\r
Pd−1\r
i,j=0 αij |ii ⊗ |ji = |ψi. (65)

17\r
At this point, we have related the vectors in the extended space HA ⊗ H to operators acting on H. This can only be\r
done because the vector |Γi is maximally entangled. We go now back to our extended map V2. Its action on |ΓihΓ| is\r
given by Eq. (62) and as it is a positive map it can be expanded as\r
V2 (|ΓihΓ|) =\r
d\r
X2−1\r
l=0\r
|vlihvl|. (66)\r
with |vli ∈ HA ⊗ H. The vectors |vli can be related to operators in H as in Eq. (65).\r
|vli = (1A ⊗ Vl)|Γi. (67)\r
Based on this result we can calculate the product of an arbitrary vector |iiA ∈ HA with |vli.\r
hi|A|vli = hi|A (1A ⊗ Vl)|Γi = Vl\r
X\r
d−1\r
k=0\r
hi|kiA ⊗ |ki. (68)\r
This is the last ingredient we need for the proof.\r
We come back to the original question, we want to characterise the map V. We do so by applying it to an arbitrary\r
basis element |iihj| of B (H).\r
V (|iihj|) = (hi|A ⊗ 1A) V2 (|ΓihΓ|) (|jiA ⊗ 1A) = (hi|A ⊗ 1A)\r
\r
\r
d\r
X2−1\r
l=0\r
|vlihvl|\r
\r
 (|jiA ⊗ 1A)\r
=\r
d\r
X2−1\r
l=0\r
[(hi|A ⊗ 1A)|vli] [hvl|(|jiA ⊗ 1A)] =\r
d\r
X2−1\r
l=0\r
Vl|iihj|Vl. (69)\r
As |iihj| is an arbitrary element of a basis any operator can be expanded in this basis. Therefore, it is straightforward\r
to prove that\r
Vρ =\r
d\r
X2−l\r
l\r
V\r
†\r
l\r
ρVl.\r
End of the proof.\r
Thanks to Choi’s Theorem, we know the general form of CP-maps, but there is still an issue to address. As density\r
matrices should have trace one, we need to require any physical maps to be also trace-preserving. This requirement\r
gives as a new constraint that completely defines all CPT-maps. This requirement comes from the following theorem.\r
Theorem 2 Choi-Kraus’ Theorem.\r
A linear map V : B(H) → B(H) is completely positive and trace-preserving iff it can be expressed as\r
Vρ =\r
X\r
l\r
V\r
†\r
l\r
ρVl(70)\r
with Vl ∈ B(H) fulfilling\r
X\r
l\r
VlV\r
†\r
l = 1H. (71)

18\r
Proof.\r
We have already proved that this is a completely positive map, we only need to prove that it is also trace-preserving\r
and that all trace preserving-maps fulfil Eq. (71). The ‘if’ proof is quite simple by applying the cyclic permutations\r
and linearity properties of the trace operator.\r
Tr [Vρ] = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
VlρV †\r
l\r
\r
 = Tr\r
\r
\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl\r
\r
 ρ\r
\r
 = Tr [ρ] . (72)\r
We have to prove also that any map in the form (70) is trace-preserving only if the operators Vl fulfil (71). We start\r
by stating that if the map is trace-preserving by applying it to an any arbitrary element of a basis of B (H) we should\r
obtain\r
Tr [V (|iihj|)] = Tr [|iihj|] = δi,j . (73)\r
As the map has a form given by (70) we can calculate this same trace in an alternative way.\r
Tr [V (|iihj|)] = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
Vl|iihj|V\r
†\r
l\r
\r
 = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl|iihj|\r
\r
\r
=\r
X\r
k\r
hk|\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl|iihj|\r
\r
 |ki = hj|\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl\r
\r
 |ii, (74)\r
where {|ki} is an arbitrary basis of H. As both equalities should be right we obtain\r
hj|\r
\r
\r
d\r
X2−1\r
l=1\r
VlV\r
†\r
l\r
\r
 |ii = δi,j , (75)\r
and therefore, the condition (71) should be fulfilled.\r
End of the proof.\r
Operators Vi of a map fulfilling condition (71) are called Krauss operators. Because of that, sometimes CPT-maps\r
are also called Krauss maps, especially when they are presented as a collection of Krauss operators. Both concepts\r
are ubiquitous in quantum information science. Krauss operators can also be time-dependent as long as they fulfil\r
relation (71) for all times.\r
At this point, we already know the form of CPT-maps, but we do not have a master equation, that is a continuous\r
set of differential equations. This means that we know how to perform an arbitrary operation in a system, but we do\r
not have an equation to describe its time evolution. To do so, we need to find a time-independent generator L such\r
that\r
d\r
dtρ (t) = Lρ(t), (76)\r
and therefore our CPT-map could be expressed as V(t) = e\r
Lt\r
. The following calculation is about founding the explicit\r
expression of L. We start by choosing an orthonormal basis of the bounded space of operators B(H), {Fi}\r
d\r
2\r
i=1. To be\r
orthonormal it should satisfy the following condition\r
hhFi|Fj ii ≡ Tr hF\r
†\r
i Fj\r
i\r
= δi,j . (77)\r
Without any loss of generality, we select one of the elements of the basis to be proportional to the identity, Fd2 = √\r
1\r
d\r
1H.\r
It is trivial to prove that the norm of this element is one, and it is easy to see from Eq. (77) that all the other elements\r
of the basis should have trace zero.

19\r
Tr [Fi] = 0 ∀i = 1, . . . , d2 − 1. (78)\r
The closure relation of this basis is 1B(H) =\r
P\r
i\r
|FiiihhFi|. Therefore, the Krauss operators can be expanded in this\r
basis by using the Fock-Liouville notation\r
Vl(t) =\r
d\r
X2\r
i=1\r
hhFi|Vl(t)ii|Fiii. (79)\r
As the map V(t) is in the form (59) we can apply (79) to obtain4.\r
V(t)ρ =\r
X\r
l\r
\r
\r
d\r
X2\r
i=1\r
hhFi|Vl(t)iiFi ρ\r
d\r
X2\r
j=1\r
F\r
†\r
j\r
hhVl(t)|Fj ii\r
\r
 =\r
d\r
X2\r
i,j=1\r
ci,j (t)FiρF†\r
j\r
, (80)\r
where we have absorved the sumation over the Krauss operators in the terms ci,j (t) = P\r
l\r
hhFi|VliihhVl|Fj ii. We go\r
back now to the original problem by applying this expansion into the time-derivative of Eq. (76)\r
dρ\r
dt = lim\r
∆t→0\r
1\r
∆t\r
(V(∆t)ρ − ρ) = lim\r
∆t→0\r
\r
\r
d\r
X2\r
i,j=1\r
ci,j (∆t)FiρF†\r
j − ρ\r
\r
\r
= lim\r
∆t→0\r
\r
\r
d\r
X2−1\r
i,j=0\r
ci,j (∆t)FiρF†\r
j +\r
d\r
X2−1\r
i=1\r
ci,d2 FiρF†\r
d2\r
+\r
d\r
X2−1\r
j=1\r
cd2,j (∆t)Fd2 ρF†\r
j + cd2,d2 (∆t)Fd2 ρF†\r
d2 − ρ\r
\r
 , (81)\r
where we have separated the summations to take into account that Fd2 = √\r
1\r
d\r
1H. By using this property this equation\r
simplifies to\r
dρ\r
dt = lim\r
∆t→0\r
1\r
∆t\r
\r
\r
d\r
X2−1\r
i,j=1\r
ci,j (∆t)FiρF†\r
j +\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
ci,d2 (∆t)Fi\r
ρ\r
+\r
1\r
√\r
d\r
d\r
X2−1\r
j=1\r
cd2,j (∆t)ρF†\r
j +\r
1\r
d\r
cd2,d2 (∆t)ρ − ρ\r
\r
 . (82)\r
The next step is to eliminate the explicit dependence with time. To do so, we define new constants to absorb all the\r
time intervals.\r
gi,j ≡ lim\r
∆t→0\r
ci,j (∆t)\r
∆t\r
(i, j < d2),\r
gi,d2 ≡ lim\r
∆t→0\r
ci,d2 (∆t)\r
∆t\r
(i < d2),\r
gd2,j ≡ lim\r
∆t→0\r
cd2,j (∆t)\r
∆t\r
(j < d2), (83)\r
gd2,d2 ≡ lim\r
∆t→0\r
cd2,d2 (∆t) − d\r
∆t\r
.\r
4 For simplicity, in this discussion we omit the explicit time- dependency of the density matrix.

20\r
Introducing these coefficients in Eq (82) we obtain an equation with no explicit dependence in time.\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j +\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
gi,d2 Fiρ +\r
1\r
√\r
d\r
d\r
X2−1\r
j=1\r
gd2,jρF†\r
j +\r
gd2,d2\r
d\r
ρ.\r
(84)\r
As we are already summing up over all the Krauss operators it is useful to define a new operator\r
F ≡\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
gi,d2 Fi. (85)\r
Applying it to Eq. (82).\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j + F ρ + ρF† +\r
gd2,d2\r
d\r
ρ. (86)\r
At this point, we want to separate the dynamics of the density matrix into a Hermitian (equivalent to von Neunmann\r
equation) and an incoherent part. We split the operator F in two to obtain a Hermitian and anti-Hermitian part.\r
F =\r
F + F\r
†\r
2\r
+ i\r
F − F\r
†\r
2i\r
≡ G − iH, (87)\r
where we have used the notation H for the Hermitian part for obvious reasons. If we take this definition to Eq. (86)\r
we obtain\r
dρ\r
dt = gi,jFiρF†\r
j + {G, ρ} − i[H, ρ] + gd2,d2\r
d\r
ρ. (88)\r
We define now the last operator for this proof, G2 ≡ G +\r
gd2,d2\r
2d\r
, and the expression of the time derivative leads to\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j + {G2, ρ} − i[H, ρ] . (89)\r
Until now we have imposed the complete positivity of the map, as we have required it to be written in terms of Krauss\r
maps, but we have not used the trace-preserving property. We impose now this property, and by using the cyclic\r
property of the trace, we obtain a new condition\r
Tr \u0014\r
dρ\r
dt \u0015\r
= Tr\r
\r
\r
d\r
X2−1\r
i,j=1\r
F\r
†\r
j Fiρ + 2G2ρ\r
\r
 = 0. (90)\r
Therefore, G2 should fulfil\r
G2 =\r
1\r
2\r
d\r
X2−1\r
i,j=1\r
gi,jF\r
†\r
j Fiρ. (91)\r
By applying this condition, we arrive at the Lindblad master equation\r
dρ\r
dt = −i[H, ρ] +\r
d\r
X2−1\r
i,j=1\r
gi,j \u0012FiρF†\r
j −\r
1\r
2\r
n\r
F\r
†\r
j Fi\r
, ρo\u0013. (92)

21\r
Finally, by definition the coefficients gi,j can be arranged to form a Hermitian, and therefore diagonalisable, matrix.\r
By diagonalising it, we obtain the diagonal form of the Lindblad master equation.\r
d\r
dtρ = −i[H, ρ] +X\r
k\r
Γk\r
\u0012\r
LkρL†\r
k −\r
1\r
2\r
n\r
LkL\r
†\r
k\r
, ρo\u0013≡ Lρ. (93)\r
D. Properties of the Lindblad Master Equation\r
Some interesting properties of the Lindblad equation are:\r
• Under a Lindblad dynamics, if all the jump operators are Hermitian, the purity of a system fulfils d\r
dt \r
Tr \u0002ρ\r
2\r
\u0003\u0001 ≤\r
0. The proof is given in A.\r
• The Lindblad Master Equation is invariant under unitary transformations of the jump operators\r
p\r
ΓiLi →\r
p\r
Γ\r
0\r
iL\r
0\r
i =\r
X\r
j\r
vijpΓjLj , (94)\r
with v representing a unitary matrix. It is also invariant under inhomogeneous transformations in the form\r
Li → L\r
0\r
i = Li + ai\r
H → H0 = H +\r
1\r
2i\r
X\r
j\r
Γj\r
\u0010\r
a\r
∗\r
jAj − ajA\r
†\r
j\r
\u0011\r
+ b, (95)\r
where ai ∈ C and b ∈ R. The proof of this can be found in Ref. [2] (Section 3).\r
• Thanks to the previous properties it is possible to find traceless jump operators without loss of generality.

22\r
Box 6. A master equation for a two-level system with decay.\r
Continuing our example of a two-level atom, we can make it more realistic by including the pos\u0002sibility of atom decay by the emission of a photon. This emission happens due to the interaction\r
of the atom with the surrounding vacuum statea. The complete quantum system would be in\r
this case the ‘atom+vacuum’ system and its time evolution should be given by the von Neumann\r
equation (13), where H represents the total ‘atom+vacuum’ Hamiltonian. This system belongs to\r
an infinite-dimension Hilbert space, as the radiation field has infinite modes. If we are interested\r
only in the time dependence state of the atom, we can derive a Markovian master equation for the\r
reduced density matrix of the atom (see for instance Refs. [1, 2]). The master equation we will\r
study is\r
d\r
dtρ(t) = −i[H, ρ] + Γ \u0012\r
σ\r
−ρσ+ −\r
1\r
2\r
\b\r
σ\r
+σ−, ρ\t\r
\u0013\r
, (96)\r
where Γ is the coupling between the atom and the vacuum.\r
In the Fock-Liouvillian space (following the same ordering as in Eq. (3)) the Liouvillian corre\u0002sponding to evolution (96) is\r
L =\r
\r
\r
0 iΩ −iΩ Γ\r
iΩ −iE −\r
Γ\r
2\r
0 −iΩ\r
−iΩ 0 −iE −\r
Γ\r
2\r
iΩ\r
0 −iΩ iΩ −Γ\r
\r
 . (97)\r
Expressing explicitly the set of differential equations we obtain\r
ρ˙00 = iΩρ01 − iΩρ10 + Γρ11\r
ρ˙01 = iΩρ00 −\r
\u0012\r
iE −\r
Γ\r
2\r
\u0013\r
ρ01 − iΩρ11\r
ρ˙10 = −iΩρ00 \u0012−iE −\r
Γ\r
2\r
\u0013\r
ρ10 + iΩρ11 (98)\r
ρ˙10 = −iΩρ01 + iΩρ10 − Γρ11\r
a This is why atoms decay.

23\r
VI. RESOLUTION OF THE LINDBLAD MASTER EQUATION\r
A. Integration\r
To calculate the time evolution of a system determined by a Master Equation in the form (96) we need to solve a\r
set of equations with as many equations as the dimension of the density matrix. In our example, this means to solve\r
a 4 variable set of equations, but the dimension of the problem increases exponentially with the system size. Because\r
of this, for bigger systems techniques for dimension reduction are required.\r
To solve systems of partial differential equations there are several canonical algorithms. This can be done analytically\r
only for a few simple systems and by using sophisticated techniques as damping bases [29]. In most cases, we have\r
to rely on numerical approximated methods. One of the most popular approaches is the 4th-order Runge-Kutta\r
algorithm (see, for instance, [30] for an explanation of the algorithm). By integrating the equations of motion, we can\r
calculate the density matrix at any time t.\r
The steady-state of a system can be obtained by evolving it for a long time (t → ∞). Unfortunately, this method\r
presents two difficulties. First, if the dimension of the system is big, the computing time would be huge. This means\r
that for systems beyond a few qubits, it will take too long to reach the steady-state. Even worse is the problem of\r
stability of the algorithms for integrating differential equations. Due to small errors in the calculation of derivatives by\r
the use of finite differences, the trace of the density matrix may not be constantly equal to one. This error accumulates\r
during the propagation of the state, giving non-physical results after a finite time. One solution to this problem is the\r
use of algorithms specifically designed to preserve the trace, as Crank-Nicholson algorithm [31]. The problem with\r
this kind of algorithms is that they consume more computational power than Runge-Kutta, and therefore they are\r
not useful to calculate the long-time behaviour of big systems. An analysis of different methods and their advantages\r
and disadvantages can be found at Ref. [32].\r
Box 7. Time dependency of the two-level system with decay.\r
In this box we show some results of solving Eq (96) and calculating the density matrix as a function\r
of time. A Mathematica notebook solving this problem can be found at [20]. To illustrate the time\r
behaviour of this system, we calculate the evolution for different state parameters. In all cases,\r
we start with an initial state that represents the state being excited ρ11 = 1, with no coherence\r
between different states, meaning ρ01 = ρ10 = 0. If the decay parameter Γ is equal to zero, the\r
problem reduces to solve von Neumann equation, and the result is displayed in Figure 2. The other\r
extreme case would be a system with no coherent dynamics (Ω = 0) but with decay. In this case,\r
we observe an exponential decay of the population of the excited state. Finally, we can calculate\r
the dynamics of a system with both coherent driving and decay. In this case, both behaviours\r
coexist, and there are oscillations and decay.\r
5 10 15 20\r
Time\r
0.2\r
0.4\r
0.6\r
0.8\r
1.0\r
Population\r
2 4 6 8 10\r
Time\r
0.2\r
0.4\r
0.6\r
0.8\r
1.0\r
Population\r
FIG. 4: Left: Population dynamics under a pure incoherent dynamics (Γ = 0.1, n = 1, Ω =\r
0, E = 1). Right: Population dynamics under both coherent and incoherent dynamics (Γ =\r
0.1, n = 1, Ω = 1, E = 1). In both the blue lines represent ρ11 and the orange one ρ00.

24\r
B. Diagonalisation\r
As we have discussed before, in the Fock-Liouville space the Liouvillian corresponds to a complex matrix (in general\r
complex, non-hermitian, and non-symmetric). By diagonalising it we can calculate both the time-dependent and the\r
steady-state of the density matrices. For most purposes, in the short time regime integrating the differential equations\r
may be more efficient than diagonalising. This is due to the high dimensionality of the Liouvillian that makes the\r
diagonalisation process very costly in computing power. On the other hand, in order to calculate the steady-state,\r
the diagonalisation is the most used method due to the problems of integrating the equation of motions discussed in\r
the previous section.\r
Let see first how we use diagonalisation to calculate the time evolution of a system. As the Liouvillian matrix is\r
non-Hermitian, we cannot apply the spectral theorem to it, and it may have different left and right eigenvectors. For\r
a specific eigenvalue Λi we can obtain the eigenvectors |Λ\r
R\r
i\r
ii and |Λ\r
L\r
i\r
ii s. t.\r
L | ˜ Λ\r
R\r
i\r
ii = Λi|Λ\r
R\r
i\r
ii\r
hhΛ\r
L\r
i\r
| L˜ = ΛihhΛ\r
L\r
i\r
| (99)\r
An arbitrary system can be expanded in the eigenbasis of L˜ as [1, 33]\r
|ρ(0)ii =\r
X\r
i\r
|Λ\r
R\r
i\r
iihhΛ\r
L\r
i\r
|ρ(0)ii. (100)\r
Therefore, the state of the system at a time t can be calculated in the form\r
|ρ(t)ii =\r
X\r
i\r
e\r
Λit\r
|Λ\r
R\r
i\r
iihhΛ\r
L\r
i\r
|ρ(0)ii. (101)\r
Note that in this case to calculate the state a time t we do not need to integrate into the interval [0, t], as we have to\r
do if we use a numerical solution of the differential set of equations. This is an advantage when we want to calculate\r
long-time behaviour. Furthermore, to calculate the steady-state of a system, we can look to the eigenvector that has\r
zero eigenvalue, as this is the only one that survives when t → ∞.\r
For any finite system, Evans’ Theorem ensures the existence of at least one zero eigenvalue of the Liouvillian\r
matrix [34, 35]. The eigenvector corresponding to this zero eigenvalue would be the steady-state of the system. In\r
exceptional cases, a Liouvillian can present more than one zero eigenvalues due to the presence of symmetry in the\r
system [26, 27, 36]. This is a non-generic case, and for most purposes, we can assume the existence of a unique\r
fixed point in the dynamics of the system. Therefore, diagonalising can be used to calculate the steady-state without\r
calculating the full evolution of the system. This can be done even analytically for small systems, and when numerical\r
approaches are required this technique gives better precision than integrating the equations of motion. The spectrum\r
of Liouvillian superoperators has been analysed in several recent papers [33, 37].

25\r
Box 8. Spectrum-analysis of the Liouvillian for the two-level system with decay.\r
Here we diagonalise (97) and obtain its steady state. A Mathematica notebook solving this problem\r
can be downloaded from [20]. This specific case is straightforward to diagonalize as the dimension\r
of the system is very low. We obtain 4 different eigenvalues, two of them are real while the other\r
two form a conjugated pair. Figure 5 sisplays the spectrum of the superoperator L given in (97).\r
-0.4 -0.3 -0.2 -0.1\r
-2\r
-1\r
1\r
2\r
FIG. 5: Spectrum of the Liouvillian matrix given by (97) for the general case of both coherent and\r
incoherent dynamics (Γ = 0.2, n = 1, Ω = 0, E = 1).\r
As there only one zero eigenvalue we can conclude that there is only one steady-state, and any\r
initial density matrix will evolve to it after an infinite-time evolution. By selecting the right\r
eigenvector corresponding to the zero-eigenvalue and normalizing it we obtain the density matrix.\r
This can be done even analytically. The result is the matrix:\r
ρSS =\r
\r
\r
(1+n)(4 E\r
2+(Γ+2n Γ)2\r
)+4(1+2n)Ω2\r
(1+2n)(4 E2+(Γ+2n Γ)2+8Ω2)\r
2(−2 E−i(Γ+2nΓ))Ω\r
(1+2n)(4 E2+(Γ+2n Γ)2+8 Ω2)\r
2(−2 E+i(Γ+2n Γ))Ω\r
(1+2n)(4 E2+(Γ+2n Γ)2+8Ω2)\r
n(4E\r
2+(Γ+2nΓ)2\r
)+4(1+2n)Ω2\r
(1+2n)(4 E2+(Γ+2nΓ)2+8 Ω2)\r
\r
 (102)\r
VII. ACKNOWLEDGEMENTS\r
The author wants to acknowledge the Spanish Ministry and the Agencia Espa˜nola de Investigaci´on (AEI) for\r
financial support under grant FIS2017-84256-P (FEDER funds).\r
[1] C.W. Gardiner and P. Zoller. Quantum Noise. Springer, Berlin, 2000.\r
[2] H.P. Breuer and F. Petruccione. The theory of open quantum systems. Oxford University Press, 2002.\r
[3] A. Rivas and S. Huelga. Open Quantum Systems. An Introduction. Springer, New York, 2012.\r
[4] G. Lindblad. On the generators of quantum dynamical semigroups. Commun. Math. Phys., 119:48, 1976.\r
[5] V. Gorini, A. Kossakowski, and E.C. Sudarsahan. Completely positive semigroups of n-level systems. J. Math. Phys.,\r
17:821, 1976.\r
[6] D. Manzano and E. Kyoseva. An atomic symmetry-controlled thermal switch. Scientific Reports, 6:31161, 2016.\r
[7] T. Prosen. Open xxz spin chain: Nonequilibrium steady state and a strict bound on ballistic transport. Phys. Rev. Lett.,\r
106:217206, 2011.

26\r
[8] D. Manzano, M. Tiersch, A. Asadian, and H.J. Briegel. Quantum transport efficiency and Fourier’s law. Phys. Rev. E,\r
86:061118, 2012.\r
[9] D. Manzano, C. Chuang, and J. Cao. Quantum transport in d-dimensional lattices. New J. Physics, 18:043044, 2015.\r
[10] B. Olmos, I. Lesanovsky, and J.P. Garrahan Facilitated Spin Models of Dissipative Quantum Glasses Phys. Rev. Lett.,\r
109:020403, 2012.\r
[11] J. Metz, M. Trupke, andA. Beige Robust Entanglement through Macroscopic Quantum Jumps Phys. Rev. Lett., 97:040503,\r
2006.\r
[12] R. Jones, J. A. Needham, I. Lesanovsky, F. Intravaia, Beatriz Olmos Modified dipole-dipole interaction and dissipation in\r
an atomic ensemble near surfaces Phys. Rev. A, 97:053841, 2018.\r
[13] D.A. Lidar, I.L. Chuang, and K. B. Whaley. Decoherence-free subspaces for quantum computation. Phys. Rev. Lett.,\r
81(12):2594, 1998.\r
[14] B. Kraus, H. P. B¨uchler, S. Diehl, A. Kantian, A. Micheli, and P. Zoller. Preparation of entangled states by quantum\r
markov processes. Phys. Rev. A, 2008.\r
[15] T.A. Brun. Continuous measurements, quantum trajectories, and decoherent histories. Phys. Rev. A, 61:042107, 2000.\r
[16] M. Schlosshauer. Decoherence and the Quantum-to-Classical Transition. Springer, New York, 2007.\r
[17] M. Plenio and S. Huelga. Dephasing-assisted transport: quantum networks and biomolecules. New J. Phys., 10:113019,\r
2008.\r
[18] M. Mohseni, P. Rebentrost, S. Lloyd, and A. Aspuru-Guzik. Enviroment-assisted quantum walks in photosynthetic energy\r
transfer. Journal of Chemical Physics, 129:174106, 2008.\r
[19] D. Manzano. Quantum transport in quantum networks and photosynthetic complexes at the steady state. PLoS ONE,\r
8(2):e57041, 2013.\r
[20] https://ic1.ugr.es/manzano/Descargas/Lindblad/Lindblad_Manzano.zip\r
[21] L. Debnath and P. Mikusi´nki. Introduction to Hilbert Spaces with Applications. Elsevier Academic Press, 2005.\r
[22] M.A. Nielsen and I.L. Chuang. Quantum Computation and Quantum Information. Cambridge Univ. Press, Cambridge,\r
2000.\r
[23] J.J. Sakurai. Modern Quantum Mechanics. Addison-Wesley Publishing Co., 1994.\r
[24] A. Galindo and P. Pascual. Quantum Mechanics I. Springer, Berlin, 1990.\r
[25] A. Peres. Quantum Theory: Concepts and Methods. Kluwer Academic Publishers, 1995.\r
[26] D. Manzano and P.I. Hurtado. Harnessing symmetry to control quantum transport. Adv. Phys, 67:1, 2018.\r
[27] D. Manzano and P.I. Hurtado. Symmetry and the thermodynamics of currents in open quantum systems Phys. Rev. B,\r
90:125138, 2014.\r
[28] M.M. Wilde. Quantum Information Theory. Cambridge Univ. Press, Cambridge, 2017.\r
[29] H.J. Briegel and B.G. Englert. Quantum optical master equation: The use of damping bases. Phys. Rev. A, 47:3311, 1993.\r
[30] W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. Numerical Recipes. Cambridge Univ. Press, Cambridge,\r
2007.\r
[31] A. Goldberg, H. Schey, and J.L. Schwartz. Computer-generated motion pictures of one-dimensional quantum-mechanical\r
transmission and reflection phenomena. Am. J. Phys., 35:177, 1967.\r
[32] M. Riesch and C. Jirauschek. Analyzing the positivity preservation of numerical methods for the liouville-von neumann\r
equation. J. Comp. Phys., 390:290, 2019.\r
[33] J. Thingna, D. Manzano, and J. Cao. Dynamical signatures of molecular symmetries in nonequilibrium quantum transport.\r
Scientific Reports, 6:28027, 2016.\r
[34] D.E. Evans. Irreducible quantum dynamical semigroups. Commun. Math. Phys., 54:293, 1977.\r
[35] D.E. Evans and H. Hance-Olsen. The generators of positive semigroups. Journal of Positive Analysis, 32:207, 1979.\r
[36] B. Buˇca and T. Prosen. A note on symmetry reductions of the Lindblad equation: Transport in constrained open spin\r
chains. New J. Physics, 14:073007, 2012.\r
[37] V.V. Albert and L. Jiang. Symmetries and conserved quantities in Lindblad master equations. Phys. Rev. A, 89:022118,\r
2014.

27\r
Appendix A: Proof of d\r
dtTr \u0002\r
ρ\r
2\r
\u0003\r
≤ 0\r
In this appendix we proof that under the Lindblad dynamics given by Eq. (93) the purity of a density matrix fulfils\r
that d\r
dtTr \u0002\r
ρ\r
2\r
\u0003\r
≤ 0 if all the jump operators of the Lindblad dynamics are Hermitian.\r
We start just by interchanging the trace and the derivative. As the trace is a linear operation it commutes with\r
the derivation, and we have\r
d\r
dt\r
\r
Tr \u0002ρ\r
2\r
\u0003\u0001 = Tr \u0014\r
dρ2\r
dt \u0015\r
= Tr [2ρρ˙] , (A1)\r
where we have used the cyclic property of the trace operator5. By inserting the Lindblad Eq. (93) into the r.h.s of\r
(A1) we obtain\r
d\r
dt\r
\r
Tr \u0002ρ\r
2\r
\u0003\u0001 = −\r
i\r
¯h\r
Tr [(2ρ (Hρ − ρH))]\r
+ 2X\r
k\r
ΓkTr hρ Lkρ L†\r
k\r
i\r
− 2\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
. (A2)\r
The first term is zero. Therefore, the inequality we want to prove becomes equivalent to\r
X\r
k\r
ΓkTr hρ Lkρ L†\r
k\r
i\r
≤\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
(A3)\r
As the density matrix is Hermitian we can diagonalize it to obtain its eigenvalues (Λi ∈ R) and its corresponding\r
eigenvectors (|Λii). The density matrix is diagonal in its own eigenbasis and can be expressed as6\r
ρ → ρ˜ =\r
X\r
i\r
Λi|ΛiihΛi|, (A4)\r
where we assume an ordering of the eigenvalues in the form Λ0 ≥ Λ1 ≥ · · · ≥ Λd.\r
We rename the jump operators in this basis as L˜\r
i a. Expanding each term of the inequality (A3) in this basis we\r
obtain\r
X\r
k\r
ΓkTr hρ Lk ρ L†\r
k\r
i\r
=\r
X\r
k\r
ΓkTr\r
\r
\r
 X\r
i\r
Λi|ΛiihΛi|\r
!\r
L˜\r
k\r
\r
\r
X\r
j\r
Λj |Λj ihΛj |\r
\r
 L˜\r
k\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjTr hL˜†\r
k\r
|ΛiihΛi|L˜\r
k|Λj ihΛj |\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjTr \u0014\f\r
\f\r
\fhΛi\r
|L˜\r
k|Λj i\r
\f\r
\f\r
\f\r
2\r
\u0015\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjx\r
(k)\r
ij , (A5)\r
where we have introduced the oefficients x\r
(k)\r
ij ≡\r
\f\r
\f\r
\fhΛi\r
|L˜\r
k|Λj i\r
\f\r
\f\r
\f\r
2\r
. As the operators Lk are Hermitian these coefficients\r
fulfil x\r
(k)\r
ij = x\r
(k)\r
ji\r
The second term is expanded as\r
5 This property is used along all the demonstration without ex\u0002plicitly mentioning it.\r
6 This eigenbasis changes with time, of course, but the proof is\r
valid as the inequality should be fulfilled at any time.

28\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
=\r
X\r
k\r
ΓkTr\r
\r
\r
 X\r
i\r
Λi|ΛiihΛi|\r
! \r
\r
X\r
j\r
Λj |Λj ihΛj |\r
\r
 L˜†\r
kL˜\r
k\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
ΛiΛjTr hL˜\r
k|ΛiihΛj |L˜†\r
k\r
hΛi|Λj i\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i\r
Λ\r
2\r
i Tr h\r
L˜\r
k|ΛiihΛi\r
|L˜†\r
k\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i\r
Λ\r
2\r
i Tr\r
\r
L˜\r
k|ΛiihΛi\r
|L˜†\r
k\r
\r
\r
X\r
j\r
|Λj ihΛj |\r
\r
\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i Tr h\r
hΛj |L˜\r
k|Λii + hΛi\r
|L˜\r
k|Λj i\r
i\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i xij , (A6)\r
where we have used the closure relation in the density matrix eigenbasis, 1H =\r
P\r
j\r
|Λj ihΛj |. The inequality can be\r
written now as\r
X\r
k\r
Γk\r
X\r
ij\r
ΛiΛjxij ≤\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i xij . (A7)\r
As xij = xji we can re-order the ij sum in the following way\r
X\r
k\r
Γk\r
X\r
i\r
\r
\r
X\r
j≤i\r
2ΛiΛjx\r
(k)\r
ij + Λ2\r
i x\r
(k)\r
ii\r
\r
 ≤\r
X\r
k\r
Γk\r
X\r
i\r
\r
\r
X\r
j<i\r
\r
Λ\r
2\r
i + Λ2\r
j\r
\u0001\r
x\r
(k)\r
ij + Λ2\r
i x\r
(k)\r
ii\r
\r
 . (A8)\r
Therefore, we can reduce the proof of this inequality to the proof of a set of inequalities\r
2ΛiΛjx\r
(k)\r
ij ≤\r
\r
Λ\r
2\r
i + Λ2\r
j\r
\u0001\r
x\r
(k)\r
ij ∀ (k, i, j). (A9)\r
It is obvious that (A9) ⇒ (A8) (but not the other way around). The inequalities (A9) are easily proved just by taking\r
into account that x\r
(k)\r
ij ≥ 0 and applying the Triangular Inequality."""

[metadata]
title = "arxiv 1906.04478 manzano 2019 lindblad short intro"
authors = ["Unknown"]
arxiv = "1906.04478"
year = 1906

[[sections]]
number = "0"
title = "Preamble"
text = """
A short introduction to the Lindblad Master Equation\r
Daniel Manzano1\r
1Electromagnetism and Condensed Matter Department and Carlos I Institute for Theoretical\r
and Computational Physics. University of Granada. E-18071 Granada. Spain ∗\r
The theory of open quantum system is one of the most essential tools for the development of\r
quantum technologies. Furthermore, the Lindblad (or Gorini-Kossakowski-Sudarshan-Lindblad)\r
Master Equation plays a key role as it is the most general generator of Markovian dynamics in\r
quantum systems. In this paper, we present this equation together with its derivation and methods\r
of resolution. The presentation tries to be as self-contained and straightforward as possible to be\r
useful to readers with no previous knowledge of this field.\r
I. INTRODUCTION\r
Open quantum system techniques are vital for many studies in quantum mechanics [1–3]. This happens because\r
closed quantum systems are just an idealisation of real systems1, as in Nature nothing can be isolated. In practical\r
problems, the interaction of the system of interest with the environment cannot be avoided, and we require an approach\r
in which the environment can be effectively removed from the equations of motion.\r
The general problem addressed by Open Quantum Theory is sketched in Figure 1. In the most general picture, we\r
have a total system that conforms a closed quantum system by itself. We are mostly interested in a subsystem of the\r
total one (we call it just “system” instead “total system”). Therefore, the whole system is divided into our system of\r
interest and an environment. The goal of Open Quantum Theory is to infer the equations of motions of the reduced\r
systems from the equation of motion of the total system. For practical purposes, the reduced equations of motion\r
should be easier to solve than the full dynamics of the system. Because of his requirement, several approximations\r
are usually made in the derivation of the reduced dynamics.\r
FIG. 1: A total system divided into the system of interest, “System”, and the environment.\r
∗ manzano@onsager.ugr.es"""

[[sections]]
number = "1"
title = "The same happens with closed classical systems."
text = """
arXiv:1906.04478v3 [quant-ph] 5 Feb 2020

2\r
One particular, and interesting, case of study is the dynamics of a system connected to several baths modelled by\r
a Markovian interaction. In this case the most general quantum dynamics is generated by the Lindblad equation\r
(also called Gorini-Kossakowski-Sudarshan-Lindblad equation) [4, 5]. It is difficult to overemphasize the importance\r
of this Master Equation. It plays an important role in fields as quantum optics [1, 6], condensed matter [7–10], atomic\r
physics [11, 12], quantum information [13, 14], decoherence [15, 16], and quantum biology [17–19].\r
The purpose of this paper is to provide basic knowledge about the Lindblad Master Equation. In Section II,\r
the mathematical requirements are introduced while in Section III there is a brief review of quantum mechanical\r
concepts that are required to understand the paper. Section IV, includes a description of a mathematical framework,\r
the Fock-Liouville space, that is especially useful to work in this problem. In Section V, we define the concept of\r
CPT-Maps, derive the Lindblad Master Equation from two different approaches, and we discus several properties of\r
the equation. Finally, Section VI is devoted to the resolution of the master equation using different methods. To\r
deepen in the techniques of solving the Lindblad equation, an example consisting of a two-level system with decay\r
is analysed, illustrating the content of every section. The problems proposed are solved by the use of Mathematica\r
notebooks that can be found at [20].\r
II. MATHEMATICAL BASIS\r
The primary mathematical tool in quantum mechanics is the theory of Hilbert spaces. This mathematical framework\r
allows extending many results from finite linear vector spaces to infinite ones. In any case, this tutorial deals only\r
with finite systems and, therefore, the expressions ‘Hilbert space’ and ‘linear space’ are equivalent. We assume that\r
the reader is skilled in operating in Hilbert spaces. To deepen in the field of Hilbert spaces we recommend the book\r
by Debnath and Mikusi´nki [21]. If the reader needs a brief review of the main concepts required for understanding\r
this paper, we may recommend Nielsen and Chuang’s Quantum Computing book [22]. It is also required some basic\r
knowledge about infinitesimal calculus, like integration, derivation, and the resolution of simple differential equations,\r
To help the readers, we have made a glossary of the most used mathematical terms. It can be used also as a checklist\r
of terms the reader should be familiar with.\r
Glossary:\r
• H represents a Hilbert space, usually the space of pure states of a system.\r
• |ψi ∈ H represents a vector of the Hilbert space H (a column vector).\r
• hψ| ∈ H represents a vector of the dual Hilbert space of H (a row vector).\r
• hψ|φi ∈ C is the scalar product of vectors |ψi and |φi.\r
• |||ψi|| is the norm of vector |ψi. |||ψi|| ≡ p\r
hψ|ψi.\r
• B(H) represents the space of bounded operators acting on the Hilbert space B : H → H.\r
• 1H ∈ B(H) is the Identity Operator of the Hilbert space H s.t. 1H|ψi = |ψi, ∀|ψi ∈ H.\r
• |ψihφ| ∈ B(H) is the operator such that (|ψihφ|)|ϕi = hφ|ϕi|ψi, ∀|ϕi ∈ H.\r
• O† ∈ B(H) is the Hermitian conjugate of the operator O ∈ B(H).\r
• U ∈ B(H) is a unitary operator iff UU† = U\r
†U = 1.\r
• H ∈ B(H) is a Hermitian operator iff H = H†.\r
• A ∈ B(H) is a positive operator (A > 0) iff hφ|A|φi ≥ 0, ∀|φi ∈ H\r
• P ∈ B(H) is a proyector iff P P = P.\r
• Tr [B] represents the trace of operator B.\r
• ρ (L) represents the space of density matrices, meaning the space of bounded operators acting on H with trace\r
1 and positive.\r
• |ρii is a vector in the Fock-Liouville space.\r
• hhA|Bii = Tr \u0002A†B\r
\u0003\r
is the scalar product of operators A, B ∈ B(H) in the Fock-Liouville space.\r
• L˜ is the matrix representation of a superoperator in the Fock-Liouville space."""

[[sections]]
number = "3"
title = "III. (VERY SHORT) INTRODUCTION TO QUANTUM MECHANICS"
text = """
The purpose of this chapter is to refresh the main concepts of quantum mechanics necessary to understand the\r
Lindblad Master Equation. Of course, this is NOT a full quantum mechanics course. If a reader has no background\r
in this field, just reading this chapter would be insufficient to understand the remaining of this tutorial. Therefore,\r
if the reader is unsure of his/her capacities, we recommend to go first through a quantum mechanics course or to\r
read an introductory book carefully. There are many great quantum mechanics books in the market. For beginners,\r
we recommend Sakurai’s book [23] or Nielsen and Chuang’s Quantum Computing book [22]. For more advanced\r
students, looking for a solid mathematical description of quantum mechanics methods, we recommend Galindo and\r
Pascual [24]. Finally, for a more philosophical discussion, you should go to Peres’ book [25].\r
We start stating the quantum mechanics postulates that we need to understand the derivation and application of\r
the Lindblad Master Equation. The first postulate is related to the concept of a quantum state.\r
Postulate 1 Associated to any isolated physical system, there is a complex Hilbert space H, known as the state space\r
of the system. The state of the system is entirely described by a state vector, which is a unit vector of the Hilbert space\r
(|ψi ∈ H).\r
As quantum mechanics is a general theory (or a set of theories), it does not tell us which is the proper Hilbert\r
space for each system. This is usually done system by system. A natural question to ask is if there is a one-to-one\r
correspondence between unit vectors and physical states, meaning that if every unit vector corresponds to a physical\r
system. This is resolved by the following corollary that is a primary ingredient for quantum computation theory (see\r
Ref. [22] Chapter 7).\r
Corollary 1 All unit vectors of a finite Hilbert space correspond to possible physical states of a system.\r
Unit vectors are also called pure states. If we know the pure state of a system, we have all physical information\r
about it, and we can calculate the probabilistic outcomes of any potential measurement (see the next postulate). This\r
is a very improbable situation as experimental settings are not perfect, and in most cases, we have only imperfect\r
information about the state. Most generally, we may know that a quantum system can be in one state of a set {|ψii}\r
with probabilities pi. Therefore, our knowledge of the system is given by an ensemble of pure states described by the\r
set {|ψii, pi}. If more than one piis different from zero the state is not pure anymore, and it is called a mixed state.\r
The mathematical tool that describes our knowledge of the system, in this case, is the density operator (or density\r
matrix).\r
ρ ≡\r
X\r
i\r
pi|ψiihψi|. (1)\r
Density matrices are bounded operators that fulfil two mathematical conditions"""

[[sections]]
number = "1"
title = "A density matrix ρ has unit trace (Tr[ρ] = 1)."
text = ""

[[sections]]
number = "2"
title = "A density matrix is a positive matrix ρ > 0."
text = """
Any operator fulfilling these two properties is considered a density operator. It can be proved trivially that density\r
matrices are also Hermitian.\r
If we are given a density matrix, it is easy to verify if it belongs to a pure or a mixed state. For pure states, and\r
only for them, Tr[ρ\r
2\r
] = Tr[ρ] = 1. Therefore, if Tr[ρ\r
2\r
] < 1 the system is mixed. The quantity Tr[ρ\r
2\r
] is called the\r
purity of the states, and it fulfils the bounds 1\r
d ≤ Tr[ρ\r
2\r
] ≤ 1, being d the dimension of the Hilbert space.\r
If we fix an arbitrary basis {|ii}N\r
i=1 of the Hilbert space the density matrix in this basis is written as ρ = PN\r
i,j=1 ρi,j |iihj|, or\r
ρ =\r
\r
\r
ρ00 ρ01 · · · ρ0N\r
ρ10 ρ11 · · · ρ1N\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
ρN0 ρN1 · · · ρNN\r
\r
\r
, (2)

4\r
where the diagonal elements are called populations ρii ∈ R\r
+\r
0\r
and P\r
i\r
ρi,i = 1\u0001\r
, while the off-diagonal elements are\r
called coherences ρi,j ∈ C and ρi,j = ρ\r
∗\r
j,i\u0001\r
. Note that this notation is base-dependent.\r
Box 1. State of a two-level system (qubit)\r
The Hilbert space of a two-level system is just the two-dimension lineal space H2. Examples of\r
this kind of system are 1\r
2\r
-spins and two-level atoms. We can define a basis of it by the orthonormal\r
vectors: {|0i, |1i}. A pure state of the system would be any unit vector of H2. It can always be\r
expressed as a |ψi = a|0i + b|1i with a, b ∈ C s. t. |a|\r
2 + |b|2 = 1.\r
A mixed state is therefore represented by a positive unit trace operator ρ ∈ O(H2).\r
ρ =\r
\u0012\r
ρ00 ρ01\r
ρ10 ρ11\u0013\r
= ρ00|0ih0| + ρ01|0ih1| + ρ10|1ih0| + ρ11|1ih1|, (3)\r
ant it should fulfil ρ00 + ρ11 = 1 and ρ01 = ρ\r
∗\r
10.\r
Once we know the state of a system, it is natural to ask about the possible outcomes of experiments (see Ref. [23],\r
Section 1.4).\r
Postulate 2 All possible measurements in a quantum system are described by a Hermitian operator or observable.\r
Due to the Spectral Theorem we know that any observable O has a spectral decomposition in the form2\r
O =\r
X\r
i\r
ai|aiihai|, (4)\r
being ai ∈ R the eigenvalues of the observable and |aii their corresponding eigenvectors. The probability of obtaining\r
the result ai when measuring the property described by observable O in a state |ψi is given by\r
P(ai) = |hψ|aii|2. (5)\r
After the measurement we obtain the state |aii if the outcome ai was measured. This is called the post-measurement\r
state.\r
This postulate allow us to calculate the possible outputs of a system, the probability of these outcomes, as well as\r
the after-measurement state. A measurement usually changes the state, as it can only remain unchanged if it was\r
already in an eigenstate of the observable.\r
It is possible to calculate the expectation value of the outcome of a measurement defined by operator O in a state\r
|ψi by just applying the simple formula\r
hOi = hψ|O|ψi. (6)\r
With a little algebra we can translate this postulate to mixed states. In this case, the probability of obtaining an\r
output ai that corresponds to an eigenvector |aii is\r
P(ai) = Tr [|aiihai|ρ] , (7)\r
and the expectation value of operator O is\r
hOi = Tr [Oρ] . (8)"""

[[sections]]
number = "2"
title = "For simplicity, we assume a non-degenerated spectrum."
text = ""

[[sections]]
number = "5"
title = "Box 2. Measurement in a two-level system."
text = """
A possible test to perform in our minimal model is to measure the energetic state of a system, as\u0002suming that both states have a different energy. The observable corresponding to this measurement\r
would be\r
H = E0|0ih0| + E1|1ih1|. (9)\r
This operator has two eigenvalues {E0, E1} with two corresponding eigenvectors {|0i, |1i}.\r
If we have a pure state ψ = a|0i + b|1i the probability of measuring the energy E0 would be\r
P(E0) = |h0|ψi|2 = |a|"""

[[sections]]
number = "2"
title = "The probability of finding E1 would be P(E1) = |h1|ψi|2 = |b|"
text = ""

[[sections]]
number = "2"
title = "The"
text = """
expected value of the measurement is hHi = E0 |a|\r
2 + E1 |b|2\r
.\r
In the more general case of having a mixed state ρ = ρ00|0ih0| + ρ01|0ih1| + ρ10|1ih0| + ρ11|1ih1| the\r
probability of finding the ground state energy is P(0) = Tr [|0ih0|ρ] = ρ00, and the expected value\r
of the energy would be hHi = Tr [Hρ] = E0ρ00 + E1ρ11.\r
Another natural question to ask is how quantum systems evolve. The time-evolution of a pure state of a closed\r
quantum system is given by the Schr¨odinger equation (see [24], Section 2.9).\r
Postulate 3 Time evolution of a pure state of a closed quantum system is given by the Schr¨odinger equation\r
d\r
dt|ψ(t)i = −i¯hH|ψ(t)i, (10)\r
where H is the Hamiltonian of the system and it is a Hermitian operator of the Hilbert space of the system state (from\r
now on we avoid including Planck’s constant by selecting the units such that ¯h = 1).\r
The Hamiltonian of a system is the operator corresponding to its energy, and it can be non-trivial to realise.\r
Schr¨odinger equation can be formally solved in the following way. If at t = 0 the state of a system is given by |ψ(0)i\r
at time t it will be\r
|ψ(t)i = e\r
−iHt|ψ(0)i. (11)\r
As H is a Hermitian operator, the operator U = e\r
−iHt is unitary. This gives us another way of phrasing Postulate 3.\r
Postulate 3’ The evolution of a closed system is given by a unitary operator of the Hilbert space of the system\r
|ψ(t)i = U|ψ(0)i, (12)\r
with U ∈ B (H) s.t. UU† = U\r
†U = 1.\r
It is easy to prove that unitary operators preserve the norm of vectors and, therefore, transform pure states into pure\r
states. As we did with the state of a system, it is reasonable to wonder if any unitary operator corresponds to the\r
evolution of a real physical system. The answer is yes.\r
Lemma 1 All unitary evolutions of a state belonging to a finite Hilbert space can be constructed in several physical\r
realisations like photons and cold atoms.\r
The proof of this lemma can be found at [22].

6\r
The time evolution of a mixed state can be calculated just by combining Eqs. (10) and (1), giving the von-Neumann\r
equation.\r
ρ˙ = −i[H, ρ] ≡ Lρ, (13)\r
where we have used the commutator [A, B] = AB − BA, and L is the so-called Liouvillian superoperator.\r
It is easy to prove that the Hamiltonian dynamics does not change the purity of a system\r
d\r
dtTr \u0002\r
ρ\r
2\r
\u0003\r
= Tr \u0014\r
dρ2\r
dt \u0015\r
= Tr [2ρρ˙] = −2iTr [ρ (Hρ − ρH)] = 0, (14)\r
where we have used the cyclic property of the trace. This result illustrates that the mixing rate of a state does not\r
change due to the quantum evolution.\r
Box 3. Time evolution of a two-level system.\r
The evolution of our isolated two-level system is described by its Hamiltonian\r
Hfree = E0|0ih0| + E1|1ih1|, (15)\r
As the states |0i and |1i are Hamiltonian eigenstates if at t = 0 the atom is at the excited state\r
|ψ(0)i = |1i after a time t the state would be |ψ(t)i = e\r
−iHt|1i = e−iE1t\r
|1i.\r
As the system was already in an eigenvector of the Hamiltonian, its time-evolution consists only in\r
adding a phase to the state, without changing its physical properties. (If an excited state does not\r
change, why do atoms decay?) Without losing any generality we can fix the energy of the ground\r
state as zero, obtaining\r
Hfree = E|1ih1|, (16)\r
with E ≡ E1. To make the model more interesting we can include a driving that coherently\r
switches between both states. The total Hamiltonian would be then\r
H = E|1ih1| + Ω (|0ih1| + |1ih0|), (17)\r
where Ω is the frequency of driving. By using the von-Neumann equation (13) we can calculate\r
the populations (ρ00, ρ11) as a function of time. The system is then driven between the states, and\r
the populations present Rabi oscillations, as it is shown in Fig. 2.\r
1 2 3 4 5\r
Time\r
0.2\r
0.4\r
0.6\r
0.8"""

[[sections]]
number = "1.0"
title = "Population"
text = """
FIG. 2: Population dynamics under a quantum dynamics (Parameters are Ω = 1, E = 1). The\r
blue line represents ρ11 and the orange one ρ00.

7\r
Finally, as we are interested in composite quantum systems, we need to postulate how to work with them.\r
Postulate 4 The state-space of a composite physical system, composed by N subsystems, is the tensor product of the\r
state space of each component H = H1 ⊗ H2 ⊗ · · · ⊗ HN . The state of the composite physical system is given by a\r
unit vector of H. Moreover, if each subsystem belonging to Hi is prepared in the state |ψii the total state is given by\r
|ψi = |ψ1i ⊗ |ψ2i ⊗ · · · ⊗ |ψN i.\r
The symbol ⊗ represents the tensor product of Hilbert spaces, vectors, and operators. If we have a composited mixed\r
state where each component is prepared in the state ρi the total state is given by ρ = ρ1 ⊗ ρ2 ⊗ · · · ⊗ ρN .\r
States that can be expressed in the simple form |ψi = |ψ1i ⊗ |ψ2i, in any specific basis, are very particular and they\r
are called separable states (For this discussion, we use a bipartite system as an example. The extension to a general\r
multipartite system is straightforward.) . In general, any arbitrary state should be described as |ψi =\r
P\r
i,j |ψii ⊗ |ψj i\r
(or ρ =\r
P\r
i,j ρi ⊗ ρj for mixed states). Non-separable states are called entangled states.\r
Now that we know how to compose systems, but we can be interested in going the other way around. If we have\r
a system belonging to a bipartite Hilbert space in the form H = Ha ⊗ Hb we can be interested in studying some\r
properties of the subsystem corresponding to one of the subspaces. To do so, we define the reduced density matrix. If\r
the state of our system is described by a density matrix ρ the reduced density operator of the subsystem a is defined\r
by the operator\r
ρa ≡ Trb [ρ] , (18)\r
were Trb is the partial trace over subspace b and it is defined as [22]\r
Trb\r
\r
\r
X\r
i,j,k,l\r
|aiihaj | ⊗ |bkihbl|\r
\r
 ≡\r
X\r
i,j\r
|aiihaj |Tr\r
\r
\r
X\r
k,l\r
|bkihbl|\r
\r
 . (19)\r
The concepts of reduced density matrix and partial trace are essential in the study of open quantum systems. If we\r
want to calculate the equation of motions of a system affected by an environment, we should trace out this environment\r
and deal only with the reduced density matrix of the system. This is the main idea of the theory of open quantum\r
systems."""

[[sections]]
number = "8"
title = "Box 4. Two two-level atoms"
text = """
If we have two two-level systems, the total Hilbert space is given by\r
H = H2 ⊗ H2. A basis of this Hilbert space would be given by the set\r
{|00i ≡ |0i1 ⊗ |0i2, |01i ≡ |0i1 ⊗ |1i2, |10i ≡ |1i1 ⊗ |0i2, |11i ≡ |1i1 ⊗ |1i2}. If both systems\r
are in their ground state, we can describe the total state by the separable vector\r
|ψiG = |00i. (20)\r
A more complex, but still separable, state can be formed if both systems are in superposition.\r
|ψiS =\r
1\r
√\r
2\r
(|0i1 + |1i1) ⊗\r
1\r
√\r
2\r
(|0i2 + |1i2)\r
=\r
1\r
2\r
(|00i + |10i + |01i + |11i) (21)\r
An entangled state would be\r
|ψiE =\r
1\r
√\r
2\r
(|00i + |11i). (22)\r
This state cannot be separated into a direct product of each subsystem. If we want to obtain a\r
reduced description of subsystem 1 (or 2) we have to use the partial trace. To do so, we need first\r
to calculate the density matrix corresponding to the pure state |ψiE.\r
ρE = |ψihψ|E =\r
1\r
2\r
(|00ih00| + |00ih11| + |11ih00| + |11ih11|). (23)\r
We can now calculate the reduced density matrix of the subsystem 1 by using the partial trace.\r
ρ\r
(1)\r
E = h0|2ρE|0i2 + h1|2ρE|1i2 =\r
1\r
2\r
(|00ih00|1 + |11ih11|2). (24)\r
From this reduced density matrix, we can calculate all the measurement statistics of subsystem 1."""

[[sections]]
number = "9"
title = "IV. THE FOCK-LIOUVILLE HILBERT SPACE. THE LIOUVILLE SUPEROPERATOR"
text = """
In this section, we revise a useful framework for both analytical and numerical calculations. It is clear that some\r
linear combinations of density matrices are valid density matrices (as long as they preserve positivity and trace 1).\r
Because of that, we can create a Hilbert space of density matrices just by defining a scalar product. This is clear\r
for finite systems because in this case scalar space and Hilbert space are the same things. It also happens to be true\r
for infinite spaces. This allows us to define a linear space of matrices, converting the matrices effectively into vectors\r
(ρ → |ρii). This is called Fock-Liouville space (FLS). The usual definition of the scalar product of matrices φ and ρ\r
is defined as hhφ|ρii ≡ Tr \u0002φ\r
†ρ\r
\u0003\r
. The Liouville super-operator from Eq. (13) is now an operator acting on the Hilbert\r
space of density matrices. The main utility of the FLS is to allow the matrix representation of the evolution operator.\r
Box 5. Time evolution of a two-level system.\r
The density matrix of our system (3) can be expressed in the FLS as\r
|ρii =\r
\r
\r
ρ00\r
ρ01\r
ρ10\r
ρ11\r
\r
 . (25)\r
The time evolution of a mixed state is given by the von-Neumann equation (13). The Liouvillian\r
superoperator can now be expressed as a matrix\r
L˜ =\r
\r
\r
0 iΩ −iΩ 0\r
iΩ iE 0 −iΩ\r
−iΩ 0 −iE iΩ\r
0 −iΩ iΩ 0\r
\r
 , (26)\r
where each row is calculated just by observing the output of the operation −i[H, ρ] in the compu\u0002tational basis of the density matrices space. The time evolution of the system now corresponds to\r
the matrix equation d|ρii\r
dt = L| ˜ ρii, that in matrix notation would be\r
\r
\r
ρ˙00\r
ρ˙01\r
ρ˙10\r
ρ˙11\r
\r
 =\r
\r
\r
0 iΩ −iΩ 0\r
iΩ iE 0 −iΩ\r
−iΩ 0 −iE iΩ\r
0 −iΩ iΩ 0\r
\r
\r
\r
\r
ρ00\r
ρ01\r
ρ10\r
ρ11\r
\r
 (27)"""

[[sections]]
number = "10"
title = "V. CPT-MAPS AND THE LINDBLAD MASTER EQUATION."
text = """
A. Completely positive maps\r
The problem we want to study is to find the most general Markovian transformation set between density matrices.\r
Until now, we have seen that quantum systems can evolve in two way, by a coherent evolution given (Postulate 3) and\r
by collapsing after a measurement (Postulate 2). Many efforts have been made to unify these two ways of evolving\r
[16], without giving a definite answer so far. It is reasonable to ask what is the most general transformation that can\r
be performed in a quantum system, and what is the dynamical equation that describes this transformation.\r
We are looking for maps that transform density matrices into density matrices. We define ρ(H) as the space of all\r
density matrices in the Hilbert space H. Therefore, we are looking for a map of this space onto itself, V : ρ(H) → ρ(H).\r
To ensure that the output of the map is a density matrix this should fulfil the following properties\r
• Trace preserving. Tr [VA] = Tr [A] , ∀A ∈ O(H).\r
• Completely positive (see below).\r
Any map that fulfils these two properties is called a completely positive and trace-preserving map (CPT-maps). The\r
first property is quite apparent, and it does not require more thinking. The second one is a little more complicated,\r
and it requires an intermediate definition.\r
Definition 1 A map V is positive iff ∀A ∈ B(H) s.t. A ≥ 0 ⇒ VA ≥ 0.\r
This definition is based in the idea that, as density matrices are positive, any physical map should transform positive\r
matrices into positive matrices. One could naively think that this condition must be sufficient to guarantee the\r
physical validity of a map. It is not. As we know, there exist composite systems, and our density matrix could be the\r
partial trace of a more complicated state. Because of that, we need to impose a more general condition.\r
Definition 2 A map V is completely positive iff ∀n ∈ N, V ⊗ 1n is positive.\r
To prove that not all positive maps are completely positive, we need a counterexample. A canonical example of an\r
operation that is positive but fails to be completely positive is the matrix transposition. If we have a Bell state in the\r
form |ψBi = √\r
1\r
2\r
(|01i + |10i) its density matrix can be expressed as\r
ρB =\r
1\r
2\r
(|0ih0| ⊗ |1ih1| + |1ih1| ⊗ |0ih0| + |0ih1| ⊗ |1ih0| + |1ih0| ⊗ |0ih1|), (28)\r
with a matrix representation\r
ρB =\r
1\r
2\r
\u001A\u0012 1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
0 1 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\r
+\r
\u0012\r
0 1\r
0 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\u001B . (29)\r
A little algebra shows that the full form of this matrix is\r
ρB =\r
\r
\r
0 0 0 0\r
0 1 1 0\r
0 1 1 0\r
0 0 0 0\r
\r
 , (30)\r
and it is positive.

11\r
FIG. 3: A total system (belonging to a Hilbert space HT , with states described by density matrices ρT , and with\r
dynamics determined by a Hamiltonian HT ) divided into the system of interest, ‘System’, and the environment.\r
It is easy to check that the transformation 1 ⊗ T2, meaning that we transpose the matrix of the second subsystem\r
leads to a non-positive matrix\r
(1 ⊗ T2) ρB =\r
1\r
2\r
\u001A\u0012 1 0\r
0 0 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
⊗\r
\u0012\r
0 0\r
1 0 \u0013\r
+\r
\u0012\r
0 0\r
0 1 \u0013\r
⊗\r
\u0012\r
0 1\r
0 0 \u0013\u001B . (31)\r
The total matrix is\r
(1 ⊗ T2) ρB =\r
\r
\r
0 0 0 1\r
0 1 0 0\r
0 0 1 0\r
1 0 0 0\r
\r
 , (32)\r
with −1 as an eigenvalue. This example illustrates how the non-separability of quantum mechanics restrict the\r
operations we can perform in a subsystem. By imposing this two conditions, we can derive a unique master equation\r
as the generator of any possible Markovian CPT-map.\r
B. Derivation of the Lindblad Equation from microscopic dynamics\r
The most common derivation of the Lindblad master equation is based on Open Quantum Theory. The Lindblad\r
equation is then an effective motion equation for a subsystem that belongs to a more complicated system. This\r
derivation can be found in several textbooks like Breuer and Petruccione’s [2] as well as Gardiner and Zoller’s [1].\r
Here, we follow the derivation presented in Ref. [26]. Our initial point is displayed in Figure 3. A total system\r
belonging to a Hilbert space HT is divided into our system of interest, belonging to a Hilbert space H, and the\r
environment living in HE.\r
The evolution of the total system is given by the von Neumann equation (13).\r
ρ˙T (t) = −i[HT , ρT (t)] . (33)

12\r
As we are interested in the dynamics of the system, without the environment, we trace over the environment degrees\r
of freedom to obtain the reduced density matrix of the system ρ(t) = TrE[ρT ]. To separate the effect of the total\r
hamiltonian in the system and the environment we divide it in the form HT = HS ⊗ 1E + 1S ⊗ HE + αHI , with\r
H ∈ H, HE ∈ HE, and HI ∈ HT , and being α a measure of the strength of the system-environment interaction.\r
Therefore, we have a part acting on the system, a part acting on the environment, and the interaction term. Without\r
losing any generality, the interaction term can be decomposed in the following way\r
HI =\r
X\r
i\r
Si ⊗ Ei, (34)\r
with Si ∈ B(H) and Ei ∈ B(HE)\r
3\r
.\r
To better describe the dynamics of the system, it is useful to work in the interaction picture (see Ref. [24] for\r
a detailed explanation about Schr¨odinger, Heisenberg, and interaction pictures). In the interaction picture, density\r
matrices evolve with time due to the interaction Hamiltonian, while operators evolve with the system and environment\r
Hamiltonian. An arbitrary operator O ∈ B(HT ) is represented in this picture by the time-dependent operator Oˆ(t),\r
and its time evolution is\r
Oˆ(t) = e\r
i(H+HE)t O e−i(H+HE)t\r
. (35)\r
The time evolution of the total density matrix is given in this picture by\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (t)\r
i\r
. (36)\r
This equation can be easily integrated to give\r
ρˆT (t) = ˆρT (0) − iα Z t\r
0\r
ds h\r
Hˆ\r
I (s), ρˆT (s)\r
i\r
. (37)\r
By this formula, we can obtain the exact solution, but it still has the complication of calculating an integral in the\r
total Hilbert space. It is also troublesome the fact that the state ˜ρ(t) depends on the integration of the density matrix\r
in all previous time. To avoid that we can introduce Eq. (37) into Eq. (36) giving\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
ds hHˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (s)\r
ii . (38)\r
By applying this method one more time we obtain\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
ds h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii + O(α\r
3\r
). (39)\r
After this substitution, the integration of the previous states of the system is included only in the terms that are O(α\r
3\r
)\r
or higher. At this moment, we perform our first approximation by considering that the strength of the interaction\r
between the system and the environment is small. Therefore, we can avoid high-orders in Eq. (39). Under this\r
approximation we have\r
dρˆT (t)\r
dt = −iα h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
ds hHˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (40)\r
We are interested in finding an equation of motion for ρ, so we trace over the environment degrees of freedom\r
3 From now on we will not writethe identity operators of the Hamil\u0002tonian parts explicitly when they can be inferred from the con\u0002text.

13\r
dρˆ(t)\r
dt = TrE\r
\u0014\r
dρˆT (t)\r
dt \u0015\r
= −iαTrE\r
h\r
Hˆ\r
I (t), ρˆT (0)i\r
− α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (41)\r
This is not a closed time-evolution equation for ˆρ(t), because the time derivative still depends on the full density\r
matrix ˆρT (t). To proceed, we need to make two more assumptions. First, we assume that t = 0 the system\r
and the environment have a separable state in the form ρT (0) = ρ(0) ⊗ ρE(0). This means that there are not\r
correlations between the system and the environment. This may be the case if the system and the environment have\r
not interacted at previous times or if the correlations between them are short-lived. Second, we assume that the\r
initial state of the environment is thermal, meaning that it is described by a density matrix in the form ρE(0) =\r
exp (−HE/T) /Tr[exp (−HE/T)], being T the temperature and taking the Boltzmann constant as kB = 1. By using\r
these assumptions, and the expansion of HI (34), we can calculate an expression for the first element of the r.h.s of\r
Eq. (41).\r
TrE\r
h\r
Hˆ\r
I (t), ρˆT (0)i\r
=\r
X\r
i\r
\u0010\r
Sˆ\r
i(t)ˆρ(0)TrE\r
h\r
Eˆ\r
i(t)ˆρE(0)i\r
− ρˆ(0)Sˆ\r
i(t)TrE\r
h\r
ρˆE(0)Eˆ\r
i(t)\r
i\u0011 . (42)\r
To calculate the explicit value of this term, we may use that hEii = Tr[EiρE(0)] = 0 for all values of i. This\r
looks like a strong assumption, but it is not. If our total Hamiltonian does not fulfil it, we can always rewrite it\r
as HT = (H + α\r
P\r
i\r
hEii Si) + HE + αH0\r
i\r
, with H0\r
i =\r
P\r
i Si ⊗ (Ei − hEii). It is clear that now hE0\r
i\r
i = 0, with\r
E0\r
i = Ei − hEii, and the system Hamiltonian is changed just by the addition of an energy shift that does no affect the\r
system dynamics. Because of that, we can assume that hEii = 0 for all i. Using the cyclic property of the trace, it is\r
easy to prove that the term of Eq. (42) is equal to zero, and the equation of motion (41) reduces to\r
˙ρˆ(t) = −α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆT (t)\r
ii . (43)\r
This equation still includes the entire state of the system and environment. To unravel the system from the envi\u0002ronment, we have to make a more restrictive assumption. As we are working in the weak coupling regime, we may\r
suppose that the system and the environment are non-correlated during all the time evolution. Of course, this is\r
only an approximation. Due to the interaction Hamiltonian, some correlations between system and environment are\r
expected to appear. On the other hand, we may assume that the timescales of correlation (τcorr) and relaxation of the\r
environment (τrel) are much smaller than the typical system timescale (τsys), as the coupling strength is very small\r
(α <<). Therefore, under this strong assumption, we can assume that the environment state is always thermal and\r
is decoupled from the system state, ˆρT (t) = ˆρ(t) ⊗ ρˆE(0). Eq. (43) then transforms into\r
˙ρˆ(t) = −α"""

[[sections]]
number = "2"
title = "Z t"
text = """
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s), ρˆ(t) ⊗ ρˆE(0)ii . (44)\r
The equation of motion is now independent for the system and local in time. It is still non-Markovian, as it depends\r
on the initial state preparation of the system. We can obtain a Markovian equation by realising that the kernel in the\r
integration and that we can extend the upper limit of the integration to infinity with no real change in the outcome.\r
By doing so, and by changing the integral variable to s → t − s, we obtain the famous Redfield equation [? ].\r
˙ρˆ(t) = −α"""

[[sections]]
number = "2"
title = "Z ∞"
text = """
0\r
dsTrE\r
h\r
Hˆ\r
I (t),\r
h\r
Hˆ\r
I (s − t), ρˆ(t) ⊗ ρˆE(0)ii . (45)\r
It is known that this equation does not warrant the positivity of the map, and it sometimes gives rise to density\r
matrices that are non-positive. To ensure complete positivity, we need to perform one further approximation, the\r
rotating wave approximation. To do so, we need to use the spectrum of the superoperator HA˜ ≡ [H, A], ∀A ∈ B(H).\r
The eigenvectors of this superoperator form a complete basis of space B(H) and, therefore, we can expand the\r
system-environment operators from Eq. (34) in this basis\r
Si =\r
X\r
ω\r
Si(ω), (46)

14\r
where the operators Si(ω) fulfils\r
[H, Si(ω)] = −ωSi(ω), (47)\r
being ω the eigenvalues of H˜ . It is easy to take also the Hermitian conjugated\r
h\r
H, S†\r
i\r
(ω)\r
i\r
= ωS†\r
i\r
(ω). (48)\r
To apply this decomposition, we need to change back to the Schr¨odinger picture for the term of the interaction\r
Hamiltonian acting on the system’s Hilbert space. This is done by the expression Sˆ\r
k = e\r
itHSke−itH. By using the\r
eigen-expansion (46) we arrive to\r
H˜\r
i(t) = X\r
k,ω\r
e\r
−iωtSk(ω) ⊗ E˜\r
k(t) = X\r
k,ω\r
e\r
iωtS\r
†\r
k\r
(ω) ⊗ E˜†\r
k\r
(t). (49)\r
To combine this decomposition with Redfield equation (45), we first may expand the commutators.\r
˙ρˆ(t) = −α\r
2Tr \u0014Z ∞\r
0\r
ds Hˆ\r
I (t)HˆI (t − s)ˆρ(t) ⊗ ρˆE(0) −\r
Z ∞\r
0\r
ds Hˆ\r
I (t)ˆρ(t) ⊗ ρˆE(0)HˆI (t − s)\r
−\r
Z ∞\r
0\r
ds Hˆ\r
I (t − s)ˆρ(t) ⊗ ρˆE(0)HˆI (t) + Z ∞\r
0\r
ds ρˆ(t) ⊗ ρˆE(0)Hˆ\r
I (t − s)HˆI (t)\r
\u0015\r
. (50)\r
We now apply the eigenvalue decomposition in terms of Sk(ω) for Hˆ\r
I (t − s) and in terms of S\r
†\r
k\r
(ω\r
0\r
) for Hˆ\r
I (t). By\r
using the permutation property of the trace and the fact that [HE, ρE(0)] = 0, and after some non-trivial algebra we\r
obtain\r
˙ρˆ(t) = X\r
ω,ω0\r
k,l\r
\u0010\r
e\r
i(ω\r
0−ω)t Γkl(ω)\r
h\r
Sl(ω)ˆρ(t), S†\r
k\r
(ω\r
0\r
)\r
i\r
+ e\r
i(ω−ω\r
0\r
)t Γ∗\r
lk(ω\r
0\r
)\r
h\r
Sl(ω), ρˆ(t)S\r
†\r
k\r
(ω\r
0\r
)\r
i\u0011 , (51)\r
where the effect of the environment has been absorbed into the factors\r
Γkl(ω) ≡\r
Z ∞\r
0\r
ds eiωsTrE\r
h\r
E˜†\r
k\r
(t)E˜\r
l(t − s)ρE(0)i\r
, (52)\r
where we are writing the environment operators of the interaction Hamiltonian in the interaction picture (Eˆ\r
l(t) =\r
e\r
iHEtEle−iHEt\r
). At this point, we can already perform the rotating wave approximation. By considering the time\u0002dependency on Eq. (51), we conclude that the terms with |ω − ω\r
0\r
| >> α2 will oscillate much faster than the typical\r
timescale of the system evolution. Therefore, they do not contribute to the evolution of the system. In the low\u0002coupling regime (α → 0) we can consider that only the resonant terms, ω = ω\r
0\r
, contribute to the dynamics and\r
remove all the others. By applying this approximation to Eq. (51) reduces to\r
˙ρˆ(t) = X\r
ω\r
k,l\r
\u0010\r
Γkl(ω)\r
h\r
Sl(ω)ˆρ(t), S†\r
k\r
(ω)\r
i\r
+ Γ∗\r
lk(ω)\r
h\r
Sl(ω), ρˆ(t)S\r
†\r
k\r
(ω)\r
i\u0011 . (53)\r
To divide the dynamics into Hamiltonian and non-Hamiltonian we now decompose the operators Γkl into Hermitian\r
and non-Hermitian parts, Γkl(ω) = 1\r
2\r
γkl(ω) + iπkl, with\r
πkl(ω) ≡\r
−i\r
2\r
(Γkl(ω) − Γ\r
∗\r
kl(ω))\r
γkl(ω) ≡ Γkl(ω) + Γ∗\r
kl(ω) = Z ∞\r
−∞\r
dseiωsTr hEˆ†\r
k\r
(s)ElρˆE(0)i. (54)

15\r
By these definitions we can separate the Hermitian and non-Hermitian parts of the dynamics and we can transform\r
back to the Schr¨odinger picture\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
ω\r
k,l\r
γkl(ω)\r
\u0012\r
Sl(ω)ρ(t)S\r
†\r
k\r
(ω) −\r
1\r
2\r
n\r
S\r
†\r
kSl(ω), ρ(t)\r
o\u0013\r
. (55)\r
The Hamiltonian dynamics now is influenced by a term HLs =\r
P\r
ω,k,l πkl(ω)S\r
†\r
k\r
(ω)Sl(ω). This is usually called a Lamb\r
shift Hamiltonian and its role is to renormalize the system energy levels due to the interaction with the environment.\r
Eq. (55) is the first version of the Markovian Master Equation, but it is not in the Lindblad form yet.\r
It can be easily proved that the matrix formed by the coefficients γkl(ω) is positive as they are the Fourier’s\r
transform of a positive function \u0010Tr hEˆ†\r
k\r
(s)ElρˆE(0)i\u0011. Therefore, this matrix can be diagonalised. This means that\r
we can find a unitary operator, O, s.t.\r
Oγ(ω)O\r
† =\r
\r
\r
d1(ω) 0 · · · 0\r
0 d2(ω) · · · 0\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
.\r
. 0\r
0 0 · · · dN (ω)\r
\r
\r
. (56)\r
We can now write the master equation in a diagonal form\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
i,ω\r
\u0012\r
Li(ω)ρ(t)L\r
†\r
i\r
(ω) −\r
1\r
2\r
n\r
L\r
†\r
iLi(ω), ρ(t)\r
o\u0013\r
≡ Lρ(t). (57)\r
This is the celebrated Lindblad (or Lindblad-Gorini-Kossakowski-Sudarshan) Master Equation. In the simplest case,\r
there will be only one relevant frequency ω, and the equation can be further simplified to\r
ρ˙(t) = −i[H + HLs, ρ(t)] +X\r
i\r
\u0012\r
Liρ(t)L\r
†\r
i −\r
1\r
2\r
n\r
L\r
†\r
iLi\r
, ρ(t)\r
o\u0013\r
≡ Lρ(t). (58)\r
The operators Li are usually referred to as jump operators.\r
C. Derivation of the Lindblad Equation as a CPT generator\r
The second way of deriving Lindblad equation comes from the following question: What is the most general\r
(Markovian) way of mapping density matrix onto density matrices? This is usually the approach from quantum\r
information researchers that look for general transformations of quantum systems. We analyse this problem following\r
mainly Ref. [28].\r
To start, we need to know what is the form of a general CPT-map.\r
Lemma 2 Any map V : B (H) → B (H) that can be written in the form Vρ = V\r
†ρV with V ∈ B (H) is positive.\r
The proof of the lemma requires a little algebra and a known property of normal matrices\r
Proof.\r
If ρ ≥ 0 ⇒ ρ = A†A , with A ∈ B(H). Therefore, Vρ = V\r
†ρV ⇒ hψ|V†ρV |ψi = hψ|V†A†AV |ψi = ||AV |ψi|| ≥ 0.\r
Therefore, if ρ is positive, the output of the map is also positive.\r
End of the proof.\r
This is a sufficient condition for the positivity of a map, but it is not necessary. It could happen that there are maps\r
that cannot be written in this form, but they are still positive. To go further, we need a more general condition, and\r
this comes in the form of the next theorem."""

[[sections]]
number = "16"
title = "Theorem 1 Choi’s Theorem."
text = """
A linear map V : B(H) → B(H) is completely positive iff it can be expressed as\r
Vρ =\r
X\r
i\r
V\r
†\r
i\r
ρVi(59)\r
with Vi ∈ B(H).\r
The proof of this theorem requires some algebra.\r
Proof\r
The ‘if’ implication is a trivial consequence of the previous lemma. To prove the converse, we need to extend the\r
dimension of our system by the use of an auxiliary system. If d is the dimension of the Hilbert space of pure states,\r
H, we define a new Hilbert space of the same dimension HA.\r
We define a maximally entangled pure state in the bipartition HA ⊗ H in the way\r
|Γi ≡ X\r
d−1\r
i=0\r
|iiA ⊗ |ii, (60)\r
being {|ii} and {|iiA} arbitrary orthonormal bases for H and HA.\r
We can extend the action of our original map V, that acts on B(H) to our extended Hilbert space by defining the\r
map V2 : B(HA) ⊗ B(H) → B(HA) ⊗ B(H) as\r
V2 ≡ 1B(HA) ⊗ V. (61)\r
Note that the idea behind this map is to leave the auxiliary subsystem invariant while applying the original map to\r
the original system. This map is positive because V is completely positive. This may appear trivial, but as it has been\r
explained before complete positivity is a more restrictive property than positivity, and we are looking for a condition\r
to ensure complete positivity.\r
We can now apply the extended map to the density matrix corresponding to the maximally entangled state (60),\r
obtaining\r
V2|ΓihΓ| =\r
X\r
d−1\r
i,j=0\r
|iihj| ⊗ V|iihj|. (62)\r
Now we can use the maximal entanglement of the state |Γi to relate the original map V and the action V2|ΓihΓ| by\r
taking the matrix elements with respect to HA.\r
V|iihj| = hi|A (V2|ΓihΓ|)|jiA. (63)\r
To relate this operation to the action of the map to an arbitrary vector |ψi ∈ HA ⊗ H, we can expand it in this basis\r
as\r
|ψi =\r
X\r
d−1\r
i=0\r
X\r
d−1\r
j=0\r
αij |iiA ⊗ |ji. (64)\r
We can also define an operator V|ψi ∈ B (H) s.t. it transforms |Γi into |ψi. Its explicit action would be written as\r
\r
1A ⊗ V|ψi\r
\u0001\r
|Γi =\r
Pd−1\r
i,j=0 αij (1A ⊗ |jihi|)\r
\u0010Pd−1\r
k=0 |ki ⊗ |ki\r
\u0011\r
=\r
Pd−1\r
i,j,k=0 αij (|ki ⊗ |ji)hi|ki\r
=\r
Pd−q\r
i,j,k=0 αij (|ki ⊗ |ji) δi,k =\r
Pd−1\r
i,j=0 αij |ii ⊗ |ji = |ψi. (65)

17\r
At this point, we have related the vectors in the extended space HA ⊗ H to operators acting on H. This can only be\r
done because the vector |Γi is maximally entangled. We go now back to our extended map V2. Its action on |ΓihΓ| is\r
given by Eq. (62) and as it is a positive map it can be expanded as\r
V2 (|ΓihΓ|) =\r
d\r
X2−1\r
l=0\r
|vlihvl|. (66)\r
with |vli ∈ HA ⊗ H. The vectors |vli can be related to operators in H as in Eq. (65).\r
|vli = (1A ⊗ Vl)|Γi. (67)\r
Based on this result we can calculate the product of an arbitrary vector |iiA ∈ HA with |vli.\r
hi|A|vli = hi|A (1A ⊗ Vl)|Γi = Vl\r
X\r
d−1\r
k=0\r
hi|kiA ⊗ |ki. (68)\r
This is the last ingredient we need for the proof.\r
We come back to the original question, we want to characterise the map V. We do so by applying it to an arbitrary\r
basis element |iihj| of B (H).\r
V (|iihj|) = (hi|A ⊗ 1A) V2 (|ΓihΓ|) (|jiA ⊗ 1A) = (hi|A ⊗ 1A)\r
\r
\r
d\r
X2−1\r
l=0\r
|vlihvl|\r
\r
 (|jiA ⊗ 1A)\r
=\r
d\r
X2−1\r
l=0\r
[(hi|A ⊗ 1A)|vli] [hvl|(|jiA ⊗ 1A)] =\r
d\r
X2−1\r
l=0\r
Vl|iihj|Vl. (69)\r
As |iihj| is an arbitrary element of a basis any operator can be expanded in this basis. Therefore, it is straightforward\r
to prove that\r
Vρ =\r
d\r
X2−l\r
l\r
V\r
†\r
l\r
ρVl.\r
End of the proof.\r
Thanks to Choi’s Theorem, we know the general form of CP-maps, but there is still an issue to address. As density\r
matrices should have trace one, we need to require any physical maps to be also trace-preserving. This requirement\r
gives as a new constraint that completely defines all CPT-maps. This requirement comes from the following theorem.\r
Theorem 2 Choi-Kraus’ Theorem.\r
A linear map V : B(H) → B(H) is completely positive and trace-preserving iff it can be expressed as\r
Vρ =\r
X\r
l\r
V\r
†\r
l\r
ρVl(70)\r
with Vl ∈ B(H) fulfilling\r
X\r
l\r
VlV\r
†\r
l = 1H. (71)"""

[[sections]]
number = "18"
title = "Proof."
text = """
We have already proved that this is a completely positive map, we only need to prove that it is also trace-preserving\r
and that all trace preserving-maps fulfil Eq. (71). The ‘if’ proof is quite simple by applying the cyclic permutations\r
and linearity properties of the trace operator.\r
Tr [Vρ] = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
VlρV †\r
l\r
\r
 = Tr\r
\r
\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl\r
\r
 ρ\r
\r
 = Tr [ρ] . (72)\r
We have to prove also that any map in the form (70) is trace-preserving only if the operators Vl fulfil (71). We start\r
by stating that if the map is trace-preserving by applying it to an any arbitrary element of a basis of B (H) we should\r
obtain\r
Tr [V (|iihj|)] = Tr [|iihj|] = δi,j . (73)\r
As the map has a form given by (70) we can calculate this same trace in an alternative way.\r
Tr [V (|iihj|)] = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
Vl|iihj|V\r
†\r
l\r
\r
 = Tr\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl|iihj|\r
\r
\r
=\r
X\r
k\r
hk|\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl|iihj|\r
\r
 |ki = hj|\r
\r
\r
d\r
X2−1\r
l=1\r
V\r
†\r
l\r
Vl\r
\r
 |ii, (74)\r
where {|ki} is an arbitrary basis of H. As both equalities should be right we obtain\r
hj|\r
\r
\r
d\r
X2−1\r
l=1\r
VlV\r
†\r
l\r
\r
 |ii = δi,j , (75)\r
and therefore, the condition (71) should be fulfilled.\r
End of the proof.\r
Operators Vi of a map fulfilling condition (71) are called Krauss operators. Because of that, sometimes CPT-maps\r
are also called Krauss maps, especially when they are presented as a collection of Krauss operators. Both concepts\r
are ubiquitous in quantum information science. Krauss operators can also be time-dependent as long as they fulfil\r
relation (71) for all times.\r
At this point, we already know the form of CPT-maps, but we do not have a master equation, that is a continuous\r
set of differential equations. This means that we know how to perform an arbitrary operation in a system, but we do\r
not have an equation to describe its time evolution. To do so, we need to find a time-independent generator L such\r
that\r
d\r
dtρ (t) = Lρ(t), (76)\r
and therefore our CPT-map could be expressed as V(t) = e\r
Lt\r
. The following calculation is about founding the explicit\r
expression of L. We start by choosing an orthonormal basis of the bounded space of operators B(H), {Fi}\r
d\r
2\r
i=1. To be\r
orthonormal it should satisfy the following condition\r
hhFi|Fj ii ≡ Tr hF\r
†\r
i Fj\r
i\r
= δi,j . (77)\r
Without any loss of generality, we select one of the elements of the basis to be proportional to the identity, Fd2 = √\r
1\r
d\r
1H.\r
It is trivial to prove that the norm of this element is one, and it is easy to see from Eq. (77) that all the other elements\r
of the basis should have trace zero."""

[[sections]]
number = "19"
title = "Tr [Fi] = 0 ∀i = 1, . . . , d2 − 1. (78)"
text = """
The closure relation of this basis is 1B(H) =\r
P\r
i\r
|FiiihhFi|. Therefore, the Krauss operators can be expanded in this\r
basis by using the Fock-Liouville notation\r
Vl(t) =\r
d\r
X2\r
i=1\r
hhFi|Vl(t)ii|Fiii. (79)\r
As the map V(t) is in the form (59) we can apply (79) to obtain4.\r
V(t)ρ =\r
X\r
l\r
\r
\r
d\r
X2\r
i=1\r
hhFi|Vl(t)iiFi ρ\r
d\r
X2\r
j=1\r
F\r
†\r
j\r
hhVl(t)|Fj ii\r
\r
 =\r
d\r
X2\r
i,j=1\r
ci,j (t)FiρF†\r
j\r
, (80)\r
where we have absorved the sumation over the Krauss operators in the terms ci,j (t) = P\r
l\r
hhFi|VliihhVl|Fj ii. We go\r
back now to the original problem by applying this expansion into the time-derivative of Eq. (76)\r
dρ\r
dt = lim\r
∆t→0\r
1\r
∆t\r
(V(∆t)ρ − ρ) = lim\r
∆t→0\r
\r
\r
d\r
X2\r
i,j=1\r
ci,j (∆t)FiρF†\r
j − ρ\r
\r
\r
= lim\r
∆t→0\r
\r
\r
d\r
X2−1\r
i,j=0\r
ci,j (∆t)FiρF†\r
j +\r
d\r
X2−1\r
i=1\r
ci,d2 FiρF†\r
d2\r
+\r
d\r
X2−1\r
j=1\r
cd2,j (∆t)Fd2 ρF†\r
j + cd2,d2 (∆t)Fd2 ρF†\r
d2 − ρ\r
\r
 , (81)\r
where we have separated the summations to take into account that Fd2 = √\r
1\r
d\r
1H. By using this property this equation\r
simplifies to\r
dρ\r
dt = lim\r
∆t→0\r
1\r
∆t\r
\r
\r
d\r
X2−1\r
i,j=1\r
ci,j (∆t)FiρF†\r
j +\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
ci,d2 (∆t)Fi\r
ρ\r
+\r
1\r
√\r
d\r
d\r
X2−1\r
j=1\r
cd2,j (∆t)ρF†\r
j +\r
1\r
d\r
cd2,d2 (∆t)ρ − ρ\r
\r
 . (82)\r
The next step is to eliminate the explicit dependence with time. To do so, we define new constants to absorb all the\r
time intervals.\r
gi,j ≡ lim\r
∆t→0\r
ci,j (∆t)\r
∆t\r
(i, j < d2),\r
gi,d2 ≡ lim\r
∆t→0\r
ci,d2 (∆t)\r
∆t\r
(i < d2),\r
gd2,j ≡ lim\r
∆t→0\r
cd2,j (∆t)\r
∆t\r
(j < d2), (83)\r
gd2,d2 ≡ lim\r
∆t→0\r
cd2,d2 (∆t) − d\r
∆t\r
.\r
4 For simplicity, in this discussion we omit the explicit time- dependency of the density matrix.

20\r
Introducing these coefficients in Eq (82) we obtain an equation with no explicit dependence in time.\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j +\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
gi,d2 Fiρ +\r
1\r
√\r
d\r
d\r
X2−1\r
j=1\r
gd2,jρF†\r
j +\r
gd2,d2\r
d\r
ρ.\r
(84)\r
As we are already summing up over all the Krauss operators it is useful to define a new operator\r
F ≡\r
1\r
√\r
d\r
d\r
X2−1\r
i=1\r
gi,d2 Fi. (85)\r
Applying it to Eq. (82).\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j + F ρ + ρF† +\r
gd2,d2\r
d\r
ρ. (86)\r
At this point, we want to separate the dynamics of the density matrix into a Hermitian (equivalent to von Neunmann\r
equation) and an incoherent part. We split the operator F in two to obtain a Hermitian and anti-Hermitian part.\r
F =\r
F + F\r
†\r
2\r
+ i\r
F − F\r
†\r
2i\r
≡ G − iH, (87)\r
where we have used the notation H for the Hermitian part for obvious reasons. If we take this definition to Eq. (86)\r
we obtain\r
dρ\r
dt = gi,jFiρF†\r
j + {G, ρ} − i[H, ρ] + gd2,d2\r
d\r
ρ. (88)\r
We define now the last operator for this proof, G2 ≡ G +\r
gd2,d2\r
2d\r
, and the expression of the time derivative leads to\r
dρ\r
dt =\r
d\r
X2−1\r
i,j=1\r
gi,jFiρF†\r
j + {G2, ρ} − i[H, ρ] . (89)\r
Until now we have imposed the complete positivity of the map, as we have required it to be written in terms of Krauss\r
maps, but we have not used the trace-preserving property. We impose now this property, and by using the cyclic\r
property of the trace, we obtain a new condition\r
Tr \u0014\r
dρ\r
dt \u0015\r
= Tr\r
\r
\r
d\r
X2−1\r
i,j=1\r
F\r
†\r
j Fiρ + 2G2ρ\r
\r
 = 0. (90)\r
Therefore, G2 should fulfil\r
G2 =\r
1\r
2\r
d\r
X2−1\r
i,j=1\r
gi,jF\r
†\r
j Fiρ. (91)\r
By applying this condition, we arrive at the Lindblad master equation\r
dρ\r
dt = −i[H, ρ] +\r
d\r
X2−1\r
i,j=1\r
gi,j \u0012FiρF†\r
j −\r
1\r
2\r
n\r
F\r
†\r
j Fi\r
, ρo\u0013. (92)

21\r
Finally, by definition the coefficients gi,j can be arranged to form a Hermitian, and therefore diagonalisable, matrix.\r
By diagonalising it, we obtain the diagonal form of the Lindblad master equation.\r
d\r
dtρ = −i[H, ρ] +X\r
k\r
Γk\r
\u0012\r
LkρL†\r
k −\r
1\r
2\r
n\r
LkL\r
†\r
k\r
, ρo\u0013≡ Lρ. (93)\r
D. Properties of the Lindblad Master Equation\r
Some interesting properties of the Lindblad equation are:\r
• Under a Lindblad dynamics, if all the jump operators are Hermitian, the purity of a system fulfils d\r
dt \r
Tr \u0002ρ\r
2\r
\u0003\u0001 ≤"""

[[sections]]
number = "0"
title = "The proof is given in A."
text = """
• The Lindblad Master Equation is invariant under unitary transformations of the jump operators\r
p\r
ΓiLi →\r
p\r
Γ\r
0\r
iL\r
0\r
i =\r
X\r
j\r
vijpΓjLj , (94)\r
with v representing a unitary matrix. It is also invariant under inhomogeneous transformations in the form\r
Li → L\r
0\r
i = Li + ai\r
H → H0 = H +\r
1\r
2i\r
X\r
j\r
Γj\r
\u0010\r
a\r
∗\r
jAj − ajA\r
†\r
j\r
\u0011\r
+ b, (95)\r
where ai ∈ C and b ∈ R. The proof of this can be found in Ref. [2] (Section 3).\r
• Thanks to the previous properties it is possible to find traceless jump operators without loss of generality."""

[[sections]]
number = "22"
title = "Box 6. A master equation for a two-level system with decay."
text = """
Continuing our example of a two-level atom, we can make it more realistic by including the pos\u0002sibility of atom decay by the emission of a photon. This emission happens due to the interaction\r
of the atom with the surrounding vacuum statea. The complete quantum system would be in\r
this case the ‘atom+vacuum’ system and its time evolution should be given by the von Neumann\r
equation (13), where H represents the total ‘atom+vacuum’ Hamiltonian. This system belongs to\r
an infinite-dimension Hilbert space, as the radiation field has infinite modes. If we are interested\r
only in the time dependence state of the atom, we can derive a Markovian master equation for the\r
reduced density matrix of the atom (see for instance Refs. [1, 2]). The master equation we will\r
study is\r
d\r
dtρ(t) = −i[H, ρ] + Γ \u0012\r
σ\r
−ρσ+ −\r
1\r
2\r
\b\r
σ\r
+σ−, ρ\t\r
\u0013\r
, (96)\r
where Γ is the coupling between the atom and the vacuum.\r
In the Fock-Liouvillian space (following the same ordering as in Eq. (3)) the Liouvillian corre\u0002sponding to evolution (96) is\r
L =\r
\r
\r
0 iΩ −iΩ Γ\r
iΩ −iE −\r
Γ\r
2\r
0 −iΩ\r
−iΩ 0 −iE −\r
Γ\r
2\r
iΩ\r
0 −iΩ iΩ −Γ\r
\r
 . (97)\r
Expressing explicitly the set of differential equations we obtain\r
ρ˙00 = iΩρ01 − iΩρ10 + Γρ11\r
ρ˙01 = iΩρ00 −\r
\u0012\r
iE −\r
Γ\r
2\r
\u0013\r
ρ01 − iΩρ11\r
ρ˙10 = −iΩρ00 \u0012−iE −\r
Γ\r
2\r
\u0013\r
ρ10 + iΩρ11 (98)\r
ρ˙10 = −iΩρ01 + iΩρ10 − Γρ11\r
a This is why atoms decay."""

[[sections]]
number = "23"
title = "VI. RESOLUTION OF THE LINDBLAD MASTER EQUATION"
text = """
A. Integration\r
To calculate the time evolution of a system determined by a Master Equation in the form (96) we need to solve a\r
set of equations with as many equations as the dimension of the density matrix. In our example, this means to solve\r
a 4 variable set of equations, but the dimension of the problem increases exponentially with the system size. Because\r
of this, for bigger systems techniques for dimension reduction are required.\r
To solve systems of partial differential equations there are several canonical algorithms. This can be done analytically\r
only for a few simple systems and by using sophisticated techniques as damping bases [29]. In most cases, we have\r
to rely on numerical approximated methods. One of the most popular approaches is the 4th-order Runge-Kutta\r
algorithm (see, for instance, [30] for an explanation of the algorithm). By integrating the equations of motion, we can\r
calculate the density matrix at any time t.\r
The steady-state of a system can be obtained by evolving it for a long time (t → ∞). Unfortunately, this method\r
presents two difficulties. First, if the dimension of the system is big, the computing time would be huge. This means\r
that for systems beyond a few qubits, it will take too long to reach the steady-state. Even worse is the problem of\r
stability of the algorithms for integrating differential equations. Due to small errors in the calculation of derivatives by\r
the use of finite differences, the trace of the density matrix may not be constantly equal to one. This error accumulates\r
during the propagation of the state, giving non-physical results after a finite time. One solution to this problem is the\r
use of algorithms specifically designed to preserve the trace, as Crank-Nicholson algorithm [31]. The problem with\r
this kind of algorithms is that they consume more computational power than Runge-Kutta, and therefore they are\r
not useful to calculate the long-time behaviour of big systems. An analysis of different methods and their advantages\r
and disadvantages can be found at Ref. [32].\r
Box 7. Time dependency of the two-level system with decay.\r
In this box we show some results of solving Eq (96) and calculating the density matrix as a function\r
of time. A Mathematica notebook solving this problem can be found at [20]. To illustrate the time\r
behaviour of this system, we calculate the evolution for different state parameters. In all cases,\r
we start with an initial state that represents the state being excited ρ11 = 1, with no coherence\r
between different states, meaning ρ01 = ρ10 = 0. If the decay parameter Γ is equal to zero, the\r
problem reduces to solve von Neumann equation, and the result is displayed in Figure 2. The other\r
extreme case would be a system with no coherent dynamics (Ω = 0) but with decay. In this case,\r
we observe an exponential decay of the population of the excited state. Finally, we can calculate\r
the dynamics of a system with both coherent driving and decay. In this case, both behaviours\r
coexist, and there are oscillations and decay.\r
5 10 15 20\r
Time\r
0.2\r
0.4\r
0.6\r
0.8"""

[[sections]]
number = "1.0"
title = "Population"
text = """
2 4 6 8 10\r
Time\r
0.2\r
0.4\r
0.6\r
0.8"""

[[sections]]
number = "1.0"
title = "Population"
text = """
FIG. 4: Left: Population dynamics under a pure incoherent dynamics (Γ = 0.1, n = 1, Ω =\r
0, E = 1). Right: Population dynamics under both coherent and incoherent dynamics (Γ =\r
0.1, n = 1, Ω = 1, E = 1). In both the blue lines represent ρ11 and the orange one ρ00."""

[[sections]]
number = "24"
title = "B. Diagonalisation"
text = """
As we have discussed before, in the Fock-Liouville space the Liouvillian corresponds to a complex matrix (in general\r
complex, non-hermitian, and non-symmetric). By diagonalising it we can calculate both the time-dependent and the\r
steady-state of the density matrices. For most purposes, in the short time regime integrating the differential equations\r
may be more efficient than diagonalising. This is due to the high dimensionality of the Liouvillian that makes the\r
diagonalisation process very costly in computing power. On the other hand, in order to calculate the steady-state,\r
the diagonalisation is the most used method due to the problems of integrating the equation of motions discussed in\r
the previous section.\r
Let see first how we use diagonalisation to calculate the time evolution of a system. As the Liouvillian matrix is\r
non-Hermitian, we cannot apply the spectral theorem to it, and it may have different left and right eigenvectors. For\r
a specific eigenvalue Λi we can obtain the eigenvectors |Λ\r
R\r
i\r
ii and |Λ\r
L\r
i\r
ii s. t.\r
L | ˜ Λ\r
R\r
i\r
ii = Λi|Λ\r
R\r
i\r
ii\r
hhΛ\r
L\r
i\r
| L˜ = ΛihhΛ\r
L\r
i\r
| (99)\r
An arbitrary system can be expanded in the eigenbasis of L˜ as [1, 33]\r
|ρ(0)ii =\r
X\r
i\r
|Λ\r
R\r
i\r
iihhΛ\r
L\r
i\r
|ρ(0)ii. (100)\r
Therefore, the state of the system at a time t can be calculated in the form\r
|ρ(t)ii =\r
X\r
i\r
e\r
Λit\r
|Λ\r
R\r
i\r
iihhΛ\r
L\r
i\r
|ρ(0)ii. (101)\r
Note that in this case to calculate the state a time t we do not need to integrate into the interval [0, t], as we have to\r
do if we use a numerical solution of the differential set of equations. This is an advantage when we want to calculate\r
long-time behaviour. Furthermore, to calculate the steady-state of a system, we can look to the eigenvector that has\r
zero eigenvalue, as this is the only one that survives when t → ∞.\r
For any finite system, Evans’ Theorem ensures the existence of at least one zero eigenvalue of the Liouvillian\r
matrix [34, 35]. The eigenvector corresponding to this zero eigenvalue would be the steady-state of the system. In\r
exceptional cases, a Liouvillian can present more than one zero eigenvalues due to the presence of symmetry in the\r
system [26, 27, 36]. This is a non-generic case, and for most purposes, we can assume the existence of a unique\r
fixed point in the dynamics of the system. Therefore, diagonalising can be used to calculate the steady-state without\r
calculating the full evolution of the system. This can be done even analytically for small systems, and when numerical\r
approaches are required this technique gives better precision than integrating the equations of motion. The spectrum\r
of Liouvillian superoperators has been analysed in several recent papers [33, 37]."""

[[sections]]
number = "25"
title = "Box 8. Spectrum-analysis of the Liouvillian for the two-level system with decay."
text = """
Here we diagonalise (97) and obtain its steady state. A Mathematica notebook solving this problem\r
can be downloaded from [20]. This specific case is straightforward to diagonalize as the dimension\r
of the system is very low. We obtain 4 different eigenvalues, two of them are real while the other\r
two form a conjugated pair. Figure 5 sisplays the spectrum of the superoperator L given in (97).\r
-0.4 -0.3 -0.2 -0.1\r
-2\r
-1\r
1\r
2\r
FIG. 5: Spectrum of the Liouvillian matrix given by (97) for the general case of both coherent and\r
incoherent dynamics (Γ = 0.2, n = 1, Ω = 0, E = 1).\r
As there only one zero eigenvalue we can conclude that there is only one steady-state, and any\r
initial density matrix will evolve to it after an infinite-time evolution. By selecting the right\r
eigenvector corresponding to the zero-eigenvalue and normalizing it we obtain the density matrix.\r
This can be done even analytically. The result is the matrix:\r
ρSS =\r
\r
\r
(1+n)(4 E\r
2+(Γ+2n Γ)2\r
)+4(1+2n)Ω2\r
(1+2n)(4 E2+(Γ+2n Γ)2+8Ω2)\r
2(−2 E−i(Γ+2nΓ))Ω\r
(1+2n)(4 E2+(Γ+2n Γ)2+8 Ω2)\r
2(−2 E+i(Γ+2n Γ))Ω\r
(1+2n)(4 E2+(Γ+2n Γ)2+8Ω2)\r
n(4E\r
2+(Γ+2nΓ)2\r
)+4(1+2n)Ω2\r
(1+2n)(4 E2+(Γ+2nΓ)2+8 Ω2)\r
\r
 (102)\r
VII. ACKNOWLEDGEMENTS\r
The author wants to acknowledge the Spanish Ministry and the Agencia Espa˜nola de Investigaci´on (AEI) for\r
financial support under grant FIS2017-84256-P (FEDER funds).\r
[1] C.W. Gardiner and P. Zoller. Quantum Noise. Springer, Berlin, 2000.\r
[2] H.P. Breuer and F. Petruccione. The theory of open quantum systems. Oxford University Press, 2002.\r
[3] A. Rivas and S. Huelga. Open Quantum Systems. An Introduction. Springer, New York, 2012.\r
[4] G. Lindblad. On the generators of quantum dynamical semigroups. Commun. Math. Phys., 119:48, 1976.\r
[5] V. Gorini, A. Kossakowski, and E.C. Sudarsahan. Completely positive semigroups of n-level systems. J. Math. Phys.,\r
17:821, 1976.\r
[6] D. Manzano and E. Kyoseva. An atomic symmetry-controlled thermal switch. Scientific Reports, 6:31161, 2016.\r
[7] T. Prosen. Open xxz spin chain: Nonequilibrium steady state and a strict bound on ballistic transport. Phys. Rev. Lett.,\r
106:217206, 2011.

26\r
[8] D. Manzano, M. Tiersch, A. Asadian, and H.J. Briegel. Quantum transport efficiency and Fourier’s law. Phys. Rev. E,\r
86:061118, 2012.\r
[9] D. Manzano, C. Chuang, and J. Cao. Quantum transport in d-dimensional lattices. New J. Physics, 18:043044, 2015.\r
[10] B. Olmos, I. Lesanovsky, and J.P. Garrahan Facilitated Spin Models of Dissipative Quantum Glasses Phys. Rev. Lett.,\r
109:020403, 2012.\r
[11] J. Metz, M. Trupke, andA. Beige Robust Entanglement through Macroscopic Quantum Jumps Phys. Rev. Lett., 97:040503,\r
2006.\r
[12] R. Jones, J. A. Needham, I. Lesanovsky, F. Intravaia, Beatriz Olmos Modified dipole-dipole interaction and dissipation in\r
an atomic ensemble near surfaces Phys. Rev. A, 97:053841, 2018.\r
[13] D.A. Lidar, I.L. Chuang, and K. B. Whaley. Decoherence-free subspaces for quantum computation. Phys. Rev. Lett.,\r
81(12):2594, 1998.\r
[14] B. Kraus, H. P. B¨uchler, S. Diehl, A. Kantian, A. Micheli, and P. Zoller. Preparation of entangled states by quantum\r
markov processes. Phys. Rev. A, 2008.\r
[15] T.A. Brun. Continuous measurements, quantum trajectories, and decoherent histories. Phys. Rev. A, 61:042107, 2000.\r
[16] M. Schlosshauer. Decoherence and the Quantum-to-Classical Transition. Springer, New York, 2007.\r
[17] M. Plenio and S. Huelga. Dephasing-assisted transport: quantum networks and biomolecules. New J. Phys., 10:113019,\r
2008.\r
[18] M. Mohseni, P. Rebentrost, S. Lloyd, and A. Aspuru-Guzik. Enviroment-assisted quantum walks in photosynthetic energy\r
transfer. Journal of Chemical Physics, 129:174106, 2008.\r
[19] D. Manzano. Quantum transport in quantum networks and photosynthetic complexes at the steady state. PLoS ONE,\r
8(2):e57041, 2013.\r
[20] https://ic1.ugr.es/manzano/Descargas/Lindblad/Lindblad_Manzano.zip\r
[21] L. Debnath and P. Mikusi´nki. Introduction to Hilbert Spaces with Applications. Elsevier Academic Press, 2005.\r
[22] M.A. Nielsen and I.L. Chuang. Quantum Computation and Quantum Information. Cambridge Univ. Press, Cambridge,\r
2000.\r
[23] J.J. Sakurai. Modern Quantum Mechanics. Addison-Wesley Publishing Co., 1994.\r
[24] A. Galindo and P. Pascual. Quantum Mechanics I. Springer, Berlin, 1990.\r
[25] A. Peres. Quantum Theory: Concepts and Methods. Kluwer Academic Publishers, 1995.\r
[26] D. Manzano and P.I. Hurtado. Harnessing symmetry to control quantum transport. Adv. Phys, 67:1, 2018.\r
[27] D. Manzano and P.I. Hurtado. Symmetry and the thermodynamics of currents in open quantum systems Phys. Rev. B,\r
90:125138, 2014.\r
[28] M.M. Wilde. Quantum Information Theory. Cambridge Univ. Press, Cambridge, 2017.\r
[29] H.J. Briegel and B.G. Englert. Quantum optical master equation: The use of damping bases. Phys. Rev. A, 47:3311, 1993.\r
[30] W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. Numerical Recipes. Cambridge Univ. Press, Cambridge,\r
2007.\r
[31] A. Goldberg, H. Schey, and J.L. Schwartz. Computer-generated motion pictures of one-dimensional quantum-mechanical\r
transmission and reflection phenomena. Am. J. Phys., 35:177, 1967.\r
[32] M. Riesch and C. Jirauschek. Analyzing the positivity preservation of numerical methods for the liouville-von neumann\r
equation. J. Comp. Phys., 390:290, 2019.\r
[33] J. Thingna, D. Manzano, and J. Cao. Dynamical signatures of molecular symmetries in nonequilibrium quantum transport.\r
Scientific Reports, 6:28027, 2016.\r
[34] D.E. Evans. Irreducible quantum dynamical semigroups. Commun. Math. Phys., 54:293, 1977.\r
[35] D.E. Evans and H. Hance-Olsen. The generators of positive semigroups. Journal of Positive Analysis, 32:207, 1979.\r
[36] B. Buˇca and T. Prosen. A note on symmetry reductions of the Lindblad equation: Transport in constrained open spin\r
chains. New J. Physics, 14:073007, 2012.\r
[37] V.V. Albert and L. Jiang. Symmetries and conserved quantities in Lindblad master equations. Phys. Rev. A, 89:022118,\r
2014."""

[[sections]]
number = "27"
title = "Appendix A: Proof of d"
text = """
dtTr \u0002\r
ρ\r
2\r
\u0003\r
≤ 0\r
In this appendix we proof that under the Lindblad dynamics given by Eq. (93) the purity of a density matrix fulfils\r
that d\r
dtTr \u0002\r
ρ\r
2\r
\u0003\r
≤ 0 if all the jump operators of the Lindblad dynamics are Hermitian.\r
We start just by interchanging the trace and the derivative. As the trace is a linear operation it commutes with\r
the derivation, and we have\r
d\r
dt\r
\r
Tr \u0002ρ\r
2\r
\u0003\u0001 = Tr \u0014\r
dρ2\r
dt \u0015\r
= Tr [2ρρ˙] , (A1)\r
where we have used the cyclic property of the trace operator5. By inserting the Lindblad Eq. (93) into the r.h.s of\r
(A1) we obtain\r
d\r
dt\r
\r
Tr \u0002ρ\r
2\r
\u0003\u0001 = −\r
i\r
¯h\r
Tr [(2ρ (Hρ − ρH))]\r
+ 2X\r
k\r
ΓkTr hρ Lkρ L†\r
k\r
i\r
− 2\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
. (A2)\r
The first term is zero. Therefore, the inequality we want to prove becomes equivalent to\r
X\r
k\r
ΓkTr hρ Lkρ L†\r
k\r
i\r
≤\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
(A3)\r
As the density matrix is Hermitian we can diagonalize it to obtain its eigenvalues (Λi ∈ R) and its corresponding\r
eigenvectors (|Λii). The density matrix is diagonal in its own eigenbasis and can be expressed as6\r
ρ → ρ˜ =\r
X\r
i\r
Λi|ΛiihΛi|, (A4)\r
where we assume an ordering of the eigenvalues in the form Λ0 ≥ Λ1 ≥ · · · ≥ Λd.\r
We rename the jump operators in this basis as L˜\r
i a. Expanding each term of the inequality (A3) in this basis we\r
obtain\r
X\r
k\r
ΓkTr hρ Lk ρ L†\r
k\r
i\r
=\r
X\r
k\r
ΓkTr\r
\r
\r
 X\r
i\r
Λi|ΛiihΛi|\r
!\r
L˜\r
k\r
\r
\r
X\r
j\r
Λj |Λj ihΛj |\r
\r
 L˜\r
k\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjTr hL˜†\r
k\r
|ΛiihΛi|L˜\r
k|Λj ihΛj |\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjTr \u0014\f\r
\f\r
\fhΛi\r
|L˜\r
k|Λj i\r
\f\r
\f\r
\f\r
2\r
\u0015\r
=\r
X\r
k\r
Γk\r
X\r
i,j\r
ΛiΛjx\r
(k)\r
ij , (A5)\r
where we have introduced the oefficients x\r
(k)\r
ij ≡\r
\f\r
\f\r
\fhΛi\r
|L˜\r
k|Λj i"""

[[sections]]
number = "2"
title = "As the operators Lk are Hermitian these coefficients"
text = """
fulfil x\r
(k)\r
ij = x\r
(k)\r
ji\r
The second term is expanded as\r
5 This property is used along all the demonstration without ex\u0002plicitly mentioning it."""

[[sections]]
number = "6"
title = "This eigenbasis changes with time, of course, but the proof is"
text = """
valid as the inequality should be fulfilled at any time.

28\r
X\r
k\r
ΓkTr hρ\r
2L\r
†\r
kLk\r
i\r
=\r
X\r
k\r
ΓkTr\r
\r
\r
 X\r
i\r
Λi|ΛiihΛi|\r
! \r
\r
X\r
j\r
Λj |Λj ihΛj |\r
\r
 L˜†\r
kL˜\r
k\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
ΛiΛjTr hL˜\r
k|ΛiihΛj |L˜†\r
k\r
hΛi|Λj i\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i\r
Λ\r
2\r
i Tr h\r
L˜\r
k|ΛiihΛi\r
|L˜†\r
k\r
i\r
=\r
X\r
k\r
Γk\r
X\r
i\r
Λ\r
2\r
i Tr\r
\r
L˜\r
k|ΛiihΛi\r
|L˜†\r
k\r
\r
\r
X\r
j\r
|Λj ihΛj |\r
\r
\r
\r
\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i Tr h\r
hΛj |L˜\r
k|Λii + hΛi\r
|L˜\r
k|Λj i\r
i\r
=\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i xij , (A6)\r
where we have used the closure relation in the density matrix eigenbasis, 1H =\r
P\r
j\r
|Λj ihΛj |. The inequality can be\r
written now as\r
X\r
k\r
Γk\r
X\r
ij\r
ΛiΛjxij ≤\r
X\r
k\r
Γk\r
X\r
ij\r
Λ\r
2\r
i xij . (A7)\r
As xij = xji we can re-order the ij sum in the following way\r
X\r
k\r
Γk\r
X\r
i\r
\r
\r
X\r
j≤i\r
2ΛiΛjx\r
(k)\r
ij + Λ2\r
i x\r
(k)\r
ii\r
\r
 ≤\r
X\r
k\r
Γk\r
X\r
i\r
\r
\r
X\r
j<i\r
\r
Λ\r
2\r
i + Λ2\r
j\r
\u0001\r
x\r
(k)\r
ij + Λ2\r
i x\r
(k)\r
ii\r
\r
 . (A8)\r
Therefore, we can reduce the proof of this inequality to the proof of a set of inequalities\r
2ΛiΛjx\r
(k)\r
ij ≤\r
\r
Λ\r
2\r
i + Λ2\r
j\r
\u0001\r
x\r
(k)\r
ij ∀ (k, i, j). (A9)\r
It is obvious that (A9) ⇒ (A8) (but not the other way around). The inequalities (A9) are easily proved just by taking\r
into account that x\r
(k)\r
ij ≥ 0 and applying the Triangular Inequality."""

[[tables]]
page_num = 4
headers = [
    "ai",
    "aiihai",
    ", (4)",
]
rows = [
    [
    "being ai ∈ R the eigenvalues of the observable and",
    "aii their corresponding eigenvectors. The probability of obtaining",
],
    [
    "the result ai when measuring the property described by observable O in a state",
    "ψi is given by",
],
    [
    "P(ai) =",
    "hψ",
    "aii",
    "2. (5)",
],
    [
    "After the measurement we obtain the state",
    "aii if the outcome ai was measured. This is called the post-measurement",
],
]

[[tables]]
page_num = 6
headers = [
    "As the states",
    "0i and",
    "1i are Hamiltonian eigenstates if at t = 0 the atom is at the excited state",
]
rows = [
    [
    "ψ(0)i =",
    "1i after a time t the state would be",
    "ψ(t)i = e",
],
    [
    "−iHt",
    "1i = e−iE1t",
],
]

[[tables]]
page_num = 17
headers = [
    "vlihvl",
    ". (66)",
]
rows = [
    [
    "with",
    "vli ∈ HA ⊗ H. The vectors",
    "vli can be related to operators in H as in Eq. (65).",
],
    [
    "vli = (1A ⊗ Vl)",
    "Γi. (67)",
],
    [
    "Based on this result we can calculate the product of an arbitrary vector",
    "iiA ∈ HA with",
    "vli.",
],
]

[[figures]]
label = "fig:1"
page_num = 1
image_path = "images/image_p1_1.png"

[[figures]]
label = "fig:2"
page_num = 11
image_path = "images/image_p11_2.png"
